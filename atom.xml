<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ScienJus&#39;s Blog</title>
  
  <subtitle>Science &amp; Justice</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.scienjus.com/"/>
  <updated>2018-01-15T05:58:11.000Z</updated>
  <id>http://www.scienjus.com/</id>
  
  <author>
    <name>ScienJus</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2017 年终总结</title>
    <link href="http://www.scienjus.com/2017-year-end-review/"/>
    <id>http://www.scienjus.com/2017-year-end-review/</id>
    <published>2017-12-31T15:36:33.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>一年一度的流水账…</p><a id="more"></a><h1 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h1><p>今年工作上最大的改变是离开了 ENJOY，来到了 Mobike。</p><h2 id="ENJOY"><a href="#ENJOY" class="headerlink" title="ENJOY"></a>ENJOY</h2><p>17 年上半年在 ENJOY 完成了优惠券的重构，并开始订单的重构。同时将 Zuul 推上了生产环境，接入了所有线上流量。至此，ENJOY 的后端架构对于同规模公司成熟度已经非常高了。有一套还算好用的微服务开发框架，线上应用全部通过自研的 PaaS 平台部署 Docker 容器。</p><p>我在 ENJOY 工作的一年中主要做了四件事：</p><ol><li>将「优惠券」模块从单体应用拆分到了独立微服务</li><li>将「订单」模块从单体应用拆分到了独立微服务</li><li>开发基于新 APNs 协议的推送平台</li><li>和另一个同事维护了一套类似 Spring Cloud Netflix 的微服务框架</li></ol><p>在 4 月份的时候，这些事基本都进入了尾声，同时因为一些团队内的氛围、工作方式的改变，自己对于工作上的热情开始大幅度下降。我最终决定在 6 月底主动提出了离职。</p><p>纵观在 ENJOY 的一年，实际上是过得非常充实的，同事中有 CMGS、Flex 这样的大牛，也有像 wzyboy、timfeirg 等很多优秀的同龄人。工作上能够真正去实施自己认为正确的方案，能够认同自己最终做出来的东西，能够承担更多责任，并带来更多的技术提升，产生非常好的良性循环，这段经历是非常宝贵的。</p><h2 id="Mobike"><a href="#Mobike" class="headerlink" title="Mobike"></a>Mobike</h2><p>离开 ENJOY 的时候我并没有想过自己要去哪家公司，也一向不擅长找工作和面试，所以最后只参加了三次面试，分别是「出门问问」、「LeanCloud」和「摩拜单车」。我一直都非常认同 LeanCloud 的工程师文化，对里面的大部分工程师都有一些了解，也非常敬佩庄晓丹这样的技术人，但是纠结了很久最终还是选择去了摩拜。</p><p>相比 ENJOY 摩拜的团队更加大一些，而且职责也分得更加细粒度一些，导致我呆了很久也没有完全适应。好在同事也都非常的 Nice，使我在完成本职工作之后，可以和更多的人交流，讨论和学习更多的技术。</p><p>目前我的大部分工作都和在 ENJOY 时没有太大区别，而我在工作外比较感兴趣的事是观察「如何提升整个团队的工作效率」上，举个例子，在 ENJOY 时我们希望一个 10 人的团队能做好 15 人的工作量，而在摩拜更像是希望一个 100 人的团队能做好 80 人的工作量，实现这两个目标努力的方向是完全不同的，有些甚至可能是完全相反的，当我站在完全不同的位置上去解决问题时，会发现给出的答案也会完全不同，这是非常有收获的。</p><p>摩拜是一家还在高速发展的公司，明年希望能够接受更多的技术挑战，做出更多稳定、健壮、优秀的系统，尝试更多新技术，以及支持更多的人更加快速的完成开发工作。</p><h1 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h1><p>今年发生了很多事，我的业余时间并不多，主要做了以下事：</p><ul><li>在 Github 上写了一些小组件，提了一些 MR，修了 Spring Cloud 的两个 Bug，更多的只是一些随意的小改动，比如给 yamllint 加上一个新的规则。</li><li>在 Coursera 上完成了「Functional Programming in Scala Specialization」系列课程，这门课由大名鼎鼎的 Scala 作者 Martin Odersky 开设，课程的质量非常高。</li><li>尝试维护一套自己（或和其他朋友）做 Side Project 的技术栈，主要由 Python 和 React 组成，在此之前我并没有用过这两种语言（框架），所以也学到了很多东西</li></ul><p>我有一个很大的坏习惯就是对于很多事都会很快的付诸行动，但是却没有一个长远的规划，这会导致这些事最终只会持续很短的一段时间便暂时搁置掉了，最终并不会有什么实质性的结果。所以我从下半年开始尝试写子弹笔记，开始重新续费 Things，希望能有所改善。</p><p>明年我希望自己的主要精力放在看书上，因为工作内容很有可能带来更偏向广度的知识增长，所以我需要通过看书获取一些更深度的知识保持平衡，否则很容易变成做了很多事技术能力却没有提升的窘境。</p><p>还有一点是总是感觉自己精力不够用，后来认为还是工作方式有一些问题，浪费了很多时间和精力，明年也希望多系统性的学习一些效率工具相关的知识。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一年一度的流水账…&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Spring Cloud AutoConfiguration 简介</title>
    <link href="http://www.scienjus.com/spring-cloud-autoconfiguration/"/>
    <id>http://www.scienjus.com/spring-cloud-autoconfiguration/</id>
    <published>2017-08-21T15:31:29.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>将公司内部分享的一个 Slide 拆解为两部分。本文是第一部分，主要介绍一下 Spring Boot AutoConfiguration 的组成和原理。</p><a id="more"></a><h1 id="什么是-AutoConfiguration"><a href="#什么是-AutoConfiguration" class="headerlink" title="什么是 AutoConfiguration"></a>什么是 AutoConfiguration</h1><p>Spring Boot 作为加快 Spring 项目开发的扩展框架，其中一个很重要的特性就是引入了 Starter 套件。Starter 可以在程序启动时自动初始化程序所需要的 Bean，开发者只需要关注如何使用组件本身。</p><p>Spring Boot 通过 AutoConfiguration 机制使得应用可以在启动时根据引入的类和配置，自动加载配置类（Configuration），从而在这些类中初始化所需的 Spring Bean。</p><p>一个完善的 AutoConfiguration 组件应该由四部分组成：</p><ol><li>配置类：就像开发者自己在项目中编写的一样，定义了初始化 Spring Bean 的方法。</li><li>自动装载：开发者只需要引入配置类，不用像使用组件扫描（Component Scan）的方式显式的初始化配置类，避免开发者关注组件配置具体的实现。</li><li>条件化加载：通过判断当前应用中引入的类库或是配置项，动态的判断项目是否需要加载某一个配置类，或是初始化某个 Bean。</li><li>配置项映射：定义每个组件可以通过哪些配置项进行配置，遵从约定大于配置的原则，开发者只需要按照定义对应的值。</li></ol><h1 id="配置类"><a href="#配置类" class="headerlink" title="配置类"></a>配置类</h1><p>从 Spring 3 开始，开发者就可以通过 Java Config 的方式配置 Bean 了。</p><p>一个最简单的配置类由 <code>@Configuration</code> 和 <code>@Bean</code> 组成，其中前者将该类声明为一个配置类，同时也作为一个 Spring 的组件以便被扫描、注入。后者作为方法上的注解可以将方法的返回值注册为 Spring Bean。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class GsonConfiguration &#123;</span><br><span class="line"></span><br><span class="line">@Bean</span><br><span class="line">public Gson gson() &#123;</span><br><span class="line">return new Gson();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Spring Boot 中的所有配置类都在 <code>spring-boot-autoconfigure</code> 项目中，在这个项目中可以看到 Spring 为每个组件定义了哪些类、初始化了哪些 Bean，以及是如何进行配置的。</p><h1 id="自动装载"><a href="#自动装载" class="headerlink" title="自动装载"></a>自动装载</h1><p>对于传统的配置类，在 Spring 项目中一般都是由组件扫描（<code>@ComponentScan</code>）或是主动引入（<code>@Import</code>）的方式去进行装载。这种方式使得使用者被迫的去了解组件的配制方法和源码，极易出现配置错误等问题。</p><p>而在 Spring Boot 中，则提供了具有自动装载功能的 <code>@EnableAutoConfiguration</code> 注解，只要在项目中使用了该注解（或是其作为元注解的 <code>@SpringBootApplication</code>），就会在应用启动时自动装载所有 Spring Boot 提供的配置类。</p><p>其实现原理也是基于 Spring 现有的组件。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><img src="/uploads/15032215137843.jpg" alt=""></p><p>逻辑的入口是 <code>@EnableAutoConfiguration</code>，它唯一的功能就是使用了 <code>@Import</code> 作为元注解，并引入了 <code>EnableAutoConfigurationImportSelector</code> 类。</p><p><code>@Import</code> 是在 Spring 3 中作为 Java Config 功能所引入的，其最初作用是为了实现 XML 配置中 <code>&lt;import&gt;</code> 标签的功能：将多个配置引入到主配置中。所以它最开始的用途也是为了引入一些 <code>@Configuration</code> 类。</p><p>其实 Java Config 的配置方式具有更强大的表现力，例如使用者可以在注解中设置不同的值，或是通过运行一段 Java 代码动态的加载不同的配置，于是在 Spring 3.1 中就引入了两个新的功能：</p><ul><li>配合 <code>ImportSelector</code>：通过读取注解属性，动态引入一些配置。</li><li>配合 <code>ImportBeanDefinitionRegistrar</code>：通过读取注解属性，动态注册 Bean。</li></ul><p>其中 <code>EnableAutoConfigurationImportSelector</code> 就是一个 <code>ImportSelector</code> 的实现类。该接口只有一个方法 <code>selectImports</code>，这个方法会传入注解的元信息，最后返回需要装载的配置类的类名。</p><p>在这个实现中，最终会调用 <code>SpringFactoriesLoader.loadFactoryNames</code> 加载配置类的类名。</p><p><img src="/uploads/15032270247665.jpg" alt=""></p><p>而 <code>SpringFactoriesLoader.loadFactoryNames</code> 则会去寻找项目中所有 <code>META-INF/spring.factories</code> 文件，并将其转化为 Properties，读取注解类名对应的值作为配置类的列表返回。</p><p><img src="/uploads/15032279356954.jpg" alt=""></p><p>查看 spring-boot-autoconfigure 项目，确实能发现其中包含着该文件，以及对应的配置项。</p><p><img src="/uploads/15032279639040.jpg" alt=""></p><p>至此可以得出一个结论，如果想要将一个配置类变为自动装载，只需要在项目中增加 <code>META-INF/spring.factories</code> 文件，并该类的类名作为 <code>ENableAutoConfiguration</code> 的值即可。</p><blockquote><p>这个文件不光可以定义配置类，还可以定义 <code>ApplicationListener</code> 或是 <code>ApplicationContextInitializer</code>，一样用来实现组件自动装载的功能。</p></blockquote><h2 id="阻止-AutoConfiguration"><a href="#阻止-AutoConfiguration" class="headerlink" title="阻止 AutoConfiguration"></a>阻止 AutoConfiguration</h2><p>阻止 AutoConfiguration 加载的方式有两种，一种是在 <code>@EnableAutoConfiguration</code> 的 <code>exclude</code> 属性中定义这个配置类的类名，另一种方式是在 <code>spring.autoconfigure.exclude</code> 配置中定义配置类的类名。一般更推荐前者，因为这种场景一般是在开发期都可以确定的。</p><h1 id="条件化加载"><a href="#条件化加载" class="headerlink" title="条件化加载"></a>条件化加载</h1><p>条件化加载是在 Spring 4 中引入的新特性，而到了 Spring Boot 配合自动装载才真正发挥出其强大的功能。</p><p>这个特性就是在配置类上或是某个配置 Bean 的方法上定义一系列条件。而只有这些条件满足时，这个配置类才会进行装载，或是这个方法才会被执行。</p><p>在传统的 Spring 项目中，一般配置类都是由自己定义，所以基本上定义的配置类都是实际需要使用的，也就自然不需要添加额外的加载条件。</p><p>而 Spring Boot 遵从约定大于配置，每一个 AutoConfiguration 都会根据项目中是否引入了必要的依赖，以及是否配置了必须的配置项决定是否加载，完美的契合了条件化加载的使用场景。</p><h2 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h2><p><img src="/uploads/15032299342952.jpg" alt=""></p><p>例如上图中初始化 Freemarker 的配置类，一共使用了 4 个条件化注解：</p><ul><li><code>@ConditionalOnClass</code>：指定的 Class 存在于当前 Classpath </li><li><code>@ConditionalOnWebApplication</code>：是一个 Web 应用</li><li><code>@ConditionalOnMissingBean</code>：指定的 Bean 不存在</li><li><code>@ConditionalOnProperty</code>：指定的配置项满足条件（存在、等于某个值、不等于某个值等）</li></ul><h2 id="ConditionalOnClass"><a href="#ConditionalOnClass" class="headerlink" title="@ConditionalOnClass"></a>@ConditionalOnClass</h2><p>由于用户定义的配置类永远会在 AutoConfiguration 之前进行装载，所以 <code>@ConditionalOnMissingBean</code> 可以很轻易的实现使用者自定义的 Bean 替代掉自动生成的 Bean 的功能。</p><h2 id="Profile"><a href="#Profile" class="headerlink" title="@Profile"></a>@Profile</h2><p>另一个比较特殊的注解是 <code>@Profile</code>，这个注解允许使用者通过 <code>spring.profiles.active</code> 来控制一些 Bean 是否初始化，或是初始化不同的实例。</p><p><code>@Profile</code> 实际是在 Spring 3 就有的功能，但是在 Spring 4 条件化注解出现后，其实现也通过相关 API 进行重写了。</p><h2 id="自定义条件"><a href="#自定义条件" class="headerlink" title="自定义条件"></a>自定义条件</h2><p>虽然 Spring Boot 已经提供了很多常用的条件实现，但是在某些特殊场景依旧需要自定义加载条件。</p><p>所有的条件注解实现都是由 <code>@Conditional</code> 这个注解作为元注解，并指向一个 <code>Condition</code> 接口的实现类。</p><p>以一个具体场景举例，在 Java 应用中开发者一般使用 Slf4j 作为通用的日志桥接，从而隐藏具体的 Log4j 或是 Logback 实现。而当需要开发与日志相关的配置类时，就需要根据不同日志实现加载相关的配置类，就需要自定义一个条件注解。</p><p>首先编写一个自定义的条件注解 <code>@ConditionalOnSlf4jBinding</code>，这个注解用于指定期望 Slf4j 绑定的具体实现，在使用这个注解时可以将期望实现的类名放在 <code>value</code> 中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)</span><br><span class="line">@Documented</span><br><span class="line">@Conditional(OnSlf4jBindingCondition.class)</span><br><span class="line">public @interface ConditionalOnSlf4jBinding &#123;</span><br><span class="line"></span><br><span class="line">  String value();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时按照规范，这个注解使用了 <code>@Conditional</code> 作为元注解，并指向了 <code>OnSlf4jBindingCondition</code>。这个类是一个 <code>SpringBootCondition</code> 的实现类，通过调用 Slf4j 的方法获取当前绑定的日志实现，并查看是否与期望值相同：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public class OnSlf4jBindingCondition extends SpringBootCondition &#123;</span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">  public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123;</span><br><span class="line">    String bindingClassName = attribute(metadata, &quot;value&quot;);</span><br><span class="line">    StaticLoggerBinder binder = StaticLoggerBinder.getSingleton();</span><br><span class="line">    String loggerFactoryClassName = binder.getLoggerFactoryClassStr();</span><br><span class="line"></span><br><span class="line">    return new ConditionOutcome(</span><br><span class="line">        loggerFactoryClassName.equals(bindingClassName),</span><br><span class="line">        String.format(&quot;Binding: %s, logger factory: %s&quot;, bindingClassName, loggerFactoryClassName));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  private static String attribute(AnnotatedTypeMetadata metadata, String name) &#123;</span><br><span class="line">    return (String) metadata.getAnnotationAttributes(ConditionalOnSlf4jBinding.class.getName()).get(name);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用时就像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@ConditionalOnSlf4jBinding(&quot;ch.qos.logback.classic.util.ContextSelectorStaticBinder&quot;)</span><br><span class="line">public class LogbackSentryAppenderInitializer &#123;</span><br><span class="line">  // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或是更进一步的枚举出所有日志实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)</span><br><span class="line">@Documented</span><br><span class="line">@ConditionalOnSlf4jBinding(&quot;ch.qos.logback.classic.util.ContextSelectorStaticBinder&quot;)</span><br><span class="line">public @interface ConditionalOnLogbackBinding &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用时会更加简单：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@ConditionalOnLogbackBinding</span><br><span class="line">public class LogbackSentryAppenderInitializer &#123;</span><br><span class="line">  // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="加载状态"><a href="#加载状态" class="headerlink" title="加载状态"></a>加载状态</h2><p>配置 <code>debug</code> 属性启动 Spring Boot 应用时，会打印一系列 AUTO-CONFIGURATION REPORT 的记录。</p><p>在这个记录中首先会把所有 AutoConfiguration 分为两组，一组为命中条件自动加载，另一组为未命中条件不进行自动加载。在这个报告中开发者可以很清晰的看到当前应用中每一个配置类因为满足/不满足某些条件最终会/不会被自动加载。</p><p><img src="/uploads/15032348544518.jpg" alt=""></p><h1 id="配置项映射"><a href="#配置项映射" class="headerlink" title="配置项映射"></a>配置项映射</h1><p>在配置文件中定义属性是 AutoConfiguration 唯一与使用者相关的功能。</p><p>一般在普通的应用开发中，开发者一般会使用 <code>@Value</code> 注入配置文件中的值。而在定义配置类时，更好的做法是定义一个与配置文件映射的 Model，并通过 <code>@ConfigurationProperties</code> 进行标识。</p><p><img src="/uploads/15032355461124.jpg" alt=""></p><p>而当 Configuration 装载时，可以使用 <code>@EnableConfigurationProperties</code> 将对应的配置类引入，会自动注册为 Spring Bean。</p><p><img src="/uploads/15032355276952.jpg" alt=""></p><p>使用这种做法的好处有很多：</p><ul><li>结构化配置：支持 List、Map、URL 等复杂类型以及嵌套 Model 的映射。</li><li>校验：可以通过和 Hibernate Validator 等校验组件结合，通过注解进行自动校验。</li><li>热刷新支持：在 Spring Cloud 环境下可以在应用运行中刷新绑定的配置项。</li><li>配置文件提示：Spring Boot 提供了 <code>spring-configuration-metadata.json</code> 用来描述配置项，配合 IDE 可以在编写配置文件时有提示。</li></ul><p><img src="/uploads/15032352039035.jpg" alt=""></p><blockquote><p><code>@Value</code> 实际也是支持热刷新的，但是必须定义为 <code>@RefreshScope</code>，而且实现也有不同，理论上 <code>@ConfigurationProperties</code> 的热刷新更加轻量级。</p><p>使用 <code>spring-boot-configuration-processor</code> 依赖可以在编译时扫描项目中的 <code>@ConfigurationProperties</code> 类，并自动生成 <code>spring-configuration-metadata.json</code> 文件。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;将公司内部分享的一个 Slide 拆解为两部分。本文是第一部分，主要介绍一下 Spring Boot AutoConfiguration 的组成和原理。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Spring Cloud 是如何实现热更新的</title>
    <link href="http://www.scienjus.com/spring-cloud-refresh/"/>
    <id>http://www.scienjus.com/spring-cloud-refresh/</id>
    <published>2017-07-25T12:12:31.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>作为一篇源码分析的文章，本文虽然介绍 Spring Cloud 的热更新机制，但是实际全文内容都不会与 Spring Cloud Config 以及 Spring Cloud Bus 有关，因为前者只是提供了一个远端的配置源，而后者也只是提供了集群环境下的事件触发机制，与核心流程均无太大关系。</p><a id="more"></a><h1 id="ContextRefresher"><a href="#ContextRefresher" class="headerlink" title="ContextRefresher"></a>ContextRefresher</h1><p>顾名思义，<code>ContextRefresher</code> 用于刷新 Spring 上下文，在以下场景会调用其 <code>refresh</code> 方法。</p><ol><li>请求 <code>/refresh</code> Endpoint。</li><li>集成 Spring Cloud Bus 后，收到 <code>RefreshRemoteApplicationEvent</code> 事件（任意集成 Bus 的应用，请求 <code>/bus/refresh</code> Endpoint 后都会将事件推送到整个集群）。</li></ol><p>这个方法包含了整个刷新逻辑，也是本文分析的重点。</p><p>首先看一下这个方法的实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public synchronized Set&lt;String&gt; refresh() &#123;</span><br><span class="line">  Map&lt;String, Object&gt; before = extract(</span><br><span class="line">      this.context.getEnvironment().getPropertySources());</span><br><span class="line">  addConfigFilesToEnvironment();</span><br><span class="line">  Set&lt;String&gt; keys = changes(before,</span><br><span class="line">      extract(this.context.getEnvironment().getPropertySources())).keySet();</span><br><span class="line">  this.context.publishEvent(new EnvironmentChangeEvent(keys));</span><br><span class="line">  this.scope.refreshAll();</span><br><span class="line">  return keys;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先是第一步 <code>extract</code>，这个方法接收了当前环境中的所有属性源（PropertySource），并将其中的非标准属性源的所有属性汇总到一个 Map 中返回。</p><p>这里的标准属性源指的是 <code>StandardEnvironment</code> 和 <code>StandardServletEnvironment</code>，前者会注册系统变量（System Properties）和环境变量（System Environment），后者会注册 Servlet 环境下的 Servlet Context 和 Servlet Config 的初始参数（Init Params）和 JNDI 的属性。个人理解是因为这些属性无法改变，所以不进行刷新。</p><p>第二步 <code>addConfigFilesToEnvironment</code> 是核心逻辑，它创建了一个新的 Spring Boot 应用并初始化：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SpringApplicationBuilder builder = new SpringApplicationBuilder(Empty.class)</span><br><span class="line">    .bannerMode(Banner.Mode.OFF).web(false).environment(environment);</span><br><span class="line">// Just the listeners that affect the environment (e.g. excluding logging</span><br><span class="line">// listener because it has side effects)</span><br><span class="line">builder.application()</span><br><span class="line">    .setListeners(</span><br><span class="line">        Arrays.asList(new BootstrapApplicationListener(),</span><br><span class="line">            new ConfigFileApplicationListener()));</span><br><span class="line">capture = builder.run();</span><br></pre></td></tr></table></figure><p>这个应用只是为了重新加载一遍属性源，所以只配置了 <code>BootstrapApplicationListener</code> 和 <code>ConfigFileApplicationListener</code>，最后将新加载的属性源替换掉原属性源，至此属性源本身已经完成更新了。</p><p>此时属性源虽然已经更新了，但是配置项都已经注入到了对应的 Spring Bean 中，需要重新进行绑定，所以又触发了两个操作：</p><ol><li><p>将刷新后发生更改的 Key 收集起来，发送一个 <code>EnvironmentChangeEvent</code> 事件。</p></li><li><p>调用 <code>RefreshScope.refreshAll</code> 方法。</p></li></ol><h1 id="EnvironmentChangeEvent"><a href="#EnvironmentChangeEvent" class="headerlink" title="EnvironmentChangeEvent"></a>EnvironmentChangeEvent</h1><p>在上文中，<code>ContextRefresher</code> 发布了一个 <code>EnvironmentChangeEvent</code> 事件，接下来看看这个事件产生了哪些影响。</p><blockquote><p>The application will listen for an EnvironmentChangeEvent and react to the change in a couple of standard ways (additional ApplicationListeners can be added as @Beans by the user in the normal way). When an EnvironmentChangeEvent is observed it will have a list of key values that have changed, and the application will use those to:</p><ol><li><p>Re-bind any @ConfigurationProperties beans in the context</p></li><li><p>Set the logger levels for any properties in logging.level.*</p></li></ol></blockquote><p>官方文档的介绍中提到，这个事件主要会触发两个行为：</p><ol><li>重新绑定上下文中所有使用了 <code>@ConfigurationProperties</code> 注解的 Spring Bean。</li><li>如果 <code>logging.level.*</code> 配置发生了改变，重新设置日志级别。</li></ol><p>这两段逻辑分别可以在 <code>ConfigurationPropertiesRebinder</code> 和 <code>LoggingRebinder</code> 中看到。</p><h2 id="ConfigurationPropertiesRebinder"><a href="#ConfigurationPropertiesRebinder" class="headerlink" title="ConfigurationPropertiesRebinder"></a>ConfigurationPropertiesRebinder</h2><p>这个类乍一看代码量特别少，只需要一个 <code>ConfigurationPropertiesBeans</code> 和一个 <code>ConfigurationPropertiesBindingPostProcessor</code>，然后调用 <code>rebind</code> 每个 Bean 即可。但是这两个对象是从哪里来的呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public void rebind() &#123;</span><br><span class="line">  for (String name : this.beans.getBeanNames()) &#123;</span><br><span class="line">    rebind(name);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ConfigurationPropertiesBeans</code> 需要一个 <code>ConfigurationBeanFactoryMetaData</code>， 这个类逻辑很简单，它是一个 <code>BeanFactoryPostProcessor</code> 的实现，将所有的 Bean 都存在了内部的一个 Map 中。</p><p>而 ConfigurationPropertiesBeans 获得这个 Map 后，会查找每一个 Bean 是否有 <code>@ConfigurationProperties</code> 注解，如果有的话就放到自己的 Map 中。</p><p>绕了一圈好不容易拿到所有需要重新绑定的 Bean 后，绑定的逻辑就要简单许多了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public boolean rebind(String name) &#123;</span><br><span class="line">  if (!this.beans.getBeanNames().contains(name)) &#123;</span><br><span class="line">    return false;</span><br><span class="line">  &#125;</span><br><span class="line">  if (this.applicationContext != null) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      Object bean = this.applicationContext.getBean(name);</span><br><span class="line">      if (AopUtils.isCglibProxy(bean)) &#123;</span><br><span class="line">        bean = getTargetObject(bean);</span><br><span class="line">      &#125;</span><br><span class="line">      this.binder.postProcessBeforeInitialization(bean, name);</span><br><span class="line">      this.applicationContext.getAutowireCapableBeanFactory()</span><br><span class="line">          .initializeBean(bean, name);</span><br><span class="line">      return true;</span><br><span class="line">    &#125;</span><br><span class="line">    catch (RuntimeException e) &#123;</span><br><span class="line">      this.errors.put(name, e);</span><br><span class="line">      throw e;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 <code>postProcessBeforeInitialization</code> 方法将 Bean 重新绑定了所有属性，并做了校验等操作。</p><p>而 <code>initializeBean</code> 的实现如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123;</span><br><span class="line">  Object wrappedBean = bean;</span><br><span class="line">  if(mbd == null || !mbd.isSynthetic()) &#123;</span><br><span class="line">    wrappedBean = this.applyBeanPostProcessorsBeforeInitialization(bean, beanName);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  try &#123;</span><br><span class="line">    this.invokeInitMethods(beanName, wrappedBean, mbd);</span><br><span class="line">  &#125; catch (Throwable var6) &#123;</span><br><span class="line">    throw new BeanCreationException(mbd != null?mbd.getResourceDescription():null, beanName, &quot;Invocation of init method failed&quot;, var6);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  if(mbd == null || !mbd.isSynthetic()) &#123;</span><br><span class="line">    wrappedBean = this.applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  return wrappedBean;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中主要做了三件事：</p><ol><li><code>applyBeanPostProcessorsBeforeInitialization</code>：调用所有 <code>BeanPostProcessor</code> 的 <code>postProcessBeforeInitialization</code> 方法。</li><li><code>invokeInitMethods</code>：如果 Bean 继承了 <code>InitializingBean</code>，执行 <code>afterPropertiesSet</code> 方法，或是如果 Bean 指定了 <code>init-method</code> 属性，如果有则调用对应方法</li><li><code>applyBeanPostProcessorsAfterInitialization</code>：调用所有 <code>BeanPostProcessor</code> 的 <code>postProcessAfterInitialization</code> 方法。</li></ol><p>之后 <code>ConfigurationPropertiesRebinder</code> 就完成整个重新绑定流程了。</p><h2 id="LoggingRebinder"><a href="#LoggingRebinder" class="headerlink" title="LoggingRebinder"></a>LoggingRebinder</h2><p>相比之下 <code>LoggingRebinder</code> 的逻辑要简单许多，它只是调用了 <code>LoggingSystem</code> 的方法重新设置了日志级别，具体逻辑就不在本文详述了。</p><h1 id="RefreshScope"><a href="#RefreshScope" class="headerlink" title="RefreshScope"></a>RefreshScope</h1><p>首先看看这个类的注释：</p><blockquote><p>Note that all beans in this scope are <em>only</em> initialized when first accessed, so the scope forces lazy initialization semantics. The implementation involves creating a proxy for every bean in the scope, so there is a flag</p><p>If a bean is refreshed then the next time the bean is accessed (i.e. a method is executed) a new instance is created. All lifecycle methods are applied to the bean instances, so any destruction callbacks that were registered in the bean factory are called when it is refreshed, and then the initialization callbacks are invoked as normal when the new instance is created. A new bean instance is created from the original bean definition, so any externalized content (property placeholders or expressions in string literals) is re-evaluated when it is created.</p></blockquote><p>这里提到了两个重点：</p><ol><li>所有 <code>@RefreshScope</code> 的 Bean 都是延迟加载的，只有在第一次访问时才会初始化</li><li>刷新 Bean 也是同理，下次访问时会创建一个新的对象</li></ol><p>再看一下方法实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public void refreshAll() &#123;</span><br><span class="line">  super.destroy();</span><br><span class="line">  this.context.publishEvent(new RefreshScopeRefreshedEvent());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个类中有一个成员变量 <code>cache</code>，用于缓存所有已经生成的 Bean，在调用 <code>get</code> 方法时尝试从缓存加载，如果没有的话就生成一个新对象放入缓存，并通过 <code>getBean</code> 初始化其对应的 Bean：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public Object get(String name, ObjectFactory&lt;?&gt; objectFactory) &#123;</span><br><span class="line">  if (this.lifecycle == null) &#123;</span><br><span class="line">    this.lifecycle = new StandardBeanLifecycleDecorator(this.proxyTargetClass);</span><br><span class="line">  &#125;</span><br><span class="line">  BeanLifecycleWrapper value = this.cache.put(name,</span><br><span class="line">      new BeanLifecycleWrapper(name, objectFactory, this.lifecycle));</span><br><span class="line">  try &#123;</span><br><span class="line">    return value.getBean();</span><br><span class="line">  &#125;</span><br><span class="line">  catch (RuntimeException e) &#123;</span><br><span class="line">    this.errors.put(name, e);</span><br><span class="line">    throw e;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以在销毁时只需要将整个缓存清空，下次获取对象时自然就可以重新生成新的对象，也就自然绑定了新的属性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public void destroy() &#123;</span><br><span class="line">  List&lt;Throwable&gt; errors = new ArrayList&lt;Throwable&gt;();</span><br><span class="line">  Collection&lt;BeanLifecycleWrapper&gt; wrappers = this.cache.clear();</span><br><span class="line">  for (BeanLifecycleWrapper wrapper : wrappers) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      wrapper.destroy();</span><br><span class="line">    &#125;</span><br><span class="line">    catch (RuntimeException e) &#123;</span><br><span class="line">      errors.add(e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  if (!errors.isEmpty()) &#123;</span><br><span class="line">    throw wrapIfNecessary(errors.get(0));</span><br><span class="line">  &#125;</span><br><span class="line">  this.errors.clear();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>清空缓存后，下次访问对象时就会重新创建新的对象并放入缓存了。</p><p>而在清空缓存后，它还会发出一个 <code>RefreshScopeRefreshedEvent</code> 事件，在某些 Spring Cloud 的组件中会监听这个事件并作出一些反馈。</p><h2 id="Zuul"><a href="#Zuul" class="headerlink" title="Zuul"></a>Zuul</h2><p>Zuul 在收到这个事件后，会将自身的路由设置为 dirty 状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">private static class ZuulRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">  @Autowired</span><br><span class="line">  private ZuulHandlerMapping zuulHandlerMapping;</span><br><span class="line">  </span><br><span class="line">  @Override</span><br><span class="line">  public void onApplicationEvent(ApplicationEvent event) &#123;</span><br><span class="line">    if (event instanceof ContextRefreshedEvent</span><br><span class="line">        || event instanceof RefreshScopeRefreshedEvent</span><br><span class="line">        || event instanceof RoutesRefreshedEvent) &#123;</span><br><span class="line">      this.zuulHandlerMapping.setDirty(true);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>并且当路由实现为 <code>RefreshableRouteLocator</code>  时，会尝试刷新路由：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public void setDirty(boolean dirty) &#123;</span><br><span class="line">  this.dirty = dirty;</span><br><span class="line">  if (this.routeLocator instanceof RefreshableRouteLocator) &#123;</span><br><span class="line">    ((RefreshableRouteLocator) this.routeLocator).refresh();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当状态为 dirty 时，Zuul 会在下一次接受请求时重新注册路由，以更新配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if (this.dirty) &#123;</span><br><span class="line">  synchronized (this) &#123;</span><br><span class="line">    if (this.dirty) &#123;</span><br><span class="line">      registerHandlers();</span><br><span class="line">      this.dirty = false;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Eureka"><a href="#Eureka" class="headerlink" title="Eureka"></a>Eureka</h2><p>在 Eureka 收到该事件时，对于客户端和服务端都有不同的处理方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">protected static class EurekaClientConfigurationRefresher &#123;</span><br><span class="line"></span><br><span class="line">  @Autowired(required = false)</span><br><span class="line">  private EurekaClient eurekaClient;</span><br><span class="line"></span><br><span class="line">  @Autowired(required = false)</span><br><span class="line">  private EurekaAutoServiceRegistration autoRegistration;</span><br><span class="line"></span><br><span class="line">  @EventListener(RefreshScopeRefreshedEvent.class)</span><br><span class="line">  public void onApplicationEvent(RefreshScopeRefreshedEvent event) &#123;</span><br><span class="line">    //This will force the creation of the EurkaClient bean if not already created</span><br><span class="line">    //to make sure the client will be reregistered after a refresh event</span><br><span class="line">    if(eurekaClient != null) &#123;</span><br><span class="line">      eurekaClient.getApplications();</span><br><span class="line">    &#125;</span><br><span class="line">    if (autoRegistration != null) &#123;</span><br><span class="line">      // register in case meta data changed</span><br><span class="line">      this.autoRegistration.stop();</span><br><span class="line">      this.autoRegistration.start();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于客户端来说，只是调用了下 <code>eurekaClient.getApplications</code>，理论上这个方法是没有任何效果的，但是查看上面的注释，以及联想到 <code>RefreshScope</code> 的延时初始化特性，这个方法调用应该只是为了强制初始化新的 <code>EurekaClient</code>。</p><p>事实上这里很有趣的是，在 <code>EurekaClientAutoConfiguration</code> 中，实际为了 <code>EurekaClient</code> 提供了两种初始化方案，分别对应是否有 <code>RefreshScope</code>，所以以上的猜测应该是正确的。</p><p>而对于服务端来说，<code>EurekaAutoServiceRegistration</code> 会将服务端先标记为下线，在进行重新上线。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，Spring Cloud 的热更新流程就到此结束了，从这些源码中可以总结出以下结论：</p><ol><li>通过使用 <code>ContextRefresher</code> 可以进行手动的热更新，而不需要依靠 Bus 或是 Endpoint。</li><li>热更新会对两类 Bean 进行配置刷新，一类是使用了 <code>@ConfigurationProperties</code> 的对象，另一类是使用了 <code>@RefreshScope</code> 的对象。</li><li>这两种对象热更新的机制不同，前者在同一个对象中重新绑定了所有属性，后者则是利用了 <code>RefreshScope</code> 的缓存和延迟加载机制，生成了新的对象。</li><li>通过自行监听 <code>EnvironmentChangeEvent</code> 事件，也可以获得更改的配置项，以便实现自己的热更新逻辑。</li><li>在使用 Eureka 的项目中要谨慎的使用热更新，过于频繁的更新可能会使大量项目频繁的标记下线和上线，需要注意。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作为一篇源码分析的文章，本文虽然介绍 Spring Cloud 的热更新机制，但是实际全文内容都不会与 Spring Cloud Config 以及 Spring Cloud Bus 有关，因为前者只是提供了一个远端的配置源，而后者也只是提供了集群环境下的事件触发机制，与核心流程均无太大关系。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>聊聊 API Gateway 和 Netflix Zuul</title>
    <link href="http://www.scienjus.com/api-gateway-and-netflix-zuul/"/>
    <id>http://www.scienjus.com/api-gateway-and-netflix-zuul/</id>
    <published>2017-05-30T05:03:21.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近参与了公司 API Gateway 的搭建工作，技术选型是 Netflix Zuul，主要聊一聊其中的一些心得和体会。</p><a id="more"></a><p>本文主要是介绍使用 Zuul 且在不强制使用其他 Neflix OSS 组件时，如何搭建生产环境的 Gateway，以及能使用 Gateway 做哪些事。不打算介绍任何关于如何快速搭建 Zuul，或是一些轻易集成 Eureka 之类的的方法，这些在官方文档上已经介绍的很明确了。</p><h1 id="API-Gateway"><a href="#API-Gateway" class="headerlink" title="API Gateway"></a>API Gateway</h1><p>API Gateway 是随着微服务（Microservice）这个概念一起兴起的一种架构模式，它用于解决微服务过于分散，没有一个统一的出入口进行流量管理的问题。</p><p>用 Kong 官网的两张图来解释再合适不过。</p><p><img src="https://getkong.org/assets/images/homepage/diagram-left.png" alt="分散的 API 管理"></p><p>当使用微服务构建整个 API 服务时，一般会有许许多多职责不同的应用在运行着，这些应用会需要一些通用的功能，例如鉴权、流控、监控、日志统计。</p><p>在传统的单体应用中，这些功能一般都是内嵌在应用中，作为一个组件运行。但是在微服务模式下，不同种类且独立运行的应用可能会有数十甚至数百种，继续使用这种方式会造成非常高的管理和发布成本。所以就需要在这些应用上抽象出一个统一的流量入口，完成这些功能的实现。</p><p><img src="https://getkong.org/assets/images/homepage/diagram-right.png" alt="统一的 API 管理"></p><p>在我看来，API Gateway 的职责主要分为两部分：</p><ol><li>对服务应用有感知且重要的功能，例如鉴权。</li><li>对服务应用无感知的边缘服务，例如流控、监控、页面级缓存等。</li></ol><h1 id="Netflix-Zuul"><a href="#Netflix-Zuul" class="headerlink" title="Netflix Zuul"></a>Netflix Zuul</h1><p>对于 API Gateway，常见的选型有基于 Openresty 的 Kong、基于 Go 的 Tyk 和基于 Java 的 Zuul。</p><p>这三个选型本身没有什么明显的区别，主要还是看技术栈是否能满足快速应用和二次开发，例如我司原有的技术栈就是使用 Go/Openresty 的平台组和使用 Java 的后端组，讨论后觉得 API Gateway 未来还是处理业务功能的场景更多些，而且后端这边有很多功能可以直接移植过来，最终就选择了 Zuul。</p><p>关于 Zuul，大部分使用 Java 做微服务的人可能都会或多或少了解 Spring Cloud 和 Netflix 全家桶。而对于完全不了解的人，可以暂时将它想象为一个类似于 Servlet 中过滤器（Filter）的概念。</p><p><img src="https://camo.githubusercontent.com/4eb7754152028cdebd5c09d1c6f5acc7683f0094/687474703a2f2f6e6574666c69782e6769746875622e696f2f7a75756c2f696d616765732f7a75756c2d726571756573742d6c6966656379636c652e706e67" alt="Zuul"></p><p>就像上图中所描述的一样，Zuul 提供了四种过滤器的 API，分别为前置（Pre）、后置（Post）、路由（Route）和错误（Error）四种处理方式。</p><p>一个请求会先按顺序通过所有的前置过滤器，之后在路由过滤器中转发给后端应用，得到响应后又会通过所有的后置过滤器，最后响应给客户端。在整个流程中如果发生了异常则会跳转到错误过滤器中。</p><p>一般来说，如果需要在请求到达后端应用前就进行处理的话，会选择前置过滤器，例如鉴权、请求转发、增加请求参数等行为。在请求完成后需要处理的操作放在后置过滤器中完成，例如统计返回值和调用时间、记录日志、增加跨域头等行为。路由过滤器一般只需要选择 Zuul 中内置的即可，错误过滤器一般只需要一个，这样可以在 Gateway 遇到错误逻辑时直接抛出异常中断流程，并直接统一处理返回结果。</p><h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>以下介绍一些 Zuul 中不同过滤器的应用场景。</p><h2 id="前置过滤器"><a href="#前置过滤器" class="headerlink" title="前置过滤器"></a>前置过滤器</h2><h3 id="鉴权"><a href="#鉴权" class="headerlink" title="鉴权"></a>鉴权</h3><p>一般来说整个服务的鉴权逻辑可以很复杂。</p><ul><li>客户端：App、Web、Backend</li><li>权限组：用户、后台人员、其他开发者</li><li>实现：OAuth、JWT</li><li>使用方式：Token、Cookie、SSO</li></ul><p>而对于后端应用来说，它们其实只需要知道请求属于谁，而不需要知道为什么，所以 Gateway 可以友善的帮助后端应用完成鉴权这个行为，并将用户的唯一标示透传到后端，而不需要、甚至不应该将身份信息也传递给后端，防止某些应用利用这些敏感信息做错误的事情。</p><p>Zuul 默认情况下在处理后会删除请求的 <code>Authorization</code> 头和 <code>Set-Cookie</code> 头，也算是贯彻了这个原则。</p><h3 id="流量转发"><a href="#流量转发" class="headerlink" title="流量转发"></a>流量转发</h3><p>流量转发的含义就是将指向 <code>/a/xxx.json</code> 的请求转发到指向 <code>/b/xxx.json</code> 的请求。这个功能可能在一些项目迁移、或是灰度发布上会有一些用处。</p><p>在 Zuul 中并没有一个很好的办法去修改 Request URI。在某些 <a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/435" target="_blank" rel="external">Issue</a> 中开发者会建议设置 <code>requestURI</code> 这个属性，但是实际在 Zuul 自身的 <code>PreDecorationFilter</code> 流程中又会被覆盖一遍。</p><p>不过对于一个基于 Servlet 的应用，使用 <code>HttpServletRequestWrapper</code> 基本可以解决一切问题，在这个场景中只需要重写其 <code>getRequestURI</code> 方法即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class RewriteURIRequestWrapper extends HttpServletRequestWrapper &#123;</span><br><span class="line"></span><br><span class="line">  private String rewriteURI;</span><br><span class="line"></span><br><span class="line">  public RewriteURIRequestWrapper(HttpServletRequest request, String rewriteURI) &#123;</span><br><span class="line">    super(request);</span><br><span class="line">    this.rewriteURI = rewriteURI;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">  public String getRequestURI() &#123;</span><br><span class="line">    return rewriteURI;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="后置过滤器"><a href="#后置过滤器" class="headerlink" title="后置过滤器"></a>后置过滤器</h2><h3 id="跨域"><a href="#跨域" class="headerlink" title="跨域"></a>跨域</h3><p>使用 Gateway 做跨域相比应用本身或是 Nginx 的好处是规则可以配置的更加灵活。例如一个常见的规则。</p><ol><li>对于任意的 AJAX 请求，返回 <code>Access-Control-Allow-Origin</code> 为 <code>*</code>，且 <code>Access-Control-Allow-Credentials</code> 为 <code>true</code>，这是一个常用的允许任意源跨域的配置，但是不允许请求携带任何 Cookie</li><li>如果一个被信任的请求者需要携带 Cookie，那么将它的 <code>Origin</code> 增加到白名单中。对于白名单中的请求，返回 <code>Access-Control-Allow-Origin</code> 为该域名，且 <code>Access-Control-Allow-Credentials</code> 为 <code>true</code>，这样请求者可以正常的请求接口，同时可以在请求接口时携带 Cookie</li><li>对于 302 的请求，即使在白名单内也必须要设置 <code>Access-Control-Allow-Origin</code> 为 <code>*</code>，否则重定向后的请求携带的 <code>Origin</code> 会为 <code>null</code>，有可能会导致 iOS 低版本的某些兼容问题</li></ol><h3 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h3><p>Gateway 可以统一收集所有应用请求的记录，并写入日志文件或是发到监控系统，相比 Nginx 的 access log，好处主要也是二次开发比较方便，比如可以关注一些业务相关的 HTTP 头，或是将请求参数和返回值都保存为日志打入消息队列中，便于线上故障调试。也可以收集一些性能指标发送到类似 Statsd 这样的监控平台。</p><h2 id="错误过滤器"><a href="#错误过滤器" class="headerlink" title="错误过滤器"></a>错误过滤器</h2><p>错误过滤器的主要用法就像是 Jersey 中的 <code>ExceptionMapper</code> 或是 Spring MVC 中的 <code>@ExceptionHandler</code> 一样，在处理流程中认为有问题时，直接抛出统一的异常，错误过滤器捕获到这个异常后，就可以统一的进行返回值的封装，并直接结束该请求。</p><h1 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h1><p>虽然将这些逻辑都切换到了 Gateway，省去了很多维护和迭代的成本，但是也面临着一个很大的问题，就是 Gateway 只有逻辑却没有配置，它并不知道一个请求要走哪些流程。</p><p>例如同样是后端服务 API，有的可能是给网页版用的、有的是给客户端用的，亦或是有的给用户用、有的给管理人员用，那么 Gateway 如何知道到底这些 API 是否需要登录、流控以及缓存呢？</p><p>理论上我们可以为 Gateway 编写一个管理后台，里面有当前服务的所有 API，每一个开发者都可以在里面创建新的 API，以及为它增加鉴权、缓存、跨域等功能。为了简化使用，也许我们会额外的增加一个权限组，例如 <code>/admin/*</code> 下的所有 API 都应该为后台接口，它只允许内部来源的鉴权访问。</p><p>但是这样做依旧太复杂了，而且非常硬编码，当开发者开发了一个新的 API 之后，即使这个应用已经能正常接收特定 URI 的请求并处理之后，却还要通过人工的方式去一个管理后台进行额外的配置，而且可能会因为不谨慎打错了路径中的某个单词而造成不必要的事故，这都是不合理的。</p><p>我个人推荐的做法是，在后端应用中依旧保持配置的能力，即使应用里已经没有真实处理的逻辑了。例如在 Java 中通过注解声明式的编写 API，且在应用启动时自动注册 Gateway 就是一种比较好的选择。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 这个接口需要鉴权，鉴权方式是 OAuth</span><br><span class="line"> */</span><br><span class="line">@Authorization(OAuth)</span><br><span class="line">@RequestMapping(value = &quot;/users/&#123;id&#125;&quot;, method = RequestMethod.DELETE)</span><br><span class="line">public void del(@PathVariable int id) &#123;</span><br><span class="line">  //...  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 这个接口可以缓存，并且每个 IP/User 每秒最多请求 10 次</span><br><span class="line"> */</span><br><span class="line">@Cacheable</span><br><span class="line">@RateLimiting(limit = &quot;10/1s&quot;, scope = &#123;IP, USER&#125;)</span><br><span class="line">@RequestMapping(value = &quot;/users/&#123;id&#125;&quot;, method = RequestMethod.GET)</span><br><span class="line">public void info(@PathVariable int id) &#123;</span><br><span class="line">  //...  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样 API 的编写者就会根据业务场景考虑该 API 需要哪些功能，也减少了管理的复杂度。</p><p>除此之外还会有一些后端应用无关的配置，有些是自动化的，例如恶意请求拦截，Gateway 会将所有请求的信息通过消息队列发送给一些实时数据分析的应用，这些应用会对请求分析，发现恶意请求的特征，并通过 Gateway 提供的接口将这些特征上报给 Gateway，Gateway 就可以实时的对这些恶意请求进行拦截。</p><h1 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h1><p>在 Nginx 和后端应用之间又建立了一个 Java 应用作为流量入口，很多人会去担心它的稳定性，亦或是担心它能否像 Nginx 一样和后端的多个 upstream 进行交互，以下主要介绍一下 Zuul 的隔离机制以及重试机制。</p><h2 id="隔离机制"><a href="#隔离机制" class="headerlink" title="隔离机制"></a>隔离机制</h2><p>在微服务的模式下，应用之间的联系变得没那么强烈，理想中任何一个应用超过负载或是挂掉了，都不应该去影响到其他应用。但是在 Gateway 这个层面，有没有可能出现一个应用负载过重，导致将整个 Gateway 都压垮了，已致所有应用的流量入口都被切断？</p><p>这当然是有可能的，想象一个每秒会接受很多请求的应用，在正常情况下这些请求可能在 10 毫秒之内就能正常响应，但是如果有一天它出了问题，所有请求都会 Block 到 30 秒超时才会断开（例如频繁 Full GC 无法有效释放内存）。那么在这个时候，Gateway 中也会有大量的线程在等待请求的响应，最终会吃光所有线程，导致其他正常应用的请求也受到影响。</p><p>在 Zuul 中，每一个后端应用都称为一个 Route，为了避免一个 Route 抢占了太多资源影响到其他 Route 的情况出现，Zuul 使用 Hystrix 对每一个 Route 都做了隔离和限流。</p><p>Hystrix 的隔离策略有两种，基于线程或是基于信号量。Zuul 默认的是基于线程的隔离机制，这意味着每一个 Route 的请求都会在一个固定大小且独立的线程池中执行，这样即使其中一个 Route 出现了问题，也只会是某一个线程池发生了阻塞，其他 Route 不会受到影响。</p><p>一般使用 Hystrix 时，只有调用量巨大会受到线程开销影响时才会使用信号量进行隔离策略，对于 Zuul 这种网络请求的用途使用线程隔离更加稳妥。</p><h2 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h2><p>一般来说，后端应用的健康状态是不稳定的，应用列表随时会有修改，所以 Gateway 必须有足够好的容错机制，能够减少后端应用变更时造成的影响。</p><p>Zuul 的路由主要有 Eureka 和 Ribbon 两种方式，由于我一直使用的都是 Ribbon，所以简单介绍下 Ribbon 支持哪些容错配置。</p><p>重试的场景分为三种：</p><ul><li><code>okToRetryOnConnectErrors</code>：只重试网络错误</li><li><code>okToRetryOnAllErrors</code>：重试所有错误</li><li><code>OkToRetryOnAllOperations</code>：重试所有操作（这里不太理解，猜测是 GET/POST 等请求都会重试）</li></ul><p>重试的次数有两种：</p><ul><li><code>MaxAutoRetries</code>：每个节点的最大重试次数</li><li><code>MaxAutoRetriesNextServer</code>：更换节点重试的最大次数</li></ul><p>一般来说我们希望只在网络连接失败时进行重试、或是对 5XX 的 GET 请求进行重试（不推荐对 POST 请求进行重试，无法保证幂等性会造成数据不一致）。单台的重试次数可以尽量小一些，重试的节点数尽量多一些，整体效果会更好。</p><p>如果有更加复杂的重试场景，例如需要对特定的某些 API、特定的返回值进行重试，那么也可以通过实现 <code>RequestSpecificRetryHandler</code> 定制逻辑（不建议直接使用 <code>RetryHandler</code>，因为这个子类可以使用很多已有的功能）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近参与了公司 API Gateway 的搭建工作，技术选型是 Netflix Zuul，主要聊一聊其中的一些心得和体会。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>文档化 Apache Thrift</title>
    <link href="http://www.scienjus.com/document-apache-thrift/"/>
    <id>http://www.scienjus.com/document-apache-thrift/</id>
    <published>2017-05-14T05:03:21.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 RPC 选型中，相较于最基础的 HTTP/JSON API，基于 IDL 约束的 Thrift 在跨语言、序列化性能上占有很多优势。但是在实际使用中由于无法享受 HTTP 丰富的资源库，也带来了不少困扰，其中一个比较常见的麻烦问题就是 IDL 的共享以及协议迭代。</p><a id="more"></a><h1 id="IDL-共享的问题"><a href="#IDL-共享的问题" class="headerlink" title="IDL 共享的问题"></a>IDL 共享的问题</h1><p>一般在相同语言的多个项目中如何共享 IDL 呢？</p><p>在我们大部分的 Java 项目中，服务提供方都会定义一个 <code>$project-api</code> 的模块，专门用来放给其他项目调用相关类，其中自然也包括了 Thrift IDL 生成后的类。我们甚至会在 <code>Thrift.Iface/Client</code> 上再包一层自己实现的 Client，使整个接口定义与 Thrift 这个实现方案彻底无关，即使未来有一天我们将通讯协议换成了其他方案（HTTP/gRPC），使用方也只需要更新一下依赖版本，而不需要改任何代码。</p><p>而在多语言的项目中又该如何共享 IDL 呢？</p><p>一般的 RPC 服务会存在一个 Service 和多个 Client，在我们开发的 Python 和 Java 项目中，除了 Java Client 使用 Java Service 可以用上述的方式直接共享生成后的 class 文件，其他使用方式都需要将 IDL 文件放入项目源码中，这样就会导致一份 IDL 会存在与多个项目中，而随着项目的迭代，很难做到所有项目之间的版本是相同的，混乱由此而生。而 Thrift 序列化的高效只建立在 Field Id 作为序列化索引实现的基础上，一旦 Field Id 出现了不一致，就会出现很难排查的数据丢失问题。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>面对这个问题，核心诉求就是希望 IDL 可以只存一份，并对所有项目共享（而不仅仅是通过 Java/Maven 的方式在部分语言中共享）。</p><p>使用 Git 子模块是一个很简单的解决方案，但是我很难认同这种做法，大多数情况下它增加了普通项目管理的复杂度，如果目前服务的调用方都是 Java，那么我们根本不需要这种方式，而如果有一天一个新的 Python 项目需要接入了，Service 就需要把 IDL 放到一个子模块中，那么之前的那些 Java 项目要不要也跟着进行修改？其实修改是无意义的，但是不修改又会造成多个项目之间管理的不统一。</p><p>另一种方式是单独使用一个仓库存放 IDL 文件，在发生变更的时候去触发所有语言的构建和包管理，例如打一个 Java 包上传到 Maven、生成一些 Python 文件放到 pip（虽然 Python 的 thriftpy 已经强大到不需要任何依赖就可以直接在运行时读取并解析 IDL 文件了）。</p><p>我个人认为理想的解决方案是不在任何项目中直接引用 IDL 文件，而是引用其被托管的一个网络地址（如果你了解 Java，应该会联想到 Spring Cloud Config）。当 Java 或 Python 项目<br>构建时可以选择性的去拉取变更的 IDL 文件，和上面的区别主要就是 Push 和 Pull 的区别，而且不需要为了几个文件去发一个个依赖包。</p><p>比较遗憾的是：这种做法在 Gradle 中或许只是几行代码的事情，而在 Maven 中却需要额外的添加自定义插件或是去魔改 Maven Thrift Plugin，而前者依旧会增加项目的复杂度，后者的话我连这个插件的源码托管在何处都不知道。</p><h1 id="文档化"><a href="#文档化" class="headerlink" title="文档化"></a>文档化</h1><p>回到问题的源头，我们究竟为什么希望所有项目中共享的 IDL 完全同步？</p><p>IDL 不同步带来的最坏结果就是由序列化/反序列化无法对应导致的字段丢失或是报错，其次是可能出现服务升级后提供新的 API 无法有效地通知调用方升级。</p><p>而这些在 HTTP/JSON 服务中也会出现，而且其没有任何强约束办法，只能通过 Swagger 这类文档工具进行信息同步。换言之，对于一个能够做好向后兼容的服务来说（当然这也是一个服务的最基本要求），调用方的所有更新都应该是可选的，我们只需要一个平台去展示每一个版本的 IDL 和其描述信息（文档）。</p><h1 id="实施"><a href="#实施" class="headerlink" title="实施"></a>实施</h1><h2 id="Armeria"><a href="#Armeria" class="headerlink" title="Armeria"></a>Armeria</h2><p><a href="https://github.com/line/armeria" target="_blank" rel="external">Armeria</a> 由 Netty 作者 Trustin Lee 开发的 RPC 框架，也是我目前知道的唯一可以将 Thrift 生成文档的框架。</p><p>但是由于一些坑，我们无法直接使用 Armeria 生成整套文档</p><h3 id="Thrift-Java-Compiler-的坑"><a href="#Thrift-Java-Compiler-的坑" class="headerlink" title="Thrift Java Compiler 的坑"></a>Thrift Java Compiler 的坑</h3><p>Thrift Java Compiler 本身的有一个 Bug，当 IDL 中 Struct 没有严格按照使用顺序定义时，生成的 class 文件中的 <code>FieldMetaData</code> 是错误的。</p><p>例如一个 IDL 正确的顺序应该如下：</p><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="number">1</span>:<span class="built_in">i64</span> id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span> </span>&#123;</span><br><span class="line">  <span class="number">1</span>:A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在某些语言的 Thrift Compiler 实现中，因为 B 引用了 A，所以定义顺序必须是 A 在 B 前面（例如 thriftpy 就强制要求，否则会解析错误）。</p><p>但是在 Java 中却可以将 A 定义在 B 之后，而且使用时完全没有任何问题。直到我们开始用 FieldMetaData 去生成文档。</p><p>在正常顺序下生成的 B.class 当中 A 的 FieldMetaData 为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmpMap.put(B._Fields.A, new FieldMetaData(&quot;a&quot;, (byte)3, new StructMetaData((byte)12, A.class)));</span><br></pre></td></tr></table></figure><p>它正确的使用了 <code>StructMetaData</code> 并引用到了 A.class，这样我们就可以找到这个字段相关的 Struct。</p><p>但是如果顺序是错误的，将 A 定义在了 B 的后面，生成的 FieldMetaData 为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmpMap.put(B._Fields.A, new FieldMetaData(&quot;a&quot;, (byte)3, new FieldValueMetaData((byte)12, &quot;A&quot;)));</span><br></pre></td></tr></table></figure><p>可以看到 <code>StructMetaData</code> 变成了 <code>FieldValueMetaData</code>，并且丢失了 Class 信息。</p><h3 id="扩展性问题"><a href="#扩展性问题" class="headerlink" title="扩展性问题"></a>扩展性问题</h3><p>Armeria 的文档系统是建立在其基础方案之上的，这意味着如果你本身就使用其作为 RPC 框架，那么生成文档只需要额外的加一个 <code>DocService</code> 即可。并且它还能直接在文档页面中通过 <a href="https://github.com/line/armeria/blob/master/thrift/src/main/java/com/linecorp/armeria/common/thrift/text/TTextProtocol.java" target="_blank" rel="external">TText</a> 的协议方式直接进行在线调用。</p><p>但是我目前所使用的系统并没有直接使用 Armeria，而是内部通过 Etcd 实现的 Thrift 服务注册与发现，这样使得不光没办法使用自带的在线调用功能，连生成文档界面都需要额外引入 Thrift 相关类并将空实现注册到 Armeria，整个系统能直接用到的功能非常少。</p><h2 id="thriftpy"><a href="#thriftpy" class="headerlink" title="thriftpy"></a>thriftpy</h2><p>如果你之前了解过 Swagger（一个 HTTP 文档的协议规范），你应该能明白一个良好的文档工具最重要的就是 Schema，它能够将生成程序和页面渲染程序直接解耦，方便对已有组件进行改造和复用。</p><p>很幸运的是，Armeria 就拥有一套用来描述 Thrift API 的 Schema。这样我们可以不去使用它通过读取 Java class 生成 Schema 的组件，只是用将 Schema 渲染成页面的组件去渲染我们自己生成的 Schema。</p><p>在与 Python 同事联调时，我发现 thriftpy 就可以帮助我生成 Schema，而且实际写下来整个代码逻辑会非常简单，一共只需要不到 100 行便可以完成。</p><p>由于我本身写 Python 很少，代码看上去比较丑陋就不展示了，只是介绍下大概思路：</p><ol><li>通过 <code>thriftpy.load</code> 加载 IDL 生成的模块拥有 <code>__thrift_meta__</code> 属性，可以从中获取这个 IDL 中有哪些 Struct、Service、Enum 和 Exception。</li><li>对于 Struct，通过 <code>thrift_spec</code> 可以拿到所有字段信息，这是个字典，Key 是字段 ID，Val 是一个元祖，包含字段信息。</li><li>字段信息的长度可能为 3 或是 4。是 3 的话值分别为字段类型、名称和是否必须，如果为 4 说明是 List/Set/Map，值分别为字段类型、名称、泛型和是否必须。</li><li>对于 Enum，直接通过 <code>_NAMES_TO_VALUES</code> 就可以拿到所有枚举和值之间的对应关系了。</li><li>对于 Service，需要拿到参数 <code>${service_name}_args</code> 和返回值 <code>${service_name}_result</code>，解析这两个结构基本和解析 Struct 一样。</li><li>Exception 也是一种特殊的 Struct，不再详述。</li></ol><p>当然在使用中也需要魔改部分 thriftpy 的源码，比如在 [Parser][3] 中恢复对 namespace 的执行，并读取的 Java 的 namespace。因为我们在 Etcd 上注册节点就是以 namespace 为路径的，用于查看当前节点或是未来重新支持在线调试都是必不可少的。</p><p>最后整个项目的目录为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">idl/</span><br><span class="line">-- thrift/ # 放 Thrift IDL</span><br><span class="line">-- public/ # 放 Armeria 的静态页面</span><br><span class="line">-- make_docs.py # 读取 thrift 中的文件，生成一个 JSON 文件放到 public 中</span><br></pre></td></tr></table></figure><p>目前我将其托管为了一个 Gitlab Pages 项目，只要该项目由变更（多数为 IDL 修改）就会触发 Ci build 重新生成最新的文档。</p><h1 id="一些思考"><a href="#一些思考" class="headerlink" title="一些思考"></a>一些思考</h1><p>长久以来用 Thrift 积累了很多经验和疑惑，现在个人认为对于一般小公司，如果网络请求还没有成为整个 RPC 调用的性能瓶颈，使用 HTTP/JSON API 可能会更适合一些，毕竟其拥有更多的可扩展能力以及更丰富的生态环境，能够节省很多精力（例如 Java 就可以选择 Netflix 全家桶啊！）。</p><p>比如说一些我曾遇到的使用场景：</p><ol><li>使用分布式链路追踪时，HTTP 协议可以很简单的将 Trace 信息放入 Header 头，而 Thrift 就只能通过去魔改序列化协议达到这个功能。鉴权之类的需要统一带额外信息的场景也是如此。</li><li>错误情况的返回结果 HTTP 拥有 status code，而且 JSON 协议要更加方便，Thrift 最好是自定义 TException，但是这个受检异常在实际代码编写中又会很蛋疼。</li><li>日志，如果做通用的日志，目前只能在反序列化时进行记录，但是字段信息又是写死在 Struct 字节码里的，所以这时候打印的日志是没有字段名的。</li><li>对于 HTTP 请求，监控 200/4xx/5xx 的方案实在是太多了，但是对于 Thrift，监控成功返回、业务方自定义的 TException 和程序中自然抛出的 Runtime Exception 就要麻烦很多。</li></ol><p><del>所以虽然本文的内容是如何更好地使用 Apache Thrift，但是最终要表达的意思却是没遇到性能瓶颈之前，用 HTTP/JSON 可能会更好。</del></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 RPC 选型中，相较于最基础的 HTTP/JSON API，基于 IDL 约束的 Thrift 在跨语言、序列化性能上占有很多优势。但是在实际使用中由于无法享受 HTTP 丰富的资源库，也带来了不少困扰，其中一个比较常见的麻烦问题就是 IDL 的共享以及协议迭代。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>[Functional Programming Principles in Scala] 学习笔记（二） 高阶函数和类</title>
    <link href="http://www.scienjus.com/profun1-week2/"/>
    <id>http://www.scienjus.com/profun1-week2/</id>
    <published>2017-05-01T13:03:21.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>本周主要介绍了 Scala 中的高阶函数和类的相关定义，包含高阶函数和柯里化、类的构造与抽象等内容。</p><a id="more"></a><h1 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h1><p>函数式语言将函数作为一等公民，这意味着函数可以像其他值一样作为参数或是返回值，这种做法提高了程序的灵活性。</p><p>将其他函数作为参数或者返回值的函数被称为高阶函数（Higher Order Functions）。</p><p>一个例子，下面这个方法用于计算两个整数之间的所有整数之和：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumInts</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> =</span><br><span class="line">  <span class="keyword">if</span> (a &gt; b) <span class="number">0</span> <span class="keyword">else</span> a + sumInts(a + <span class="number">1</span>, b)</span><br></pre></td></tr></table></figure><p>另一个方法用于计算两个整数之间的所有整数立方的和：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cube</span></span>(x: <span class="type">Int</span>): <span class="type">Int</span> = x * x * x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumCubes</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> =</span><br><span class="line">  <span class="keyword">if</span> (a &gt; b) <span class="number">0</span> <span class="keyword">else</span> cube(a) + sumCubes(a + <span class="number">1</span>, b)</span><br></pre></td></tr></table></figure><p>还有一个方法用于计算两个整数之间所有整数阶乘的和：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fact</span></span>(x: <span class="type">Int</span>): <span class="type">Int</span> = <span class="keyword">if</span> (x == <span class="number">0</span>) <span class="number">1</span> <span class="keyword">else</span> x * fact(x - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumFactorials</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> =</span><br><span class="line">  <span class="keyword">if</span> (a &gt; b) <span class="number">0</span> <span class="keyword">else</span> fact(a) + sumFactorials(a + <span class="number">1</span>, b)</span><br></pre></td></tr></table></figure><p>可以看出，这三个方法的大部分模式都是相同的，它们都是通过递归获得 a 到 b 的所有整数，通过某个方法进行转换，最后将转换得到的值进行累加。</p><p>那么就可以将这个转换的函数提取成为方法参数：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(f: <span class="type">Int</span> =&gt; <span class="type">Int</span>, a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> =</span><br><span class="line">  <span class="keyword">if</span> (a &gt; b) <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span> f(a) + sum(f, a + <span class="number">1</span>, b)</span><br></pre></td></tr></table></figure><p>使用时在不同的实现中传入不同的函数即可：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">id</span></span>(x: <span class="type">Int</span>): <span class="type">Int</span> = x</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumInts</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>) = sum(id, a, b)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cube</span></span>(x: <span class="type">Int</span>): <span class="type">Int</span> = x * x * x</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumCubes</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>) = sum(cube, a, b)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fact</span></span>(x: <span class="type">Int</span>): <span class="type">Int</span> = <span class="keyword">if</span> (x == <span class="number">0</span>) <span class="number">1</span> <span class="keyword">else</span> x * fact(x - <span class="number">1</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumFactorials</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>) = sum(fact, a, b)</span><br></pre></td></tr></table></figure><p>在 Scala 中， <code>A =&gt; B</code> 代表一个接受一个 <code>A</code> 类型参数，并返回一个 <code>B</code> 类型参数的方法。例如上文中的 <code>Int =&gt; Int</code> 代表将一个整数转换为另一个整数的方法。</p><h1 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h1><p>在使用高阶函数时，不可避免的需要定义很多小函数，但是其实很多时候不需要通过 <code>def</code> 定义函数并为其起一个名字。</p><p>以字符串举例，当需要打印一个常量字符串时，以下的代码是多余的：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">str</span> </span>= <span class="string">"ABC"</span></span><br><span class="line">println(str)</span><br></pre></td></tr></table></figure><p>它可以直接写为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">println(<span class="string">"ABC"</span>)</span><br></pre></td></tr></table></figure><p>就像字符串一样，函数也可以作为一个常量存在，它们被称为匿名函数（Anonymous Functions）。</p><p>上文中 <code>cube</code> 的匿名函数形式为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(x: <span class="type">Int</span>) =&gt; x * x * x</span><br></pre></td></tr></table></figure><p>其中 <code>(x: Int)</code> 是该函数的参数，<code>x * x * x</code> 是该函数的函数体。</p><p>如果函数有多个参数，那么彼此之间需要用 <code>,</code> 分隔，例如：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; x + y</span><br></pre></td></tr></table></figure><p>如果函数的类型可以通过上下文推断得出，那么是可以省略的。</p><p>一个匿名函数 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(x1 : T1, ..., xn : Tn) =&gt; E</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">可以被定义为一个形如</span><br></pre></td></tr></table></figure><p>{ def f(x1 : T1, …, xn : Tn) = E; f }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">的表达式，其中 `f` 是一个任意的未被占用的名称。所以可以把匿名函数当做一个语法糖（Syntactic Sugar）。</span><br><span class="line"></span><br><span class="line">通过匿名函数，上文中的方法又可以进一步简化：</span><br><span class="line"></span><br><span class="line">```scala</span><br><span class="line">def sumInts(a: Int, b: Int) = sum(x =&gt; x, a, b)</span><br><span class="line"></span><br><span class="line">def sumCubes(a: Int, b: Int) = sum(x =&gt; x * x * x, a, b)</span><br></pre></td></tr></table></figure></p><h1 id="柯里化"><a href="#柯里化" class="headerlink" title="柯里化"></a>柯里化</h1><p>再次观察上面的函数，它们是否还有进一步优化的空间？</p><p>在上面的函数实现中，参数 <code>a</code> 和 <code>b</code> 都没有经过任何处理，而是直接传到了 <code>sum</code> 函数中，是否有更好的写法隐藏这些参数呢？</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(f: <span class="type">Int</span> =&gt; <span class="type">Int</span>): (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = &#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sumF</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> =</span><br><span class="line">    <span class="keyword">if</span> (a &gt; b) <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span> f(a) + sumF(a + <span class="number">1</span>, b)</span><br><span class="line">  sumF</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个重写的函数不再接受两个 Int 类型的参数，而是直接将另一个函数作为了返回值，这个返回的函数才接受两个 Int 类型参数，并返回最终的结果。</p><p>上文中的函数定义将会变得更加简单：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumInts</span> </span>= sum(x =&gt; x)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumCubes</span> </span>= sum(x =&gt; x * x * x)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumFactorials</span> </span>= sum(fact)</span><br></pre></td></tr></table></figure><p>甚至可以避免定义这些中间变量，直接通过原始方法调用：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(cube)(<span class="number">1</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>在这当中 <code>sum(cube)</code> 返回了一个计算阶乘之和的方法，它和 <code>sumCubes</code> 是完全一样的，并且可以直接通过紧接着的 <code>(1, 10)</code> 参数调用这个方法。</p><p>在函数中返回另一个函数是非常有用的，为此 Scala 有一种特殊的语法：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(f: <span class="type">Int</span> =&gt; <span class="type">Int</span>)(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> =</span><br><span class="line">  <span class="keyword">if</span> (a &gt; b) <span class="number">0</span> </span><br><span class="line">  <span class="keyword">else</span> f(a) + sum(f)(a + <span class="number">1</span>, b)</span><br></pre></td></tr></table></figure><p>这段方法和上面返回 <code>sumF</code> 的实现几乎是一样的，但是写起来更简洁。</p><p>如果定义了一个含有多个参数列表的方法：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span></span>(args1)...(argsn) = <span class="type">E</span></span><br></pre></td></tr></table></figure><p>它实际等同于：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span></span>(args1)...(argsn−<span class="number">1</span>) = &#123; <span class="function"><span class="keyword">def</span> <span class="title">g</span></span>(argsn) = <span class="type">E</span>; g &#125;</span><br></pre></td></tr></table></figure><p>或是像匿名函数一样：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span></span>(args1)...(argsn−<span class="number">1</span>) =  (argsn ⇒ <span class="type">E</span>)</span><br></pre></td></tr></table></figure><p>往复替换 n 次之后，就会变为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span> </span>= (args1 ⇒ (args2 ⇒ ...(argsn ⇒ <span class="type">E</span>)...)</span><br></pre></td></tr></table></figure><p>这种风格被称为柯里化（Currying）。</p><p>最终定义的 <code>sum</code> 方法的类型为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(<span class="type">Int</span> =&gt; <span class="type">Int</span>) =&gt; (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span></span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">因为函数类型的关联是从右向左的，所以实际等同于：</span><br><span class="line"></span><br><span class="line">```scala</span><br><span class="line">(<span class="type">Int</span> =&gt; <span class="type">Int</span>) =&gt; ((<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span>)</span><br></pre></td></tr></table></figure><h1 id="Scala-语法汇总"><a href="#Scala-语法汇总" class="headerlink" title="Scala 语法汇总"></a>Scala 语法汇总</h1><p>以下定义中所用到的符号的含义为：</p><ul><li><code>|</code> ：替代关系</li><li><code>[...]</code> 0 或 1 个</li><li><code>{...}</code> 0 或 多个</li></ul><h2 id="类型（Types）"><a href="#类型（Types）" class="headerlink" title="类型（Types）"></a>类型（Types）</h2><p><img src="/uploads/types.png" alt="Types"></p><p>类型可以是：</p><ul><li>数字：Int、Double（Byte、Short、Char、Long、Float）</li><li>布尔：true 或 false</li><li>字符串</li><li>函数：像是 <code>Int =&gt; Int</code> 或者 <code>(Int, Int) =&gt; Int</code></li></ul><h2 id="表达式（Expressions）"><a href="#表达式（Expressions）" class="headerlink" title="表达式（Expressions）"></a>表达式（Expressions）</h2><p><img src="/uploads/expressions.png" alt="Expressions"></p><p>表达式可以是：</p><ul><li>标识符：例如 <code>x</code> 或是 <code>isGoodEnough</code></li><li>常量：例如 <code>0</code>、<code>1.0</code> 或是 <code>&quot;abc&quot;</code></li><li>执行函数：例如 <code>sqrt(x)</code></li><li>执行运算符：例如 <code>-x</code> 、<code>x + y</code></li><li>选择表达式：例如 <code>math.abs</code> （这里不太懂 <code>selection</code>是指的什么，该方法的内部实现是用的选择表达式？）</li><li>条件表达式：例如 <code>if (x &lt; 0) -x else x</code></li><li>代码块：例如 <code>{ val x = math.abs(y) ; x * 2 }</code></li><li>匿名函数：例如 <code>x =&gt; x + 1</code></li></ul><h2 id="定义（Definitions）"><a href="#定义（Definitions）" class="headerlink" title="定义（Definitions）"></a>定义（Definitions）</h2><p><img src="/uploads/definitions.png" alt="Definitions"></p><p>定义可以是：</p><ul><li>方法定义：例如 <code>def square(x: Int) = x</code></li><li>值定义：例如 <code>val y = square(2)</code></li></ul><p>其中参数可以是：</p><ul><li>值调用：例如 <code>(x: Int)</code></li><li>名称调用：例如 <code>(y: =&gt; Double)</code></li></ul><h1 id="函数和数据"><a href="#函数和数据" class="headerlink" title="函数和数据"></a>函数和数据</h1><p>本节通过一个例子介绍如何在 Scala 中使用函数创建和封装结构体。</p><p>一个分数由一个整数分子和另一个整数分母组成。如果需要计算两个分数的和，就需要定义两个如下的方法：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addRationalNumerator</span></span>(n1: <span class="type">Int</span>, d1: <span class="type">Int</span>, n2: <span class="type">Int</span>, d2: <span class="type">Int</span>): <span class="type">Int</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addRationalDenominator</span></span>(n1: <span class="type">Int</span>, d1: <span class="type">Int</span>, n2: <span class="type">Int</span>, d2: <span class="type">Int</span>): <span class="type">Int</span></span><br></pre></td></tr></table></figure><p>但是这样做明显增加了代码的维护成本，一种更好的方式是将分子和分母共同维护在一个结构体中。</p><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><p>在 Scala 中，可以用下面这种方式定义一个类（Classes）：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numer</span> </span>= x</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">denom</span> </span>= y</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段定义包含了两部分：</p><ol><li>一个新的类型（Type）：Rational</li><li>一个可以用于创建 Rational 实例的构造方法（Constructor）</li></ol><p>Scala 会保证定义的名称和值在不同的命名空间（Namespace）中，所以多个 Rational 定义彼此之间不会冲突（？）</p><h2 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h2><p>每个类型的元素被称为对象（Objects），通过 <code>new</code> 加上构造方法可以创建一个新的对象：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>每个 Rational 对象都有两个成员变量（Members）：<code>numer</code> 和 <code>denom</code>。通过 <code>.</code> 操作符可以获取对象的成员变量：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> x = <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">2</span>) &gt; x: <span class="type">Rational</span> = <span class="type">Rational</span>@<span class="number">2</span>abe0e27</span><br><span class="line">x.numer                    &gt; <span class="number">1</span></span><br><span class="line">x.denom                    &gt; <span class="number">2</span></span><br></pre></td></tr></table></figure><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在拥有 Rational 对象之后，就可以对其定义一些计算函数了：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addRational</span></span>(r: <span class="type">Rational</span>, s: <span class="type">Rational</span>): <span class="type">Rational</span> =</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Rational</span>(r.numer * s.denom + s.numer * r.denom, r.denom * s.denom)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeString</span></span>(r: <span class="type">Rational</span>) =</span><br><span class="line">  r.numer + ”/” + r.denom</span><br><span class="line">  </span><br><span class="line">makeString(addRational(<span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">2</span>), <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">2</span>, <span class="number">3</span>))) &gt; <span class="number">7</span>/<span class="number">6</span></span><br></pre></td></tr></table></figure><p>在此之上，还可以直接将函数抽象为结构体本身，这样的函数被称为方法（Methods）。</p><p>Rational 类本身就可以有 <code>add</code> 和 <code>toString</code> 方法：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numer</span> </span>= x</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">denom</span> </span>= y</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(r: <span class="type">Rational</span>) =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Rational</span>(numer * r.denom + r.numer * denom, denom * r.denom)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span> </span>= numer + ”/” + denom</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：<code>toString</code> 是由 <code>java.lang.Object</code> 继承而来的方法，所以需要加上 <code>override</code> 关键词。</p><p>这样调用时就可以变为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> x = <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> y = <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">5</span>, <span class="number">7</span>)</span><br><span class="line"><span class="keyword">val</span> z = <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">x.add(y).add(z)</span><br></pre></td></tr></table></figure><h2 id="抽象"><a href="#抽象" class="headerlink" title="抽象"></a>抽象</h2><p>在上面的例子中，可以发现通过计算而得出的分数有可能不是最简形态（例如 <code>3/6</code> 可以被约为 <code>1/2</code>）。</p><p>为此我们可以在每一个计算分数的方法中都加入化简的逻辑，但是这会使代码难以维护，很有可能在某个计算中忘记加入这部分逻辑。</p><p>一个更好的办法是直接在构造分数时就进行化简：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">gcd</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = <span class="keyword">if</span> (b == <span class="number">0</span>) a <span class="keyword">else</span> gcd(b, a % b)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> g = gcd(x, y)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numer</span> </span>= x / g</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">denom</span> </span>= y / g</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面方法中的 <code>gcd</code> 和 <code>g</code> 都是私有成员，它们只能在该对象内部被访问到。</p><p>另一种方式是将 <code>numer</code> 和 <code>denom</code> 都声明为 <code>val</code>，然后直接用 <code>gcd</code> 方法去计算，这样可以保证 <code>numer</code> 和 <code>denom</code> 只会初始化一次：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">gcd</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = <span class="keyword">if</span> (b == <span class="number">0</span>) a <span class="keyword">else</span> gcd(b, a % b)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> numer = x / gcd(x, y)</span><br><span class="line">  <span class="keyword">val</span> denom = y / gcd(x, y)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面两种方式对调用方都是无感知的，但是可以通过具体的情况选择不同的实现方案，这种方式称之为抽象（Abstraction）。</p><p>抽象是软件工程中的基石。</p><h2 id="自引用"><a href="#自引用" class="headerlink" title="自引用"></a>自引用</h2><p>在类的内部可以使用 <code>this</code> 关键词指代当前执行方法的对象，也就是自引用（Self Reference）。</p><p>例如为 Rational 添加 <code>less</code> 和 <code>max</code> 方法：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;  ...  <span class="function"><span class="keyword">def</span> <span class="title">less</span></span>(that: <span class="type">Rational</span>) =    <span class="keyword">this</span>.numer * that.denom &lt; that.numer * <span class="keyword">this</span>.denom</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(that: <span class="type">Rational</span>) =    <span class="keyword">if</span> (<span class="keyword">this</span>.less(that)) that <span class="keyword">else</span> <span class="keyword">this</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="前提检验"><a href="#前提检验" class="headerlink" title="前提检验"></a>前提检验</h2><p>假设 Rational 类要求分母必须是一个正整数，就可以通过 <code>require</code> 方法进行校验：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;  require(y &gt; <span class="number">0</span>, ”denominator must be positive”)  ...&#125;</span><br></pre></td></tr></table></figure><p><code>require</code> 是一个预定义方法，它需要一个条件以及可选的提示信息。当条件为假时，将会抛出一个携带提示信息的 <code>IllegalArgumentException</code> 异常。</p><h2 id="断言"><a href="#断言" class="headerlink" title="断言"></a>断言</h2><p>另一种校验的方式是使用断言（Assert），它同样接受一个条件和可选的提示信息，而当条件不满足时，它会抛出 <code>AssertionError</code> 异常。</p><p>两个异常的不同代表着这两种方式分别适合用于不同的场景：</p><ul><li><code>require</code> 适合在方法执行前校验外部传入的参数</li><li><code>assert</code> 用于校验方法执行过程中的逻辑</li></ul><h2 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h2><p>在 Scala 中，类定义就会隐式的引入一个构造函数，它被称为主构造函数（Primary Constructor）。</p><p>构造函数的主要用途是：</p><ul><li>接收传入的参数</li><li>执行类体中的所有语句</li></ul><p>除了主构造函数以外，还可以定义辅助构造函数，例如：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(x: <span class="type">Int</span>) = <span class="keyword">this</span>(x, <span class="number">1</span>)  ...&#125;<span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">2</span>) &gt; <span class="number">2</span>/<span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="类中的代换模型"><a href="#类中的代换模型" class="headerlink" title="类中的代换模型"></a>类中的代换模型</h1><p>在之前的笔记中有提到 Scala 的函数执行是通过一种称为代换模型的计算模型，在类和对象中也是如此。</p><p>当构建一个类实例 <code>new C(e1, ..., em)</code> 时，它的表达式参数依旧会像普通函数一样会被返回值所替代，成为 <code>new C(v1, ..., vm)</code>。</p><p>假设有一个包含方法的类定义：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span>(<span class="params">x1, ..., xm</span>)</span>&#123; ... <span class="function"><span class="keyword">def</span> <span class="title">f</span></span>(y1, ..., yn) = b ... &#125;</span><br></pre></td></tr></table></figure><p>它拥有类的形参 <code>x1, ..., xn</code> 和类实例方法的形参 <code>y1, ..., yn</code>，那么当执行 <code>new C(v1, ..., vm).f(w1, ..., wn)</code> 时，这整个表达式会被重写为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[w1/y1, ..., wn/yn][v1/x1, ..., vm/xm][<span class="keyword">new</span> <span class="type">C</span>(v1, ..., vm)/<span class="keyword">this</span>] b</span><br></pre></td></tr></table></figure><p>这里有三处地方被代换了：</p><ul><li><code>w1, ..., wn</code> 被代换为了方法 <code>f</code> 的形参 <code>y1, ..., yn</code></li><li><code>v1, ..., vn</code> 被代换为了类 <code>C</code> 的形参 <code>x1, ..., xm</code></li><li>表达式 <code>new C(v1, ..., vn)</code> 被代换为了自引用 <code>this</code></li></ul><p>以 Rational 作为一个具体的例子，当调用以下方法时：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">2</span>).less(<span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure><p>首先会进行代换：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>/x, <span class="number">2</span>/y] [newRational(<span class="number">2</span>, <span class="number">3</span>)/that] [<span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">2</span>)/<span class="keyword">this</span>]</span><br></pre></td></tr></table></figure><p>于是该方法的实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.numer * that.denom &lt; that.numer * <span class="keyword">this</span>.denom</span><br></pre></td></tr></table></figure><p>就会被替换为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">2</span>).numer * <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">2</span>, <span class="number">3</span>).denom &lt; <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">2</span>, <span class="number">3</span>).numer * <span class="keyword">new</span> <span class="type">Rational</span>(<span class="number">1</span>, <span class="number">2</span>).denom</span><br></pre></td></tr></table></figure><p>最后可以轻松的计算出结果：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> * <span class="number">3</span> &lt; <span class="number">2</span> * <span class="number">2</span></span><br><span class="line"><span class="literal">true</span></span><br></pre></td></tr></table></figure><h1 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h1><p>原则上来说，通过 Rational 定义的分数和整数没有什么区别，但是在使用时却有一些差异。</p><p>当我们想要计算两个整数的和时，只需要调用 <code>x + y</code>，而当需要计算两个 Rational 的和时，却需要调用 <code>r.add(s)</code>。</p><p>在 Scala 中，可以通过两步消除这种差异。</p><h2 id="中缀运算"><a href="#中缀运算" class="headerlink" title="中缀运算"></a>中缀运算</h2><p>任何只有一个参数的方法都可以使用中缀运算符（Infix Operator）的方式进行调用：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r add s  = r.add(s)</span><br><span class="line">r less s = r.less(s)</span><br><span class="line">r max s  = r.max(s)</span><br></pre></td></tr></table></figure><h2 id="标识符"><a href="#标识符" class="headerlink" title="标识符"></a>标识符</h2><p>在 Scala 中标识符可以有两种形态：</p><ul><li>字母数字（Alphanumeric）：以字母为起始字符，字母和数字组成的序列</li><li>符号（Symbolic）：以一个运算符为起始字符，后面可以跟着其他的运算符</li><li>下划线（<code>_</code>）也算是字母的一种</li><li>字母数字的标识符可以以下划线结尾，之后跟着一些运算符，例如 <code>vector_++</code></li></ul><p>所以 Rational 类中的部分方法可以通过运算符进行替换：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>(<span class="params">x: <span class="type">Int</span>, y: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">gcd</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = <span class="keyword">if</span> (b == <span class="number">0</span>) a <span class="keyword">else</span> gcd(b, a % b)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> g = gcd(x, y)</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numer</span> </span>= x / g</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">denom</span> </span>= y / g</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">+</span> </span>(r: <span class="type">Rational</span>) =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Rational</span>(numer * r.denom + r.numer * denom, denom * r.denom)</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">-</span> </span>(r: <span class="type">Rational</span>) = ...</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">*</span> </span>(r: <span class="type">Rational</span>) = ...</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样使用时就可以像 Int 或是 Double 一样了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val x = new Rational(1, 2)</span><br><span class="line">val y = new Rational(1, 3)</span><br><span class="line"></span><br><span class="line">(x * x) + (y * y)</span><br></pre></td></tr></table></figure><p>运算符的优先级由其第一个字符决定，下图为优先级有低至高的运算符。</p><p><img src="/uploads/precedence.png" alt="precedence"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周主要介绍了 Scala 中的高阶函数和类的相关定义，包含高阶函数和柯里化、类的构造与抽象等内容。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>博客迁移到 Github Pages 了</title>
    <link href="http://www.scienjus.com/moved-blog-to-github-pages/"/>
    <id>http://www.scienjus.com/moved-blog-to-github-pages/</id>
    <published>2017-04-23T08:11:51.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>还有两个月专门放博客的主机就要到期了，仔细一想现在也懒得折腾 WordPress 了，干脆最后折腾一把弄成静态博客的丢到 Github Pages 吧！</p><a id="more"></a><h1 id="选型"><a href="#选型" class="headerlink" title="选型"></a>选型</h1><p>这几年静态博客相关的方案已经有很多了，但是基本上都是基于 Markdown 去写文章，然后生成为 HTML 直接发布。</p><p>本来作为一个 Ruby 爱好者，再加上有 Github Pages 官方支持的加成，自然应该会去选择 Jekyll。但是无奈找了半天都找不到一款合适的主题，又懒得自己折腾，就选择了烂大街的 Hexo 和 <a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="external">NexT</a>。这个主题功能很全面，配置起来很简单，非常适合我这种懒人。</p><p>关于如何安装 Hexo 以及相关配置就不在这里详述了，感兴趣可以直接去 <a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="external">Hexo</a> 官网查看。</p><h1 id="文章迁移"><a href="#文章迁移" class="headerlink" title="文章迁移"></a>文章迁移</h1><p>虽然我很早开始就通过 Markdown 写博客了，但是最开始在 WordPress 上找不到一个合适的 Markdown 渲染插件，一时脑残就选择了自己在本地渲染成 HTML 然后再通过 WordPress 发布，导致迁移的时候造成了不必要的麻烦。</p><p>我的文章迁移的流程为：</p><ol><li>通过 WordPress 的后台将所有博客的导出成 XML 文件</li><li>将文章内容的 HTML 转换为 Markdown</li><li>修改一些边角的转移字符</li><li>按照文章链接输出到对应的文件</li></ol><p>我通过一个 Ruby 脚本完成这一切，使用 <code>oga</code> 解析 XML，<code>reverse_markdown</code> 将 HTML 转为 Markdown，<code>auto-correct</code> 优化排版，整个脚本的代码大概如下（因为只是用一次所以写的比较随意）：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">require</span> <span class="string">'oga'</span></span><br><span class="line"><span class="keyword">require</span> <span class="string">'reverse_markdown'</span></span><br><span class="line"><span class="keyword">require</span> <span class="string">'time'</span></span><br><span class="line"><span class="keyword">require</span> <span class="string">'auto-correct'</span></span><br><span class="line"></span><br><span class="line">template = <span class="string">&lt;&lt;-TEMPLATE</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">title: '%s'</span></span><br><span class="line"><span class="string">date: %s</span></span><br><span class="line"><span class="string">permalink: %s</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%s</span></span><br><span class="line"><span class="string">TEMPLATE</span></span><br><span class="line"></span><br><span class="line">handle = File.open(<span class="string">'/path/to/wordpress.xml'</span>)</span><br><span class="line"></span><br><span class="line">doc = Oga.parse_xml(handle)</span><br><span class="line"></span><br><span class="line">doc.xpath(<span class="string">'channel/item'</span>).each <span class="keyword">do</span> <span class="params">|item|</span></span><br><span class="line">  title = item.at_xpath(<span class="string">'title'</span>).text</span><br><span class="line">  time = item.at_xpath(<span class="string">'pubDate'</span>).text</span><br><span class="line">  link = item.at_xpath(<span class="string">'link'</span>).text</span><br><span class="line">  content = item.at_xpath(<span class="string">'content:encoded'</span>).text</span><br><span class="line">  <span class="comment"># html 2 markdown</span></span><br><span class="line">  content = ReverseMarkdown.convert(content, <span class="symbol">github_flavored:</span> <span class="literal">true</span>).inspect</span><br><span class="line">  <span class="comment"># auto correct</span></span><br><span class="line">  content = content.auto_correct!</span><br><span class="line"></span><br><span class="line">  File.open(<span class="string">"/path/to/blog/<span class="subst">#&#123;link&#125;</span>.md"</span>, <span class="string">'w'</span>).write(template % [title, time, link, content])</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>需要注意的是在将 HTML 转成 Markdown 后可能会出现一些边边角角的转义字符，上面的程序并没有列出这部分逻辑，需要自己观察博客并修改。</p><h1 id="图片迁移"><a href="#图片迁移" class="headerlink" title="图片迁移"></a>图片迁移</h1><p>之前的图片是直接上传到 WordPress 资源库，用七牛云做 CDN，如果当初直接把图片丢到七牛也就没这破事了，但是我这次依旧没有把图片丢到七牛（主要就是懒，应该也不会再迁移第三回了）。</p><p>个人比较建议将所有图片都放在 <code>source</code> 下，也就是和 <code>_posts</code> 平级，这样当使用 MWeb 这样对其有支持的编辑器时，可以比较好的提供本地预览的支持</p><p><img src="/uploads/mweb.png" alt="mweb"></p><p>Hexo 官方推荐的另外一种做法是设置 <code>post_asset_folder: true</code> 然后将每个文章使用的资源都放在与文章同名的文件夹下。但是由于我需要将以前的图片迁移过来，这样做只会增加额外的迁移工作量。</p><p>而且这种做法据说还会带来图片在首页或归档页无法正常显示的问题，以至于兼容这个问题还需要在 Markdown 里人为的添加 Hexo 独有的标签，这太不清真了，果断拒绝。</p><h1 id="评论迁移"><a href="#评论迁移" class="headerlink" title="评论迁移"></a>评论迁移</h1><p>在最开始就用了 Disqus，之后依旧会使用它，所以整个迁移过程很简单。</p><p>Disqus 是通过 URL 识别每篇文章的，官方也提供了非常丰富的迁移工具，如果只是域名发生了更改可以直接使用 <a href="https://help.disqus.com/customer/portal/articles/912627-domain-migration-wizard" target="_blank" rel="external">Domain Migration Tool</a>，如果文章的地址也发生了改变就需要使用 <a href="https://help.disqus.com/customer/portal/articles/912757-url-mapper" target="_blank" rel="external">URL Mapper</a> 了。</p><p>在博客完全替换之前，为了预览效果我给新博客分配了一个二级域名，而当我在博客迁移完、将主域名转到新博客后，却发现评论没有如预期的那样同步过来。</p><p>此时我在 Disqus 上正常评论是可以显示的，看后台导出的记录发现新评论依旧是挂在二级域名下，最后将所有评论都从主域名转到二级域名下，评论终于能够在新博客上默认显示了。</p><p>所以在此也建议在博客完全迁移完之前，不要进行 Disqus 相关的配置。</p><h1 id="版本管理"><a href="#版本管理" class="headerlink" title="版本管理"></a>版本管理</h1><p>在文章的最初曾经提到 Github Pages 默认支持的引擎是 Jekyll，这意味着如果你使用 Jekyll 写博客，只需要将作为源文件的 Markdown 发布到 Github，就能自动跑一套 CI 生成静态页面，整个版本管理会简单很多。</p><p>很遗憾的是 Hexo 目前并不具备这种条件，这意味着只能先在本地生成静态页面，再将静态页面发布到 Github 上，而源文件没有任何版本控制，只有本地存储了一份。</p><p>目前我在同一仓库中又建立了一个 <code>source</code> 分支，每次写好博客后，先会通过普通 Git 操作流程将源文件发布到该分支，然后再通过 <code>hexo g -d</code> 将最新的页面发布到 <code>master</code> 分支。也有朋友建议我提交源文件后通过第三方 CI 进行发布，但是我觉得写博客作为一个低频行为（至少对于我来说是低频行为），不值得搞得这么复杂。</p><hr><p>最后，虽然还有很多东西没有弄（统计、计数、CDN），但是至少可以开始产出文章了，愿这个新平台给我带来更良好、更高效的写作体验。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;还有两个月专门放博客的主机就要到期了，仔细一想现在也懒得折腾 WordPress 了，干脆最后折腾一把弄成静态博客的丢到 Github Pages 吧！&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>[Functional Programming Principles in Scala] 学习笔记（一） 函数调用</title>
    <link href="http://www.scienjus.com/profun1-week1/"/>
    <id>http://www.scienjus.com/profun1-week1/</id>
    <published>2017-04-04T15:03:21.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="开始之前"><a href="#开始之前" class="headerlink" title="开始之前"></a>开始之前</h1><ol><li>这篇笔记是 Coursera 上的 <a href="https://www.coursera.org/learn/progfun1" target="_blank" rel="external">Functional Programming Principles in Scala</a> 课程，主讲者是 Scala 的作者 Martin Odersky，所以还是相当推荐的。</li><li>英文能力渣 + 中文表达能力渣，如果错误信息欢迎指正</li></ol><hr><h1 id="编程范式"><a href="#编程范式" class="headerlink" title="编程范式"></a>编程范式</h1><p>在目前的编程中主要有三种范式：</p><ol><li>函数式编程（Functional Programming）</li><li>命令式编程（Imperative Programming）</li><li>逻辑式编程（Logic Programming）</li></ol><p>除此之外，还有一些人认为面向对象编程（Object Oriented Programming）也是一种范式。</p><h2 id="命令式编程"><a href="#命令式编程" class="headerlink" title="命令式编程"></a>命令式编程</h2><p>命令式编程主要由可变变量、赋值语句和程序控制语句（例如 if..then..else 和 loops）组成。最普遍的理解方式是冯诺依曼计算机的计算序列，它们有这样的对应关系：</p><ol><li>可变变量 ≈ 内存空间</li><li>变量引用 ≈ 加载指令</li><li>变量赋值 ≈ 存储指令</li><li>控制结构 ≈ 指令跳转</li></ol><p>命令式编程的问题是：如何能够避免逐字逐句的进行编程？</p><p>所以我们需要更高级别的抽象，例如多项式、集合、字符串、文档等，最好能够开发其相关的法则。该法则包含一个或多个数据类型、如何操作这些数据类型以及描述值和操作之间的关系。</p><p>通常情况下，法则并不会改变数据本身。例如以下是一个多项式的法则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(a * x + b) + (c * x + d) = (a + c) * x + (b + d)</span><br></pre></td></tr></table></figure><p>它并不会通过某个操作符改变系数本身使这个法则成立。</p><p>另一个例子是字符串通过 <code>++</code> 串联的法则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(a ++ b) ++ c = a ++ (b ++ c)</span><br></pre></td></tr></table></figure><p>它也不会通过操作符修改字符串中的字符序列而保证法则成立（例如在 Java 中，字符串是不可变的）。</p><h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><ol><li>狭义而言，函数式编程是没有赋值、可变变量、循环等控制结构的编程手段。</li><li>广义而言，函数式编程以函数为重点。函数可以作为一个值被创建、使用和组合。</li><li>在函数式编程语言中，这一切都会变得很容易。</li></ol><h2 id="函数式编程语言"><a href="#函数式编程语言" class="headerlink" title="函数式编程语言"></a>函数式编程语言</h2><ol><li>狭义而言，函数式编程语言是没有赋值、可变变量、循环等控制结构的编程语言。</li><li>广义而言，函数式编程语言允许构建以函数为重点的程序。</li><li>函数在函数式编程语言中是第一等公民（First-Class Citizens），这意味着：<ol><li>函数可以定义在任何地方，无论是在其他函数内部或外部</li><li>像其他值一样，函数可以作为另一个函数的参数或是返回值</li><li>像其他值一样，存在一些操作用于组合函数</li></ol></li></ol><h2 id="现有的函数式编程语言"><a href="#现有的函数式编程语言" class="headerlink" title="现有的函数式编程语言"></a>现有的函数式编程语言</h2><p>狭义而言：</p><ol><li>Pure Lisp, XSLT, XPath, XQuery, FP</li><li>Haskell（不包含 I/O 单元或 UnsafePerformIO）</li></ol><p>广义而言：</p><ol><li>Lisp, Scheme, Racket, Clojure</li><li>SML, Ocaml, F#</li><li>Haskell (整个语言)</li><li>Scala</li><li>Smalltalk, Ruby</li></ol><p>在通常情况下 Smalltalk 和 Ruby 被视为面向对象语言，但是这两种语言都拥有构建语句块（本质上是一等公民函数）的能力。</p><p>他们的历史是：</p><ul><li>1959 Lisp</li><li>1975-77 ML, FP, Scheme</li><li>1978 Smalltalk</li><li>1986 Standard ML</li><li>1990 Haskell, Erlang</li><li>1999 XSLT</li><li>2000 OCaml</li><li>2003 Scala, XQuery</li><li>2005 F#</li><li>2007 Clojure</li></ul><h1 id="求值策略"><a href="#求值策略" class="headerlink" title="求值策略"></a>求值策略</h1><h2 id="传值调用（Call-by-value）"><a href="#传值调用（Call-by-value）" class="headerlink" title="传值调用（Call by value）"></a>传值调用（Call by value）</h2><p>假设有一个函数 <code>sumOfSquares</code> 用于求两个数字平方之和，在传值调用时，它的计算步骤为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sumOfSquares(3, 2 + 2)</span><br><span class="line">sumOfSquares(3, 4)</span><br><span class="line">square(3) + square(4) </span><br><span class="line">3 * 3 + square(4) </span><br><span class="line">9 + square(4) </span><br><span class="line">9 + 4 * 4 </span><br><span class="line">9 + 16 </span><br><span class="line">25</span><br></pre></td></tr></table></figure><p>整个执行流程为从左至右的计算函数的所有的表达式参数，然后将参数替换为计算后的值。</p><p>这种表达式求值方案称为代换模型（Substitution Model），核心思想是所有的表达式都可以被其计算出的返回值替换掉，只要这些表达式没有副作用（Side Effects）。</p><h2 id="传名称调用（Call-by-name"><a href="#传名称调用（Call-by-name" class="headerlink" title="传名称调用（Call by name)"></a>传名称调用（Call by name)</h2><p>传名称调用在实际使用参数前并不会计算表达式的值，同样是上面的函数，计算步骤为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sumOfSquares(3, 2 + 2) </span><br><span class="line">square(3) + square(2 + 2)</span><br><span class="line">3 * 3 + square(2 + 2) </span><br><span class="line">9 + square(2 + 2)</span><br><span class="line">9 + (2 + 2) * (2 + 2)</span><br><span class="line">9 + 4 * (2 + 2) </span><br><span class="line">9 + 4 * 4</span><br><span class="line">25</span><br></pre></td></tr></table></figure><p>相比之下，传值调用的优点是每个参数的值只会计算一次，而传名称调用的优点是参数如果没有在函数体中被用到，则根本不需要去计算。</p><h2 id="终止条件"><a href="#终止条件" class="headerlink" title="终止条件"></a>终止条件</h2><p>一个疑问：所有的表达式都可以在有限的步骤内计算为一个值么？</p><p>答案：否，例如 <code>def loop: Int = loop</code>。</p><p>所以在某些情况下，使用传名称调用函数可以顺利结束并得到一个返回值，使用传值调用则不能，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def first(x: Int, y: Int) = x</span><br><span class="line"></span><br><span class="line">first(1, loop)</span><br></pre></td></tr></table></figure><p>Scala 在通常情况下使用传值调用，但是通过 <code>=&gt;</code> 定义参数可以改为传名称调用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def constOne(x: Int, y: =&gt; Int) = 1</span><br></pre></td></tr></table></figure><h1 id="条件和值定义"><a href="#条件和值定义" class="headerlink" title="条件和值定义"></a>条件和值定义</h1><h2 id="条件表达式"><a href="#条件表达式" class="headerlink" title="条件表达式"></a>条件表达式</h2><p>Scala 拥有条件表达式 if-else，其用起来很像 Java，但是在 Scala 中它是表达式而不是语句，这意味着可以这样使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def abs(x: Int) = if (x &gt;= 0) x else -x</span><br></pre></td></tr></table></figure><h2 id="值定义"><a href="#值定义" class="headerlink" title="值定义"></a>值定义</h2><p>就像函数的参数可以通过传值或是传名称调用一样，值的定义也可以通过 <code>def</code> 或是 <code>val</code> 进行按名称或是按值的定义。</p><p>例如当使用 <code>def x = loop</code> 时，这是一个有效的赋值。而当时用 <code>val y = loop</code> 时，则会导致一个死循环。</p><h1 id="嵌套函数"><a href="#嵌套函数" class="headerlink" title="嵌套函数"></a>嵌套函数</h1><p>好的函数式编程风格是将一个任务分解为多个小函数。但是其中很多函数我们并不希望用户去直接使用它，基于此可以将这些小函数定义在真正使用的函数内部。</p><p>就像是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def sqrt(x: Double) = &#123;</span><br><span class="line">  def sqrtIter(guess: Double, x: Double): Double =</span><br><span class="line">    if (isGoodEnough(guess, x)) guess</span><br><span class="line">    else sqrtIter(improve(guess, x), x)</span><br><span class="line"></span><br><span class="line">  def improve(guess: Double, x: Double) =</span><br><span class="line">    (guess + x / guess) / 2</span><br><span class="line"></span><br><span class="line">  def isGoodEnough(guess: Double, x: Double) =</span><br><span class="line">    abs(square(guess) - x) &lt; 0.001</span><br><span class="line"></span><br><span class="line">  sqrtIter(1.0, x)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 <code>sqrtIter</code>、<code>improve</code>、<code>isGoodEnough</code> 都只是 <code>sqrt</code> 中逻辑的一部分，所以对外只需要暴露这一个函数。</p><h1 id="语句块"><a href="#语句块" class="headerlink" title="语句块"></a>语句块</h1><p>在 Scala 中通过 <code>{ ... }</code> 定义一个语句块。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  val x = f(3)</span><br><span class="line">  x * x</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>语句块有以下特性：</p><ol><li>语句块中可以包含一系列的定义和表达式</li><li>语句块中最后的表达式代表这个块的值</li><li>或者也可以在这之前用 return 表达式返回值</li><li>语句块可以出现在任何一般表达式可以出现的地方</li></ol><p>语句块中的变量有以下特性：</p><ol><li>语句块中定义的变量只有在语句块中才可以访问</li><li>语句块中可以定义和语句块外同名的变量</li><li>语句块内可以访问语句块外的变量</li></ol><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val x = 0 </span><br><span class="line">def f(y: Int) = y + 1 </span><br><span class="line">val result = &#123; </span><br><span class="line">  val x = f(3) </span><br><span class="line">  x * x </span><br><span class="line">&#125; + x</span><br></pre></td></tr></table></figure><p><code>result</code> 的值为 <code>16</code>，因为语句块内的 <code>x</code> 为 4，而语句块外的 <code>x</code> 始终为 <code>0</code>。</p><h1 id="尾递归"><a href="#尾递归" class="headerlink" title="尾递归"></a>尾递归</h1><p>有两个通过递归进行计算的函数，一个是 gcd：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def gcd(a: Int, b: Int): Int =</span><br><span class="line">    if (b == 0) a else gcd(b, a % b)</span><br></pre></td></tr></table></figure><p>当调用时它的执行步骤为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gcd(14, 21)</span><br><span class="line">if (21 == 0) 14 else gcd(21, 14 % 21)</span><br><span class="line">if (false) 14 else gcd(21, 14 % 21)</span><br><span class="line">gcd(21, 14 % 21)</span><br><span class="line">gcd(21, 14)</span><br><span class="line">if (14 == 0) 21 else gcd(14, 21 % 14)</span><br><span class="line">gcd(14, 7)</span><br><span class="line">gcd(7, 0)</span><br><span class="line">if (0 == 0) 7 else gcd(0, 7 % 0)</span><br><span class="line">7</span><br></pre></td></tr></table></figure><p>另一个函数是 factorial：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def factorial(n: Int): Int =</span><br><span class="line">    if (n == 0) 1 else n * factorial(n - 1)</span><br></pre></td></tr></table></figure><p>它的执行步骤为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">factorial(4)</span><br><span class="line">if (4 == 0) 1 else 4 * factorial(4 - 1)</span><br><span class="line">4 * factorial(3)</span><br><span class="line">4 * (3 * factorial(2))</span><br><span class="line">4 * (3 * (2 * factorial(1)))</span><br><span class="line">4 * (3 * (2 * (1 * factorial(0)))</span><br><span class="line">4 * (3 * (2 * (1 * 1)))</span><br><span class="line">120</span><br></pre></td></tr></table></figure><p>它们的区别是：如果一个函数最后的动作只是调用它自己，那么这个函数的栈帧就可以被复用，这被称为尾递归（Tail Recursion）。</p><p>上面两个函数中，gcd 就是一个尾递归函数，而 factorial 并不是，因为它需要递归函数的返回值额外进行计算。</p><p>另外，如果一个函数最后的动作只是调用另一个函数（可能为它自己），那么一个栈帧就足够被这两个函数使用，这被称为尾调用（Tail Calls）。</p><p>factorial 也可以被改为使用尾递归的形式，只需要将函数中暂存的乘积作为参数传到下一次调用即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def factorial(n : Int): Int = &#123;</span><br><span class="line">  def loop(acc: Int, n: Int): Int =</span><br><span class="line">    if (n == 0) acc</span><br><span class="line">    else loop(acc * n, n - 1)</span><br><span class="line">  loop(1, n)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Scala 中，只有在当前函数中直接进行递归调用的函数才会做尾递归优化。</p><p>也可以通过 <code>@tailrec</code> 指定该函数为尾递归函数，但如果函数本身就不是尾递归函数，则会抛出一个编译错误。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;开始之前&quot;&gt;&lt;a href=&quot;#开始之前&quot; class=&quot;headerlink&quot; title=&quot;开始之前&quot;&gt;&lt;/a&gt;开始之前&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;这篇笔记是 Coursera 上的 &lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>基于 Elasticsearch 的 Zipkin 统计</title>
    <link href="http://www.scienjus.com/zipkin-statistics-based-on-elasticsearch/"/>
    <id>http://www.scienjus.com/zipkin-statistics-based-on-elasticsearch/</id>
    <published>2017-01-02T23:19:50.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近将 Zipkin 的底层存储切换到了 Elasticsearch，相比 Cassandra，Elasticsearch 拥有更加灵活的查询和聚合方式，所以可以完成一些之前做不到的自定义统计，在此记录一下。</p><h2 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h2><p>Zipkin 的存储是基于 Span 的，每一个 Span 为一个文档，字段有：</p><ul><li><code>traceId</code>：所属的 Trace</li><li><code>duration</code>：执行消耗的时间（单位为微秒）</li><li><code>timestamp</code>、<code>timestamp_millis</code>：生成时间（单位分别为微秒和毫秒）</li><li><code>name</code>：Span 的名称</li><li><code>annotations</code>：主要用于记录系统通信的情况，有 <code>Client Send</code>、<code>Server Receive</code>、<code>Server Send</code> 和 <code>Client Receive</code> 四种通信记录</li><li><code>binaryAnnotations</code>：记录一些自定义数据，可以记录任何关心的数据，例如方法参数、SQL 语句、Server 端地址等</li><li><code>parentId</code>：父 Span</li><li><p><code>collector_timestamp_millis</code>：采集时间</p><p>使用 Zipkin UI 时 <code>name</code>、<code>binaryAnnotations</code> 都仅作为展示字段，而在 Elasticsearch 中，通过良好的方式定义这些字段，可以完成一些横向的查询和聚合。</p><p>理论上如果定义得当，最多可以通过 <code>name</code>、<code>binaryAnnotations.key</code> 和 <code>binaryAnnotations.value</code> 进行三层的聚合，这里举几个例子。</p></li></ul><h2 id="Span-定义与查询"><a href="#Span-定义与查询" class="headerlink" title="Span 定义与查询"></a>Span 定义与查询</h2><h3 id="HTTP-RPC-API-的-Span-定义："><a href="#HTTP-RPC-API-的-Span-定义：" class="headerlink" title="HTTP/RPC API 的 Span 定义："></a>HTTP/RPC API 的 Span 定义：</h3><p> 将 Endpoint 作为 <code>name</code>，然后将 Header、Param 等信息作为 <code>binaryAnnotations</code>，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;traceId&quot;: &quot;51c068d64b9f7a58&quot;,</span><br><span class="line">  &quot;duration&quot;: 1330683,</span><br><span class="line">  &quot;binaryAnnotations&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;endpoint&quot;: &#123;</span><br><span class="line">        &quot;ipv4&quot;: &quot;10.xxx.xxx.xxx&quot;,</span><br><span class="line">        &quot;port&quot;: 8088,</span><br><span class="line">        &quot;serviceName&quot;: &quot;user-service&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;value&quot;: &quot;[user-agent=okhttp/3.2.0]&quot;,</span><br><span class="line">      &quot;key&quot;: &quot;Headers&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;endpoint&quot;: &#123;</span><br><span class="line">        &quot;ipv4&quot;: &quot;10.xxx.xxx.xxx&quot;,</span><br><span class="line">        &quot;port&quot;: 8088,</span><br><span class="line">        &quot;serviceName&quot;: &quot;user-service&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;value&quot;: &quot;[id=100001]&quot;,</span><br><span class="line">      &quot;key&quot;: &quot;Params&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;endpoint&quot;: &#123;</span><br><span class="line">        &quot;ipv4&quot;: &quot;10.xxx.xxx.xxx&quot;,</span><br><span class="line">        &quot;port&quot;: 8088,</span><br><span class="line">        &quot;serviceName&quot;: &quot;user-service&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;value&quot;: &quot;/v1/users/&#123;id&#125;.json&quot;,</span><br><span class="line">      &quot;key&quot;: &quot;lc&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;timestamp_millis&quot;: 1483143424117,</span><br><span class="line">  &quot;name&quot;: &quot;/v1/users/&#123;id&#125;.json&quot;,</span><br><span class="line">  &quot;collector_timestamp_millis&quot;: &quot;2016-12-31T00:17:05.808+0000&quot;,</span><br><span class="line">  &quot;id&quot;: &quot;2987302a57b7212f&quot;,</span><br><span class="line">  &quot;parentId&quot;: &quot;51c068d64b9f7a58&quot;,</span><br><span class="line">  &quot;timestamp&quot;: 1483143424117000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这样可以通过如下的查询语句统计一下当前系统 HTTP API 的性能情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0,</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;nested&quot;: &#123;</span><br><span class="line">          &quot;path&quot;: &quot;binaryAnnotations&quot;,</span><br><span class="line">          &quot;query&quot;: &#123;</span><br><span class="line">            &quot;match&quot;: &#123;</span><br><span class="line">              &quot;binaryAnnotations.key&quot;: &quot;Params&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;path&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;name&quot;,</span><br><span class="line">        &quot;order&quot;: &#123;</span><br><span class="line">          &quot;avg_duration&quot;: &quot;desc&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;size&quot;: 20,</span><br><span class="line">        &quot;min_doc_count&quot;: 100</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;avg_duration&quot;: &#123;</span><br><span class="line">          &quot;avg&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;duration&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;top_duration_trace&quot;: &#123;</span><br><span class="line">          &quot;top_hits&quot;: &#123;</span><br><span class="line">            &quot;sort&quot;: &#123;</span><br><span class="line">            &quot;duration&quot;: &#123;</span><br><span class="line">                &quot;order&quot;: &quot;desc&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">              &quot;includes&quot;: [</span><br><span class="line">                  &quot;traceId&quot;,</span><br><span class="line">                  &quot;duration&quot;</span><br><span class="line">              ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;size&quot; : 3</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 该语句首先查出了所有 API 入口的 Span，聚合出平均响应时间最长的 20 个 API，并给出每个 API 中响应时间最长的 3 个 Trace。</p><p> 这种结构有一点不好的是没办法进一步通过参数进行聚合了，如果一个接口在请求参数不同时响应时间差别比较大，就没有办法找出具体是哪些参数影响的了。将每一个参数都加入 <code>binaryAnnotations</code> 中并不是一个很好的做法，因为会增加许多无意义的嵌套文档。如果能像 RESTful 一样将一些重要参数定义在 URI 路径上也许能解决这个问题。</p><h3 id="MySQL-Redis-等数据库查询的-Span-定义："><a href="#MySQL-Redis-等数据库查询的-Span-定义：" class="headerlink" title="MySQL/Redis 等数据库查询的 Span 定义："></a>MySQL/Redis 等数据库查询的 Span 定义：</h3><p> 建议将 <code>name</code> 设置为命令名，像是 <code>mysql-select</code>、<code>redis-get</code> 等。之后便可以分析在每一个 Trace 中，SQL 查询或是 Redis 查询发生的次数以及总耗时。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0,</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;traceId&quot;: &quot;3fa0711deeb82b11&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;span_name&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;name&quot;,</span><br><span class="line">        &quot;order&quot;: &#123;</span><br><span class="line">          &quot;sum_duration&quot;: &quot;desc&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;sum_duration&quot;: &#123;</span><br><span class="line">          &quot;sum&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;duration&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 上面的查询语句通过聚合一个 Trace 的所有 Span，根据类型计算总耗时并排序，它的返回结果是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;span_name&quot;: &#123;</span><br><span class="line">    &quot;doc_count_error_upper_bound&quot;: 0,</span><br><span class="line">    &quot;sum_other_doc_count&quot;: 0,</span><br><span class="line">    &quot;buckets&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;mysql-insert&quot;,</span><br><span class="line">        &quot;doc_count&quot;: 200,</span><br><span class="line">        &quot;sum_duration&quot;: &#123;</span><br><span class="line">          &quot;value&quot;: 848077</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;mysql-select&quot;,</span><br><span class="line">        &quot;doc_count&quot;: 202,</span><br><span class="line">        &quot;sum_duration&quot;: &#123;</span><br><span class="line">          &quot;value&quot;: 605769</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;rpc-get_id&quot;,</span><br><span class="line">        &quot;doc_count&quot;: 400,</span><br><span class="line">        &quot;sum_duration&quot;: &#123;</span><br><span class="line">          &quot;value&quot;: 104678</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;redis-incr&quot;,</span><br><span class="line">        &quot;doc_count&quot;: 200,</span><br><span class="line">        &quot;sum_duration&quot;: &#123;</span><br><span class="line">          &quot;value&quot;: 217</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;key&quot;: &quot;redis-get&quot;,</span><br><span class="line">        &quot;doc_count&quot;: 201,</span><br><span class="line">        &quot;sum_duration&quot;: &#123;</span><br><span class="line">          &quot;value&quot;: 216</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这个返回结果表明，这一次调用共执行了：</p><ul><li>200 次 MySQL 插入，总耗时 848 ms</li><li>202 次 MySQL 查询，总耗时 605 ms</li><li>400 次 RPC 发号器调用，总耗时 104 ms</li><li>217 次 Redis 自增操作，总耗时 0.2 ms</li><li><p>216 次 Redis 查询操作，总耗时 0.2 ms</p><p>再进一步，可以将 <code>binaryAnnotation</code> 设置为执行的预编译 SQL 模板，例如：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;mysql-select&quot;,</span><br><span class="line">  &quot;binaryAnnotations&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;endpoint&quot;: &#123;</span><br><span class="line">        &quot;ipv4&quot;: &quot;10.xxx.xxx.xxx&quot;,</span><br><span class="line">        &quot;port&quot;: 8088,</span><br><span class="line">        &quot;serviceName&quot;: &quot;user-service&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;value&quot;: &quot;select * from user where user_id = ?&quot;,</span><br><span class="line">      &quot;key&quot;: &quot;query&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这样就可以找到系统中到底执行了哪些慢查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0,</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;mysql-select&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;path&quot;: &#123;</span><br><span class="line">      &quot;nested&quot;: &#123;</span><br><span class="line">        &quot;path&quot;: &quot;binaryAnnotations&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;filter_sql&quot;: &#123;</span><br><span class="line">          &quot;filter&quot; : &#123; </span><br><span class="line">            &quot;term&quot;: &#123;</span><br><span class="line">              &quot;binaryAnnotations.key&quot;: &quot;executed.query&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;aggs&quot;: &#123;</span><br><span class="line">            &quot;sql&quot;: &#123;</span><br><span class="line">              &quot;terms&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;binaryAnnotations.value&quot;</span><br><span class="line">              &#125;,</span><br><span class="line">              &quot;aggs&quot;: &#123;</span><br><span class="line">                &quot;reverse_duration&quot;: &#123;</span><br><span class="line">                  &quot;reverse_nested&quot;: &#123;&#125;,</span><br><span class="line">                  &quot;aggs&quot;: &#123;</span><br><span class="line">                    &quot;duration_outlier&quot;: &#123;</span><br><span class="line">                           &quot;percentiles&quot; : &#123;</span><br><span class="line">                             &quot;field&quot;: &quot;duration&quot;,</span><br><span class="line">                             &quot;percents&quot;: [75, 95, 99]</span><br><span class="line">                           &#125;</span><br><span class="line">                         &#125;</span><br><span class="line">                    &quot;avg_duration&quot;: &#123;</span><br><span class="line">                      &quot;avg&quot;: &#123;</span><br><span class="line">                        &quot;field&quot;: &quot;duration&quot;</span><br><span class="line">                      &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;sum_duration&quot;: &#123;</span><br><span class="line">                      &quot;sum&quot;: &#123;</span><br><span class="line">                        &quot;field&quot;: &quot;duration&quot;</span><br><span class="line">                      &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 在上面这个查询中可以聚合出每种 SQL 执行的次数、总耗时、平均耗时、Mean 75/95/99 耗时等信息</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p> 基于 Elasticsearch 的 Zipkin 自定义查询，核心是定义好 <code>name</code>、<code>binaryAnnotations.key</code> 和 <code>binaryAnnotations.value</code> 三个字段，使其作为 Terms 聚合将不同功能的 Span 拆分，之后再通过 Avg、Sum、Percentiles 等统计型聚合对 <code>duration</code> 算出需要的数据。</p><p> 但是这其中也是有一些坑的，首先是 Zipkin 的 Span 文档量会非常的多，所以无任何过滤条件的聚合请求响应时间非常长。基本上达到一定数量级后，Zipkin UI 加载 Service Name 和 Span Name 的接口就必然会超时了。这时候反而用 Kibana 会比 Zipkin UI 效率更高，因为自定义查询语句无论是功能上还是性能上都是可控的。</p><p> 另外一个坑就是 <code>binaryAnnotations</code> 是一个嵌套文档，但聚合时最终落在统计指标的 <code>duration</code> 却是外层的字段，这在某些聚合语句下会有问题。目前来看最常见的一个场景是想指定一个聚合结果作为排序条件时，被提示 <code>Ordering on a single-bucket aggregation can only be done on its doc_count.</code>，目前还没找到很好地解决办法。</p><p> 其实 Zipkin 在 Cassandra 上存储的方式很好，性能足够支撑大数据量且查询速度也很快。但是切换为 Elasticsearch 之后，查询和聚合的方式丰富了许多，<code>binaryAnnotations</code> 这种字段在文档型存储中就显得比较尴尬的。此时就有了自定义存储结构的价值，可以根据业务定制各种需要存储的额外字段，改造难度也不大。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近将 Zipkin 的底层存储切换到了 Elasticsearch，相比 Cassandra，Elasticsearch 拥有更加灵活的查询和聚合方式，所以可以完成一些之前做不到的自定义统计，在此记录一下。&lt;/p&gt;
&lt;h2 id=&quot;存储结构&quot;&gt;&lt;a href=&quot;#存储结构
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>2016 年终总结</title>
    <link href="http://www.scienjus.com/2016-year-end-review/"/>
    <id>http://www.scienjus.com/2016-year-end-review/</id>
    <published>2016-12-30T08:24:29.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天过去的好快…感觉什么都没做…</p><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><p> 上半年主要在前公司主导了一次系统重构，将原有的老系统的基础框架基本全换了，用上了 Spring Boot，写了一堆 Spring 的基础组件，将搜索服务从我之前基于 Lucene/MongoDB 封装的苦逼系统切换为了 Elasticsearch。现在想来在 2014 年年 底选择这样的技术栈也是有些激进了，好在虽然踩了不少坑但还是顺利的用起来了。</p><p> 在上家公司剩下的日子里主要就是不务正业的瞎鼓捣东西，例如用 Django 搭了一套管理后台（之后就再也没写过 Python），搭了套 ELK 做一些简单的日志分析（自嗨），后来又嫌 Django 维护起来太麻烦索性用 Vue 将后台又重写了（还是自嗨）。</p><p>5 月初裸辞后本来想好好玩一段时间，结果迫于父母压力只在家宅了不到一周就开始投简历了，3 天后入职了 ENJOY，目前存活过了试用期还在高高兴兴的打酱油。</p><p> 在这边就是本本分分的做业务，技术栈很稳，同事也都很 Nice，还被一些同年龄段的强人碾压的一无是处。唯一遗憾的是我暂时还没做出能让自己感到自豪的东西，反而还留了不少坑，明年接着努力吧。</p><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><p> 前年是 Mooc，去年是瞎玩，今年什么都没干，真是一年不如一年。</p><p> 今年真的是自我膨胀的厉害，被一堆吹比架构师忽悠，天天看什么微服务、分布式的心灵鸡汤，最后什么也没落到。不过也认清了现在整个行业的氛围就是这样，反正我不想掺和了，也不想成为这样的人，我只想在一线写代码，至少写到 40 岁！（还有 17年）</p><p> 索性今年还是读了一些书的，我觉得比较好的有：</p><ul><li>《Elasticsearch in Action》：没什么好说的，和官方文档、权威指南都是学 Elasticsearch 必读书籍，但是其实比这两者更深一些，更关注些 API 以外的东西</li><li>《七周七语言：理解多种编程范型》：一本大补剂，累了没心情撸码了读一读，瞬间就满血复活了。</li><li>《微服务设计》：入门书籍，很多人连这么通俗易懂的书都不读就瞎吹真是心寒</li><li><p>《深入理解 Java 虚拟机 JVM 高级特性与最佳实践》：我写的代码再也不是有人生没人养的孩子了</p><p>我一向喜欢鼓捣编程语言，同时一直在用极度肤浅的方式评价着每一种语言（我写起来爽不爽）。今年摸索过的语言有：</p></li><li><p>Kotlin：一开始为了「更简单的 Scala」毅然决然的入了坑，其中付出多少心血踩了多少架子摔得粉身碎骨都坚持了下来，妄图封装一套类似于 Sinatra 的轻量级 Web 框架，最后只换来一句「Android 界的 Swift」，最终认识到不是一个世界的语言是不会有结果的 QAQ</p></li><li>Golang：因为去年希望可以玩玩，所以今年上半年就随便写了点小 Demo，当时感觉还行不过没找到太合适的应用场景就一直放着了。后来机缘巧合在新公司有机会写了一个半成品小服务，但是感觉实在不太喜欢 Golang 的某些语法，就没在用了</li><li>Rust：这个真的是 Hello World 级别的摸索，好久以前搜 Rust 时在知乎瞥到了 TiKV，年底 PingCAP 的人来公司分享又安利了 Rust，结果就摸了摸，仅仅是摸了摸</li><li>Elixir：我就是 Ruby 脑残粉啊，爱一个语言就要接受它的全部，包括那些和它长得有些相似的远房亲戚，左手 CoffeeScript，右手 Elixir</li><li><p>Groovy：在某些时候用 Groovy 辅助我的 Java 项目少写了很多无意义代码，还是很有意义的</p><p>就像布丁在 <a href="http://yuheng.io/articles/i-hate-java" target="_blank" rel="external">我为什么讨厌 Java</a> 中说的一样，有些时候我也想证明自己是一个手艺人，而不是一个流水线上的生产工人。所以希望能够选择一些能够证明自己的编程语言，像是 Scala。但是现在觉得作为一个连 Java 都写不好的废柴，妄图换个语言就逆天改命，也是有点可笑的。所以明年就老实写 Java 了。</p><p>注：或许纠结于编程语言真的挺无聊的，但是我实在不认同「语言只是工具」这样的话，也许这句话在工作中确实奏效，如果现在我的上司让我改用另外一种编程语言写业务，我也有信心花 1-2 个礼拜就能开始有产出。但是这种认知太浅薄了，而且并不开心。</p><p>明年主要的重点主要放在学习分布式组件，包括看文档、阅读源码、了解原理及实现。以及写代码以外的一些东西，包括性能调优、监控、自动化等。</p><p>需要额外一提的是，虽然去年和今年都没有参加任何 Mooc 课程，但是明年应该会重新开始追一两门课，原因是 14-15 年那会的 Mooc 普遍就是将大学学堂的课搬到了网上，虽然也跟了一些不错的课程，但是由于都比较偏基础和理论，很快就感到厌烦了。前两天偶然看了看，发现现在也有一些不错的工业界课程了，觉得可以重新开始追一追了，我对 Mooc 这种学习方式还是相当喜爱的。</p></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><p> 该来的还是来了，年底我永远的失去了这世上对我最重要的人之一。</p><p> 明年会带着他的份，继续前行吧，更加努力的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天过去的好快…感觉什么都没做…&lt;/p&gt;
&lt;h2 id=&quot;工作&quot;&gt;&lt;a href=&quot;#工作&quot; class=&quot;headerlink&quot; title=&quot;工作&quot;&gt;&lt;/a&gt;工作&lt;/h2&gt;&lt;p&gt; 上半年主要在前公司主导了一次系统重构，将原有的老系统的基础框架基本全换了，用上了 Spri
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Armeria 学习笔记之断路器</title>
    <link href="http://www.scienjus.com/armeria-circuit-breaker/"/>
    <id>http://www.scienjus.com/armeria-circuit-breaker/</id>
    <published>2016-12-24T01:28:50.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么需要断路器"><a href="#为什么需要断路器" class="headerlink" title="为什么需要断路器"></a>为什么需要断路器</h2><p> 在分布式系统中，应用之间通过 RPC 调用，这意味着一个服务的健康状态不再只与该服务所在的应用有关，还与其所依赖的所有服务有关。这将会出现两个问题：</p><ol><li>一个服务被多个服务所依赖，如果该服务出现了故障，依赖其的服务都会受到影响</li><li><p>一个服务依赖多个服务，如果其中一个依赖服务出现了故障，该服务就会受到影响</p><p>也就是意味着在一整条服务的调用链路中，任何一个单元出现了故障（程序问题或是网络问题），都会造成连锁失败，这实际是非常不可靠的。</p></li></ol><p><img src="/uploads/2016/12/cascading_failure.jpg" alt=""></p><p> 断路器是一个基于客户端的自我保护行为，它会统计依赖服务的健康状态，在依赖服务不可靠时快速失败，而避免等待超时等行为对自身造成太大影响。</p><p><img src="/uploads/2016/12/fail_fast.jpg" alt=""></p><h2 id="如何实现一个断路器"><a href="#如何实现一个断路器" class="headerlink" title="如何实现一个断路器"></a>如何实现一个断路器</h2><p> 一个简单的断路器实现其实就是状态机，通过服务调用的成功、失败次数在开启和关闭之间切换。</p><p> 断路器的状态有：</p><ul><li>关闭：所有请求都正常进行</li><li>开启：阻止所有请求并快速失败</li><li><p>半开启：在开启和关闭状态的中间切换状态</p><p>断路器的生命周期为：</p></li></ul><ol><li>初始为关闭状态，所有请求正常执行，并统计成功、失败数</li><li>当失败率高于容忍的阈值后，切换为开启状态，阻止请求执行</li><li>开启状态持续一定时间后，切换为半开启状态，并通过一个请求</li><li>等待该请求的结果，如果成功切换为关闭状态，失败则重新恢复为开启状态</li></ol><p><img src="/uploads/2016/12/fsm.jpg" alt=""></p><h2 id="Armeria-源码分析"><a href="#Armeria-源码分析" class="headerlink" title="Armeria 源码分析"></a>Armeria 源码分析</h2><h3 id="断路器的设计"><a href="#断路器的设计" class="headerlink" title="断路器的设计"></a>断路器的设计</h3><p> 断路器的接口结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public interface CircuitBreaker &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 成功时执行该方法</span><br><span class="line">     */</span><br><span class="line">    void onSuccess ();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 失败时执行该方法</span><br><span class="line">     * @param cause 捕获的异常</span><br><span class="line">     */</span><br><span class="line"></span><br><span class="line">    void onFailure (Throwable cause);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 失败时执行该方法</span><br><span class="line">     */</span><br><span class="line">    void onFailure ();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 通过当前状态判断是否可以执行该次请求</span><br><span class="line">     */</span><br><span class="line"></span><br><span class="line">    boolean canRequest ();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 对请求的封装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">// 通过断路器判断是否可以执行该次请求</span><br><span class="line">if (circuitBreaker.canRequest ()) &#123;</span><br><span class="line">    // 发起请求</span><br><span class="line">    final O response;</span><br><span class="line">    try &#123;</span><br><span class="line">        response = delegate ().execute (ctx, req);</span><br><span class="line">    &#125; catch (Throwable cause) &#123;</span><br><span class="line">        // 发生异常时，记录失败并抛出异常</span><br><span class="line">        circuitBreaker.onFailure (cause);</span><br><span class="line">        throw cause;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    response.closeFuture ().handle (voidFunction ((res, cause) -&gt; &#123;</span><br><span class="line">        // 通过请求结果记录成功、失败</span><br><span class="line">        if (cause == null) &#123;</span><br><span class="line">            circuitBreaker.onSuccess ();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            circuitBreaker.onFailure (cause);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)).exceptionally (CompletionActions::log);</span><br><span class="line"></span><br><span class="line">    return response;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    // 如果断路器不允许进行该次请求，直接快速失败</span><br><span class="line">    throw new FailFastException (circuitBreaker);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 调用时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">    productClient.getProduct (productId);</span><br><span class="line">&#125; catch (TException e) &#123;</span><br><span class="line">    // 错误处理</span><br><span class="line">&#125; catch (FailFastException e) &#123;</span><br><span class="line">    // 对于快速失败的错误，可以返回本地缓存中的值，或是准备一个默认值</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="断路器的实现"><a href="#断路器的实现" class="headerlink" title="断路器的实现"></a>断路器的实现</h3><p>Armeria 的默认断路器实现是 <code>NonBlockingCircuitBreaker</code>，通过内部维护 <code>State</code> 用于状态切换。</p><p><code>canRequest</code> 实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public boolean canRequest () &#123;</span><br><span class="line">    final State currentState = state.get ();</span><br><span class="line">    if (currentState.isClosed ()) &#123;</span><br><span class="line">        // all requests are allowed during CLOSED</span><br><span class="line">        return true;</span><br><span class="line">    &#125; else if (currentState.isHalfOpen () || currentState.isOpen ()) &#123;</span><br><span class="line">        if (currentState.checkTimeout () &amp;&amp; state.compareAndSet (currentState, newHalfOpenState ())) &#123;</span><br><span class="line">            // changes to HALF_OPEN if OPEN state has timed out</span><br><span class="line">            logStateTransition (CircuitState.HALF_OPEN, null);</span><br><span class="line">            notifyStateChanged (CircuitState.HALF_OPEN);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        // all other requests are refused</span><br><span class="line">        notifyRequestRejected ();</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>当前状态为关闭时，断路器对于所有请求都会返回 <code>true</code></li><li>当状态为开启和半开启时，会先检查当前状态是否还在持续时间内（开启和半开启状态都有固定的持续时间），如果还在持续时间内就返回 <code>false</code></li><li>如果当前状态为开启，且已经到期了，就尝试将状态改为半开启，同时返回 <code>true</code> 通过一个请求去校验服务器状态</li><li>如果当前状态为半开启，且已经到期了（这种情况出现的原因只可能是之前切换状态时，通过的那个请求没有得到反馈），就清空状态，再放出一个新的请求。</li></ul><p><code>onSuccess</code> 实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void onSuccess () &#123;</span><br><span class="line">    final State currentState = state.get ();</span><br><span class="line">    if (currentState.isClosed ()) &#123;</span><br><span class="line">        // fires success event</span><br><span class="line">        final Optional&lt;EventCount&gt; updatedCount = currentState.counter ().onSuccess ();</span><br><span class="line">        // notifies the count if it has been updated</span><br><span class="line">        updatedCount.ifPresent (this::notifyCountUpdated);</span><br><span class="line">    &#125; else if (currentState.isHalfOpen ()) &#123;</span><br><span class="line">        // changes to CLOSED if at least one request succeeds during HALF_OPEN</span><br><span class="line">        if (state.compareAndSet (currentState, newClosedState ())) &#123;</span><br><span class="line">            logStateTransition (CircuitState.CLOSED, null);</span><br><span class="line">            notifyStateChanged (CircuitState.CLOSED);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>当前状态为关闭时统计成功数，成功事件并不会造成关闭状态的状态变更</li><li>当前状态为半开启时，说明切换为半开启状态时通过的那个请求成功了，将状态切换为关闭</li></ul><p><code>onFailure</code> 实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void onFailure () &#123;</span><br><span class="line">    final State currentState = state.get ();</span><br><span class="line">    if (currentState.isClosed ()) &#123;</span><br><span class="line">        // fires failure event</span><br><span class="line">        final Optional&lt;EventCount&gt; updatedCount = currentState.counter ().onFailure ();</span><br><span class="line">        // checks the count if it has been updated</span><br><span class="line">        updatedCount.ifPresent (count -&gt; &#123;</span><br><span class="line">            // changes to OPEN if failure rate exceeds the threshold</span><br><span class="line">            if (checkIfExceedingFailureThreshold (count) &amp;&amp;</span><br><span class="line">                state.compareAndSet (currentState, newOpenState ())) &#123;</span><br><span class="line">                logStateTransition (CircuitState.OPEN, count);</span><br><span class="line">                notifyStateChanged (CircuitState.OPEN);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                notifyCountUpdated (count);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; else if (currentState.isHalfOpen ()) &#123;</span><br><span class="line">        // returns to OPEN if a request fails during HALF_OPEN</span><br><span class="line">        if (state.compareAndSet (currentState, newOpenState ())) &#123;</span><br><span class="line">            logStateTransition (CircuitState.OPEN, null);</span><br><span class="line">            notifyStateChanged (CircuitState.OPEN);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>当前状态为关闭时统计失败数，当失败率超过阈值时转换为半开启状态</li><li>当前状态为半开启时，说明切换为半开启状态时通过的那个请求失败了，重新将状态切换为关闭</li></ul><p><code>NonBlockingCircuitBreaker</code> 使用了 <code>AtomicReference</code> 的 <code>compareAndSet</code> 方法切换状态，这样可以保证在并发时多个线程中只会有一个线程真正的切换状态，实现了非阻塞且线程安全。</p><p> 在关闭状态时使用了 <code>SlidingWindowCounter</code> 的实现统计成功失败数，内部实现用 <code>LongAdder</code> 原子记录成功、失败数，并通过时间分段存储在一个 <code>ConcurrentLinkedQueue</code> 中。</p><hr><p> 本文是通过阅读 Armeria 源码和 Line 技术博客整理出的笔记，其中还有一些内容并没有介绍，可以移步到原文阅读：</p><ul><li><a href="https://github.com/line/armeria" target="_blank" rel="external">line / armeria</a></li><li><a href="http://developers.linecorp.com/blog/?p=3882" target="_blank" rel="external">Circuit breakers for distributed services</a></li><li><p><a href="http://developers.linecorp.com/blog/?p=3918" target="_blank" rel="external">Applying CircuitBreaker to Channel Gateway</a></p><p>一些其他资料：</p></li><li><p><a href="http://coolshell.cn/articles/11454.html" target="_blank" rel="external">从 LongAdder 看更高效的无锁实现</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;为什么需要断路器&quot;&gt;&lt;a href=&quot;#为什么需要断路器&quot; class=&quot;headerlink&quot; title=&quot;为什么需要断路器&quot;&gt;&lt;/a&gt;为什么需要断路器&lt;/h2&gt;&lt;p&gt; 在分布式系统中，应用之间通过 RPC 调用，这意味着一个服务的健康状态不再只与该服务所在的
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>[Elasticsearch in Action读书笔记]第三章 索引、更新和删除数据</title>
    <link href="http://www.scienjus.com/elasticsearch-in-action-3/"/>
    <id>http://www.scienjus.com/elasticsearch-in-action-3/</id>
    <published>2016-06-26T23:17:31.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h3><p> 类型只是逻辑上的概念，实际在物理结构上是没有这个概念的。所以一个字段如果分布在相同索引不同类型的文档中，字段的类型必须是相同的。</p><p> 通过<code>GET /index-name/_mapping [/type-name]</code>可以查看类型的映射（如果不指定类型名，就是查看该索引的所有映射）。</p><p> 通过<code>PUT /index-name/_mapping [/type-name]</code>可以手动添加和修改映射，但是无法修改已经存在文档的字段映射。</p><h3 id="基础字段类型"><a href="#基础字段类型" class="headerlink" title="基础字段类型"></a>基础字段类型</h3><p>Elasticsearch 的基础字段类型分为字符串（<code>string</code>）、数字（<code>number</code>）、布尔（<code>boolean</code>）和日期（<code>date</code>）四种。</p><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><p> 分析器是字符串映射中一个比较重要的概念，它负责分析文本内容，并对其做一些搜索相关的处理。例如默认的分析器会将所有字母都转换为小写，保证搜索时不需要区分大小写。</p><p> 分析器会将文本内容解析成一个个词元，词元是文本中能被索引和搜索的基础单元，它可以是一个单词、一个 ip 地址或是一个邮箱。</p><p> 通过在映射中设置字段的<code>index</code>为<code>not_analyzed</code>可以使该字段跳过分析阶段，将整个值作为一个词元索引。</p><p> 如果设置<code>index</code>为<code>no</code>，那么该字段不会被索引，也就是说无法通过该字段进行搜索。当一个字段不需要被搜索时，这样做可以减少索引空间占用并加快索引和查询的速度。</p><h4 id="数字"><a href="#数字" class="headerlink" title="数字"></a>数字</h4><p> 数字类型分为整型的<code>byte</code>，<code>short</code>，<code>integer</code>和<code>long</code>，浮点型的<code>float</code>和<code>double</code>。这些类型的存储空间和范围和 Java 中是相同的。</p><p> 如果不确定索引数据的范围，就使用最大范围的<code>long</code>和<code>double</code>，虽然会占用更多的空间导致索引变大和搜索变慢。但是最起码不会在建立索引时出现超出范围（<code>out-of-range</code>）错误。</p><h4 id="日期"><a href="#日期" class="headerlink" title="日期"></a>日期</h4><p>日期类型在索引时会转换为 long 类型的 unix 时间戳，在传输时则会格式化为 string。默认的格式化方案为 ISO 8601，也可以自己指定格式化方式方案。</p><p>Elasticsearch 内置了很多可选的格式化方案，也可以自定义格式。</p><h4 id="布尔"><a href="#布尔" class="headerlink" title="布尔"></a>布尔</h4><p> 在 Lucene 中会将<code>true</code>、<code>false</code>转化为<code>T</code>和<code>F</code>索引。</p><h3 id="复杂字段类型"><a href="#复杂字段类型" class="headerlink" title="复杂字段类型"></a>复杂字段类型</h3><p>Elasticsearch 还提供了两种方式可以使一个字段拥有多个值。分别是数组（<code>array</code>）和复杂字段（<code>multi-fields</code>）。</p><h4 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h4><p> 数组的映射定义方法和普通字段的定义方法一样，例如一个 string 的映射就可以直接用于 string 数组。这在 Lucene 中仅仅是对一个字段的多个词元进行了索引。</p><h4 id="复杂字段"><a href="#复杂字段" class="headerlink" title="复杂字段"></a>复杂字段</h4><p> 复杂字段可以使一个字段拥有多个映射配置。例如一个<code>name</code>字段，在某些场景下会使用分词匹配，而有些地方需要完全匹配，那么就需要用这种方式配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;users&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">        &quot;index&quot;: &quot;analyzed&quot;,</span><br><span class="line">        &quot;fields&quot;: &#123;</span><br><span class="line">          &quot;verbatim&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">            &quot;index&quot;: &quot;not_analyzed&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 需要分词匹配时，使用<code>name</code>搜索，需要全部匹配时，使用<code>name.verbatim</code>搜索。</p><h3 id="内置字段"><a href="#内置字段" class="headerlink" title="内置字段"></a>内置字段</h3><p>Elasticsearch 内置了许多字段，这些字段多用于标示文档的特征。</p><h4 id="source"><a href="#source" class="headerlink" title="\_source"></a>\_source</h4><p><code>_source</code>字段存储了文档的源数据。它可以通过设置<code>enabled</code>属性决定是否需要存储。在默认情况下这个值是<code>true</code>。</p><p> 由于很多重要的功能都需要这个字段（例如更新文档和高亮内容），并且它的存储十分廉价，所以在 2.0 版本已经删除了这个配置。</p><p> 通过配置映射的<code>store</code>可以决定该字段是否存储，这样可以节约一些空间。</p><h4 id="all"><a href="#all" class="headerlink" title="\_all"></a>\_all</h4><p><code>_all</code>字段会将文档的所有字段内容汇总并索引，所以当通过该字段搜索时，只要有任意字段满足条件都会返回该文档。在不确定具体查询某个字段的情境下十分有用。</p><p> 如果总是在确定的字段上搜索，那么可以在映射中关闭<code>_all</code>字段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&quot;users&quot;: &#123;</span><br><span class="line">  &quot;_all&quot;: &#123;</span><br><span class="line">    &quot;enabled&quot;: false</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 或者可以通过<code>include_in_all</code>属性使某个字段不会出现在<code>_all</code>字段中，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;users&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">        &quot;index&quot;: &quot;analyzed&quot;,</span><br><span class="line">        &quot;include_in_all&quot;: false</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这样可以节约索引空间，并加快查询和索引的速度。</p><h4 id="ttl"><a href="#ttl" class="headerlink" title="\_ttl"></a>\_ttl</h4><p><code>_ttl</code>字段可以使文档在一段时间后自动删除。像是 Redis 中的<code>expire</code>指令。</p><h3 id="标识字段："><a href="#标识字段：" class="headerlink" title="标识字段："></a>标识字段：</h3><p>Elasticsearch 通过<code>_index</code>、<code>_type</code>、<code>_id</code>和<code>_version</code>等字段标识某个文档，这些字段分别代表着文档所存放的索引和类型、文档的 id 和版本。</p><p> 在索引文档时可以显示的指定文档 id，或是让 Elasticsearch 自动生成 id。</p><h3 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h3><h4 id="使用文档更新"><a href="#使用文档更新" class="headerlink" title="使用文档更新"></a>使用文档更新</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">POST /index-name/type-name/id/_update</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;Roy&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 在<code>doc</code>下设置需要更新的字段和值。</p><p> 当对应 id 的文档不存在时，更新不会产生任何效果，但是可以通过设置<code>upsert</code>字段使得添加内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">POST /index-name/type-name/id/_update</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;Roy&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;upsert&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;Roy&quot;,</span><br><span class="line">    &quot;created_at&quot;: &quot;2016-06-04&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这样产生的效果是，如果 id 不存在对应的文档，将 upsert 的内容作为文档索引，如果存在的话，将 doc 的内容更新。</p><h4 id="使用脚本更新"><a href="#使用脚本更新" class="headerlink" title="使用脚本更新"></a>使用脚本更新</h4><p> 使用 doc 的方式更新一个文档很有效，但是如果要更新多个文档就比较麻烦了。</p><p> 一个比较常见的需求，需要将商城中所有商品的价格都增加 10。如果使用上面这种方法，就需要取出每个文档，计算价格后在更新回去，效率是极低的。</p><p> 使用脚本更新便可以很简单的解决问题，只需要类似于下面这种语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST /index-name/type-name/id/_update</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;script&quot;: &quot;ctx._source.price += price_diff&quot;,</span><br><span class="line">  &quot;params&quot;: &#123;</span><br><span class="line">    &quot;price_diff&quot;: 10</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="并发问题"><a href="#并发问题" class="headerlink" title="并发问题"></a>并发问题</h4><p>Elasticsearch 更新文档的流程：</p><ol><li>取出已经索引的旧文档</li><li>将更改的字段合并到文档中</li><li><p>重新索引新文档</p><p>这个操作并非为原子操作，所以在并发更新时会造成一些错误。</p><p>例如有一个文档：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;K&quot;,</span><br><span class="line">  &quot;age&quot;: 22</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 同时有两个查询要修改该文档，分别是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;W&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 和</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123;</span><br><span class="line">    &quot;age&quot;: 25</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 希望的结果应该是两条更新都成功了，文档变成这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;W&quot;,</span><br><span class="line">  &quot;age&quot;: 25</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 但是实际上，如果这两条语句真的是同时操作的话，最后的结果只会有一条成功，但是其实是后一条的更新将前一条的更新覆盖掉了。</p><p> 它们的流程是：</p><ol><li>更新语句 1 开始执行，首先取出旧文档</li><li>更新语句 2 开始执行，同样取出旧文档</li><li>更新语句 1 开始合并更新，合并结果为<code>{&quot;name&quot;: &quot;W&quot;, &quot;age&quot;: 22}</code></li><li>更新语句 2 开始合并更新，合并结果为<code>{&quot;name&quot;: &quot;K&quot;, &quot;age&quot;: 25}</code></li><li>更新语句 1 重新索引文档，文档变为<code>{&quot;name&quot;: &quot;W&quot;, &quot;age&quot;: 22}</code></li><li><p>更新语句 2 重新索引文档，文档变为<code>{&quot;name&quot;: &quot;K&quot;, &quot;age&quot;: 25}</code></p><p>于是更新语句 1 的结果就被更新语句 2 的结果覆盖掉了。</p></li></ol><p><img src="/uploads/2016/06/multiple-updates.jpg" alt="并发更新可能导致的错误"></p><p> 对于这种情况，Elasticsearch 给出的解决方案是给文档增加一个版本号，也就是常说的乐观锁。每次修改都会将版本号自增 1，这样修改时就可以知道在查询文档之后是否有其他更新同样修改了该文档。</p><p><img src="http://7xk046.com1.z0.glb.clouddn.com/wp-content/uploads/2016/06/concurrency-control.jpg" alt="乐观锁"></p><p> 乐观锁假定大部分情况下不会发生冲突，所以它允许并发操作文档并在真正发生冲突时报错。当发生冲突时，可以通过指定<code>retry_on_conflict</code>参数设定重试次数。</p><p> 开发者也可以维护自己的版本号，只需要指定<code>version_type=external</code>并且每次都传一个更高的<code>version</code>即可。</p><h3 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h3><h4 id="删除单个文档"><a href="#删除单个文档" class="headerlink" title="删除单个文档"></a>删除单个文档</h4><p> 通过<code>DELETE /index-name/type-name/id</code>可以删除指定 id 的文档。</p><p> 当删除一个文档时，会将这个文档标记为已删除，然后在合并时真正去除这个文档。合并需要额外的 CPU 和磁盘 I/O 资源，好在它是一个异步操作</p><h4 id="批量删除文档"><a href="#批量删除文档" class="headerlink" title="批量删除文档"></a>批量删除文档</h4><p>Elasticsearch 还提供根据自定义的查询条件删除对象。只需要将搜索 API 的请求方式从<code>GET</code>改为<code>DELETE</code>，并将<code>_search</code>改为<code>_query</code>即可。</p><p> 例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /index-name/type-name/_query?q=keyWords</span><br></pre></td></tr></table></figure><h4 id="并发问题-1"><a href="#并发问题-1" class="headerlink" title="并发问题"></a>并发问题</h4><p> 删除也会有并发问题，例如同更新操作一起进行时，并且这件事情无法通过外部的版本控制实现，因为任何的外部版本控制都会将版本信息存放在文档中。</p><p> 为了解决这个问题，Elasticsearch 会将删除文档的版本号保留一段时间，以便阻止低版本的更新请求。默认的保留时间是 60 秒，或是通过<code>elasticsearcy.yml</code>中的<code>index.gc_deletes</code>属性配置。</p><h4 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h4><p> 删除索引会删除掉该索引下的所有文档。这个操作的速度很快，因为会直接将所有分片中包含该索引的文件删除。</p><p> 通过删除<code>_all</code>索引可以删除掉所有索引。这个操作十分危险，所以可以在<code>elasticsearch.yml</code>中设置<code>action.destructive_requires_name: true</code>阻止该操作。</p><h4 id="删除类型"><a href="#删除类型" class="headerlink" title="删除类型"></a>删除类型</h4><p> 删除类型可以直接删除该类型下的所有文档。但是底层实现还是首先去查询出该类型的所有文档再一一删除，所以实际上这种行为比起删除索引要耗费更多的时间，并且占用更多的资源。</p><p> 删除索引会很快，因为就是直接将所有分片中包含索引的文件删除了。</p><h4 id="关闭索引"><a href="#关闭索引" class="headerlink" title="关闭索引"></a>关闭索引</h4><p> 在某些情况下，关闭索引和可以替代删除索引。关闭后的索引将禁止读写直到再次开启。</p><p> 例如使用 Elasticsearch 记录日志流水，一般会在每天创建一个新的索引记录当天的日志。一般来说旧日志之后还会用与查询和统计，但是直接保留的话又会占用内存资源，这时候就可以暂时关闭改索引减少资源使用，也不会损失数据。</p><p> 关闭索引的方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST index-name/_close</span><br></pre></td></tr></table></figure><p> 重新开启的方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST index-name/_open</span><br></pre></td></tr></table></figure><p> 当索引关闭时，唯一存放在内存中的数据只有索引的元数据，例如名称以及存储在哪些分片中。如果有足够的磁盘空间并且不确定是否还会需要再次查询这些数据，比起删除索引，关闭索引是更合适的选择。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;映射&quot;&gt;&lt;a href=&quot;#映射&quot; class=&quot;headerlink&quot; title=&quot;映射&quot;&gt;&lt;/a&gt;映射&lt;/h3&gt;&lt;p&gt; 类型只是逻辑上的概念，实际在物理结构上是没有这个概念的。所以一个字段如果分布在相同索引不同类型的文档中，字段的类型必须是相同的。&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>使用Observer实现HBase到Elasticsearch的数据同步</title>
    <link href="http://www.scienjus.com/hbase-observer-elasticsearch/"/>
    <id>http://www.scienjus.com/hbase-observer-elasticsearch/</id>
    <published>2016-06-04T05:22:42.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="多数据源的数据同步"><a href="#多数据源的数据同步" class="headerlink" title="多数据源的数据同步"></a>多数据源的数据同步</h3><p> 多个数据源中的数据同步问题，无非就三种解决方式：</p><ol><li>客户端双写，分别将数据写入两个数据源（同步、异步）</li><li>主数据源在收到数据后推给辅数据源（同步、异步）</li><li><p>辅数据源从主数据源中拉取数据（轮训、监听，全量、增量）</p><p>具体到 HBase 同步到 Elasticsearch 时，后两种方式具体对应的方案就是 HBase 的 Observer 和 Elasticsearch 的 River，这两种方式都可以使开发者在数据源中嵌入自己的业务逻辑，并且依托于集群可以轻松地保证高可用。</p><p>但是非常遗憾的是，要使用 River 高效的同步数据，必须要有一种拉取增量数据的方式，而在 HBase 中这并没有很好的方法实现，所以本文将会介绍使用 Observer 的方法。</p><p>题外话：Elasticsearch 的 MySQL River 有两种实现：<code>elasticsearch-river-jdbc</code>和<code>elasticsearch-river-mysql</code>。前者简单的通过 SQL 查询数据同步到 Elasticsearch，所以必须要在表中定义更新时间的字段才能完成增量更新，而且它无法得知哪些数据删除掉了，除非增加并使用逻辑删除字段。而后者则通过 MySQL 的主从复制机制，读取 Binlog 完成增量数据的同步，要更加方便和实用很多。</p></li></ol><h3 id="什么是-Observer"><a href="#什么是-Observer" class="headerlink" title="什么是 Observer"></a>什么是 Observer</h3><p>HBase 0.92 版本引入了协处理器（Coprocessor），可以使开发者将自己的代码嵌入到 HBase 中，其中协处理器分为两大块，一个是终端（Endpoint），另一个是本文将要介绍的观察者（Observer）。</p><p>Observer 有些类似于 MySQL 中的触发器（Trigger），它可以为 HBase 中的操作添加钩子，并在事件发生后实现自己的的业务逻辑。</p><p>Observer 主要分为三种：</p><ul><li>RegionObserver：增删改查相关，例如 Get、Put、Delete、Scan 等</li><li>WALObserver：WAL 操作相关</li><li><p>MasterObserver：DDL-类型相关，例如创建、删除、修改数据表等</p><p>数据同步将会使用 RegionObserver 监听 Put 和 Delete 事件。</p></li></ul><h3 id="如何实现自己的-Observer"><a href="#如何实现自己的-Observer" class="headerlink" title="如何实现自己的 Observer"></a>如何实现自己的 Observer</h3><p> 每一个 Observer 都是一个 Jar 包。首先需要引入<code>hbase-server</code>包，并实现如<code>BaseRegionObserver</code>等 HBase 提供的相关接口，重写需要监听对应事件的方法。</p><p> 实现数据同步功能可以重写<code>postPut</code>和<code>putDelete</code>方法监听 Put 和 Delete 事件。</p><p> 下面就是一个最简单的例子，在这两个方法中分别得到表名和 RowKey，然后输出到 HBase 默认的日志中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public class SimpleObserver extends BaseRegionObserver &#123;</span><br><span class="line"></span><br><span class="line">    private static final Log logger = LogFactory.getLog (SimpleObserver.class);</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void postPut (ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException &#123;</span><br><span class="line">        // 拿到表名</span><br><span class="line">        String table = e.getEnvironment ().getRegion ().getRegionInfo ().getTable ().getNameAsString ();</span><br><span class="line">        // 拿到 row key</span><br><span class="line">        String rowKey = new String (delete.getRow ());</span><br><span class="line">        logger.info (&quot;a put event! table: &quot; + table + &quot;, row key: &quot; + rowKey);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void postDelete (ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Delete delete, WALEdit edit, Durability durability) throws IOException &#123;</span><br><span class="line">        // 拿到表名</span><br><span class="line">        String table = e.getEnvironment ().getRegion ().getRegionInfo ().getTable ().getNameAsString ();</span><br><span class="line">        // 拿到 row key</span><br><span class="line">        String rowKey = new String (delete.getRow ());</span><br><span class="line">        logger.info (&quot;a delete event! table: &quot; + table + &quot;, row key: &quot; + rowKey);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 之后将项目打包，上传到 HDFS 中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /observers</span><br><span class="line">hdfs dfs -put simple-observer.jar /observers</span><br></pre></td></tr></table></figure><p> 使用 HBase Shell 创建一个表，将这个 Observer 挂到该表中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create &apos;test_observer&apos;</span><br><span class="line"></span><br><span class="line">disable &apos;test_observer&apos;</span><br><span class="line"></span><br><span class="line">alter ‘test_observer&apos;, METHOD =&gt; &apos;table_att&apos;, &apos;coprocessor&apos; =&gt; &apos;hdfs:///observers/simple-observer.jar|com.scienjus.observer.SimpleObserver|&apos;</span><br><span class="line"></span><br><span class="line">enable &apos;test_observer&apos;</span><br></pre></td></tr></table></figure><p><code>coprocessor</code>的值是一个字符串，由以下几个部分组成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jar 地址（如果在配置文件中定义了 CLASS_PATH 可以不填）|类名（包含包路径）|优先级|自定义属性</span><br></pre></td></tr></table></figure><p> 此时通过<code>describe</code>可以看到这个表已经挂上了观察者：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">describe &apos;test_observer&apos;</span><br><span class="line"></span><br><span class="line">Table test_observer is ENABLED</span><br><span class="line"></span><br><span class="line">test_observer, &#123;TABLE_ATTRIBUTES =&gt; &#123;coprocessor$1 =&gt; &apos;hdfs:///observers/simple-observer.jar|com.scienjus.observer.SimpleObserver|&apos;&#125;</span><br><span class="line">COLUMN FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, VERSIO</span><br><span class="line">NS =&gt; &apos;1&apos;, COMPRESSION =&gt; &apos;NONE&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, TTL =&gt; &apos;FOREVER&apos;, KEEP_DELETED_CELLS =&gt; &apos;FALSE&apos;</span><br><span class="line">, BLOCKSIZE =&gt; &apos;65536&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;&#125;</span><br><span class="line">1 row (s) in 0.2600 seconds</span><br></pre></td></tr></table></figure><p> 向这个表中进行 Put 和 Delete 操作，就可以看到对应的日志了。</p><h3 id="如何同步数据到-Elasticsearch"><a href="#如何同步数据到-Elasticsearch" class="headerlink" title="如何同步数据到 Elasticsearch"></a>如何同步数据到 Elasticsearch</h3><p>Elasticsearch 官方的 Java 客户端提供了一个名为<code>BulkProcessor</code>的接口，这个接口可以轻易的实现一个批量发送请求的缓冲池。</p><p> 下面这段代码创建了一个缓冲池，它会定期批量发送堆积的请求，触发条件为：</p><ul><li>每 2 秒触发一次</li><li>当堆积的请求数量达到 1000 个时，触发一次</li><li>当堆积的请求达到 100mb 时，触发一次</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">processor = BulkProcessor.builder (client, new BulkProcessor.Listener () &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void beforeBulk (long executionId, BulkRequest request) &#123;</span><br><span class="line">        logger.info (&quot;before bulk !!!&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void afterBulk (long executionId, BulkRequest request, BulkResponse response) &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void afterBulk (long executionId, BulkRequest request, Throwable failure) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">        .setBulkActions (1000)</span><br><span class="line">        .setBulkSize (new ByteSizeValue (100, ByteSizeUnit.MB))</span><br><span class="line">        .setFlushInterval (TimeValue.timeValueSeconds (2))</span><br><span class="line">        .setConcurrentRequests (5)</span><br><span class="line">        .build ();</span><br></pre></td></tr></table></figure><p> 同时它还提供了一个监听器，可以在发送请求前、发送请求后、发送请求出现异常时监听到对应事件并进行处理。可以在其中处理失败情况，例如重发或是记录日志。</p><p> 将 Observer 和 BulkProcessor 结合起来，只需要在 postPut 时将文档转为 JSON 生成 Upsert 请求加入缓冲池，在 postDelete 时将 RowKey 作为 id 生成删除请求加入缓冲池即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void postPut (ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        // 拿到表名</span><br><span class="line">        String table = e.getEnvironment ().getRegion ().getRegionInfo ().getTable ().getNameAsString ();</span><br><span class="line">        // 拿到 id</span><br><span class="line">        String id = new String (put.getRow ());</span><br><span class="line">        logger.info (&quot;a put! table: &quot; + table + &quot;, key: &quot; + id);</span><br><span class="line">        // 拿到文档内容</span><br><span class="line">        Map&lt;String, String&gt; doc = new HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        for (List&lt;Cell&gt; cells : put.getFamilyCellMap ().values ()) &#123;</span><br><span class="line">            for (Cell cell : cells) &#123;</span><br><span class="line">                doc.put (new String (CellUtil.cloneQualifier (cell)), new String (CellUtil.cloneValue (cell)));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        processor.add (new UpdateRequest ()</span><br><span class="line">                .index (index)</span><br><span class="line">                .type (type)</span><br><span class="line">                .id (id)</span><br><span class="line">                .doc (doc)</span><br><span class="line">                .docAsUpsert (true)</span><br><span class="line">        );</span><br><span class="line">    &#125; catch (RuntimeException ex) &#123;</span><br><span class="line">        // TODO 记录运行异常</span><br><span class="line">        logger.info (&quot;error!&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void postDelete (ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Delete delete, WALEdit edit, Durability durability) throws IOException &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        // 拿到表名</span><br><span class="line">        String table = e.getEnvironment ().getRegion ().getRegionInfo ().getTable ().getNameAsString ();</span><br><span class="line">        // 拿到 id</span><br><span class="line">        String id = new String (delete.getRow ());</span><br><span class="line">        logger.info (&quot;a delete! table: &quot; + table + &quot;, key: &quot; + id);</span><br><span class="line">        processor.add (new DeleteRequest ()</span><br><span class="line">                .index (index)</span><br><span class="line">                .type (type)</span><br><span class="line">                .id (id)</span><br><span class="line">        );</span><br><span class="line">    &#125; catch (RuntimeException ex) &#123;</span><br><span class="line">        // TODO 记录运行异常</span><br><span class="line">        logger.info (&quot;error!&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 最后别忘了监听<code>stop</code>事件，将缓冲池和客户端都关闭：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void stop (CoprocessorEnvironment e) throws IOException &#123;</span><br><span class="line">    processor.close ();</span><br><span class="line">    client.close ();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;多数据源的数据同步&quot;&gt;&lt;a href=&quot;#多数据源的数据同步&quot; class=&quot;headerlink&quot; title=&quot;多数据源的数据同步&quot;&gt;&lt;/a&gt;多数据源的数据同步&lt;/h3&gt;&lt;p&gt; 多个数据源中的数据同步问题，无非就三种解决方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>[Elasticsearch in Action读书笔记]第二章 深入功能</title>
    <link href="http://www.scienjus.com/elasticsearch-in-action-2/"/>
    <id>http://www.scienjus.com/elasticsearch-in-action-2/</id>
    <published>2016-05-05T23:18:17.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="逻辑结构"><a href="#逻辑结构" class="headerlink" title="逻辑结构"></a>逻辑结构</h3><p>Elasticsearch 的逻辑结构分为索引、类型和文档。</p><h4 id="文档（Document）"><a href="#文档（Document）" class="headerlink" title="文档（Document）"></a>文档（Document）</h4><p>Elasticsearch 是面向文档的，通常使用 JSON 表示数据。</p><p> 文档的地位有些类似于关系型数据库的行（Row），但是有很大不同：</p><ol><li>文档的结构是独立的，每个文档都包含字段名和与其对应的值</li><li>文档是有层级的，字段的值依旧可以是一个文档</li><li>文档是弹性的，每个文档的字段不需要完全相同（但是相同字段的类型必须相同）</li></ol><h4 id="类型（Type）"><a href="#类型（Type）" class="headerlink" title="类型（Type）"></a>类型（Type）</h4><p> 类型是文档的容器，对应着关系型数据库中的表（Table）。</p><p> 每个类型都会有一个映射（Mapping），用于记录文档字段的类型和配置信息。</p><p> 在默认情况下，Elasticsearch 会自动推断插入文档的字段类型，例如通过<code>7</code>得出类型为<code>long</code>。但是这样会有局限性，例如无法将<code>40,116</code>识别为一个地理坐标点，所以最好在插入文档前显式的建立映射。</p><h4 id="索引（Index）"><a href="#索引（Index）" class="headerlink" title="索引（Index）"></a>索引（Index）</h4><p> 索引是类型的容器，也是一个独立的文档集合，类似于数据库（Database）。每个索引都会存放在磁盘的一组文件中，包含它所有的类型映射和一些配置，例如分片数量、刷新间隔时间等。</p><p><img src="/uploads/2016/05/physical-layout.jpg" alt="逻辑结构">￼</p><p> 上图中的 Elasticsearch 实例包含了两个索引：get-together 和 get-together-blog，前者含有两个类型：event 和 group，后者只有一个类型 posts，这些类型中又包含着一些文档。</p><h3 id="物理结构"><a href="#物理结构" class="headerlink" title="物理结构"></a>物理结构</h3><p>Elasticsearch 的物理结构分为节点和分片。</p><h4 id="分片（Shard）"><a href="#分片（Shard）" class="headerlink" title="分片（Shard）"></a>分片（Shard）</h4><p> 分片是 Elasticsearch 中的最小单元，它实际就是 Lucene 中的索引：一个包含倒排索引文件的文件夹。</p><p><img src="/uploads/2016/05/lucene-index.jpg" alt="Lucene 索引"></p><p> 上图就是一个分片，这个倒排索引文件包含着文档的元数据，例如词元字典、词频等信息。词元字典包含了每个词元都出现在哪些文档中，这样在搜索时就可以直接找到对应的文档，而不用全部遍历一遍。词频记录了每个文档出现了多少次该词元，可以用于计算相关度。</p><p> 分片包含主分片和复制分片，复制分片就是主分片的复制品。它可以用于处理搜索请求，或是在主分片发生故障时自动晋升为新的主分片。</p><p> 一个索引可以有一到多个主分片，每个主分片可以有零到多个复制分片。复制分片的数量可以随时修改，但是主分片的数量必须在创建索引时确定，并且不能修改。</p><p> 分片对应用程序是透明的，应用程序不需要了解分片到底是如何运作的。它只需要连接集群中的任意一个节点并发送请求即可。</p><p><img src="/uploads/2016/05/shards.jpg" alt="分片"></p><p> 上图中的索引有 2 个主分片，每个主分片有 2 个复制分片，所以一共是 6 个分片。</p><h4 id="节点（Node）"><a href="#节点（Node）" class="headerlink" title="节点（Node）"></a>节点（Node）</h4><p> 每个 Elasticsearch 实例都是一个节点，多个节点可以加入同一个集群，这样集群中的数据就会平均分散在多台机器中，从而提高性能和可用性。如果每个主分片都有至少一个复制分片，即使主分片所在的节点出现故障，集群依旧可以正常提供服务。</p><p> 一个节点上存在相同的多个分片（无论是主分片还是复制分片）是没有任何意义的，所以集群在节点数量不够时，不会分配出全部分片。</p><p> 很重要的一点：必须要保证集群中节点间的通信速度足够快，否则会出现脑裂（split brain）现象，也就是集群中的两部分无法相互通信，并都认为对方已经退出了集群。</p><p> 最简单的 Elasticsearch 集群只有一个节点：一台机器运行一个 Elasticsearch 实例。</p><p> 提升集群处理能力的方法有两种：通过增加节点的方式称为水平扩展（horizontal scaling），通过增加机器硬件配置的方式称为垂直拓展（vertical scaling）。在大部分情况下水平拓展的性价比都要好过垂直拓展。</p><p><img src="/uploads/2016/05/logical-layout.jpg" alt="物理结构"></p><p> 如上图，默认情况下 Elasticsearch 会对每个索引创建 5 个主分片，而每个主分片又会有 1 个复制分片，这些分片将会平均散布在集群的各个节点中。</p><h3 id="索引和搜索文档"><a href="#索引和搜索文档" class="headerlink" title="索引和搜索文档"></a>索引和搜索文档</h3><h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><p> 当索引一个文档时，Elasticsearch 会通过固定的 Hash 算法将它发送到指定的主分片。默认的 Hash 算法很简单，只是将文档 id 的 hash 值对主分片的个数取模，这也是主分片数量无法改变的原因：一旦分片的数量改变的，Hash 的结果也会改变，之前的文档就找不到了。</p><p> 之后文档会被该主分片的所有复制分片索引，保证复制分片和主分片是同步的，所以复制分片可以处理搜索请求，或是在主分片故障时自动提升为主分片。</p><p> 创建文档的方式：PUT 请求<code>索引名 / 类型名 / 文档 id</code>，内容为 JSON 格式的文档，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;http://localhost:9200/get-together/group/1?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;Elasticsearch Denver&quot;,</span><br><span class="line">  &quot;organizer&quot;: &quot;Lee&quot;</span><br><span class="line">&#125;</span><br><span class="line">&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;get-together&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;group&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;created&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 返回结果中<code>created</code>表示创建的结果，<code>_id</code>为文档的主键，这个请求指定了主键，也可以选择由 Elasticsearch 自动生成主键。<code>_version</code>为文档的版本号，从<code>1</code>开始，文档每次更新都会自增。</p><p> 在索引文档时会自动创建不存在的索引和类型。也可以通过 PUT 请求<code>索引名</code>手动创建，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;http://localhost:9200/new-index?pretty&apos;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 手动创建索引的好处是可以自定义一些配置，例如指定分片数量。</p><p> 在索引文档时，如果字段的映射不存在，Elasticsearch 会自动推断出映射并创建，可以通过 GET 请求<code>索引名 /_mapping/ 类型名</code>查看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/_mapping/group?pretty&apos;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;get-together&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;group&quot; : &#123;</span><br><span class="line">        &quot;properties&quot; : &#123;</span><br><span class="line">          &quot;name&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;string&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;organizer&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;string&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 返回结果中的<code>properties</code>为字段的映射信息，包含字段名、字段类型和配置。</p><h4 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h4><p> 直接通过 GET 请求<code>索引名 / 类型名 / 文档 id</code>就可以获取具体某个文档，例如获取刚才插入的文档：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/group/1?pretty&apos;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;get-together&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;group&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;Elasticsearch Denver&quot;,</span><br><span class="line">    &quot;organizer&quot;: &quot;Lee&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 返回内容包含了文档所在的索引、类型以及文档的主键、版本和数据。如果 id 不存在，返回的<code>found</code>字段将为<code>false</code>。</p><p> 通过 id 获取文档的速度非常快，并且是实时的。而搜索是接近实时的，因为搜索需要等待刷新索引。</p><h4 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h4><p> 当搜索文档时，Elasticsearch 首先会找到所有包含数据的分片，然后通过轮训调度算法对分片进行负载均衡。</p><p> 轮训调度算法的前提是所有节点的处理速度都同样快，否则会出现处理速度慢的节点成为整个集群的性能瓶颈，这时候需要自己决定负载均衡方式。</p><p> 搜索可以通过 GET 请求<code>索引名 / 类型名 /_search</code>，使用参数<code>q</code>指定关键词，例如：</p><p> 在指定类型中搜索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/group/_search?q=elasticsearch&amp;pretty&apos;</span><br></pre></td></tr></table></figure><p> 在指定索引的多个类型中搜索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/group,event/_search?q=elasticsearch&amp;pretty&apos;</span><br></pre></td></tr></table></figure><p> 在指定索引的全部类型中搜索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/_search?q=elasticsearch&amp;pretty&apos;</span><br></pre></td></tr></table></figure><p> 在多个索引中搜索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together,other-index/_search?q=elasticsearch&amp;pretty&apos;</span><br></pre></td></tr></table></figure><p> 在全部索引中搜索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/_all/_search?q=elasticsearch&amp;pretty&apos;</span><br></pre></td></tr></table></figure><p> 在全部索引的指定类型中搜索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/_all/group/_search?q=elasticsearch&amp;pretty&apos;</span><br></pre></td></tr></table></figure><p> 为了便于搜索，应该根据应用场景分配索引和类型，例如一般日志数据都会基于时间分配索引。</p><p> 搜索的返回结果结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 2,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 5,</span><br><span class="line">    &quot;successful&quot; : 5,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 1,</span><br><span class="line">    &quot;max_score&quot; : 0.15342641,</span><br><span class="line">    &quot;hits&quot; : [ &#123;</span><br><span class="line">      &quot;_index&quot; : &quot;get-together&quot;,</span><br><span class="line">      &quot;_type&quot; : &quot;group&quot;,</span><br><span class="line">      &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">      &quot;_score&quot; : 0.15342641,</span><br><span class="line">      &quot;_source&quot;:</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;name&quot;: &quot;Elasticsearch Denver&quot;,</span><br><span class="line">              &quot;organizer&quot;: &quot;Lee&quot;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125; ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>took</code>记录了该次请求花费的时间，单位为毫秒。<code>timed_out</code>记录了该次请求是否超时，默认情况下没有超时时间，可以通过<code>timeout</code>参数指定，例如<code>timeout=3s</code>。</p><p><code>_shards</code>记录了搜索的分片信息，包含总共查询了多少个分片、成功的数量和失败的数量。如果一个主分片和它所有复制分片所在的节点都发生了故障，这部分的数据的查询就失败了。</p><p><code>hits</code>包含了搜索结果的总数、最高的相关度分数和搜索结果列表。列表中包含了每个文档的索引、类型、主键、分数和数据。默认情况下 Elasticsearch 只会返回前 10 条数据，可以通过<code>size</code>参数指定返回数量，同时还可以使用<code>fields</code>参数指定返回哪些字段，例如<code>size=100&amp;fields=name,age</code>。</p><p> 使用 URL 参数无法满足表达复杂的搜索，所以 Elasticsearch 还提供了通过 JSON 构造 DSL 搜索语句的方式。</p><p> 使用 JSON 方式的搜索请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/group/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;query_string&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;elasticsearch&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&apos;</span><br></pre></td></tr></table></figure><p> 这种方式提供了更多的选项，例如上面的例子可以通过<code>default_field</code>指定搜索的字段，或是通过<code>&quot;default_operator&quot;: &quot;AND&quot;</code>要求文档必须包含所有词元（默认是<code>OR</code>：只需要包含任意词元）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/group/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;query_string&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;elasticsearch san francisco&quot;,</span><br><span class="line">      &quot;default_field&quot; :&quot;name&quot;,</span><br><span class="line">      &quot;default_operator&quot;: &quot;AND&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&apos;</span><br></pre></td></tr></table></figure><h4 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h4><p> 过滤和搜索最大的区别是，搜索会计算每个结果的相关度，而过滤不会，所以过滤的速度要更快，而且可以被缓存。</p><p> 一个过滤请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/group/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;filtered&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;elasticsearch&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&apos;</span><br></pre></td></tr></table></figure><p> 这个请求的结果会跟上面的搜索相同，只是所有文档的分数都会是 1.0。</p><h4 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h4><p> 聚合可以配合搜索和过滤得到一些统计数据，有些类似于 SQL 中的<code>group by</code>。</p><p> 一个聚合请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;http://localhost:9200/get-together/group/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;query_string&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;elasticsearch&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggregations&quot; : &#123;</span><br><span class="line">    &quot;organizers&quot; : &#123;</span><br><span class="line">      &quot;terms&quot; : &#123; &quot;field&quot; : &quot;organizer&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&apos;</span><br></pre></td></tr></table></figure><p> 这个请求会对搜索结果的<code>organizer</code>字段进行聚合，额外返回这部分数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&quot;aggregations&quot; : &#123;</span><br><span class="line">  &quot;organizers&quot; : &#123;</span><br><span class="line">    &quot;buckets&quot; : [ &#123;</span><br><span class="line">      &quot;key&quot; : &quot;lee&quot;,</span><br><span class="line">      &quot;doc_count&quot; : 2</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">      &quot;key&quot; : &quot;andy&quot;,</span><br><span class="line">      &quot;doc_count&quot; : 1</span><br><span class="line">    &#125;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 它表示有 2 个文档的 organizers 是<code>lee</code>，1 个文档的 organizer 是<code>andy</code>。</p><p> 一个很好的应用场景就是为搜索结果动态的提供筛选条件，它可以保证每个筛选条件都是有结果的，就像淘宝和京东的商品条件筛选。</p><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>Elasticsearch 的配置文件主要有三个：</p><ul><li>elasticsearch.yml：主配置文件</li><li>logging.yml：日志的配置文件</li><li>elasticsearch.in.sh：JAVA 虚拟机（JVM）相关的配置</li></ul><h4 id="elasticsearch-yml"><a href="#elasticsearch-yml" class="headerlink" title="elasticsearch.yml"></a>elasticsearch.yml</h4><p>elasticsearch.yml 存放着最主要的配置，例如集群名、监听端口、文件存储路径等。每次修改后重启生效。</p><p> 有一点需要注意：修改集群名后，之前创建的索引都会消失，因为存储数据的文件夹绑定着集群名。</p><h4 id="logging-yml"><a href="#logging-yml" class="headerlink" title="logging.yml"></a>logging.yml</h4><p>Elasticsearch 使用 Log4j 记录日志，日志文件主要有以下三种：</p><ul><li>主日志（集群名.log）：记录 Elasticsearch 运行状态的日志文件，例如新节点加入集群、搜索操作失败等</li><li>慢搜索日志（集群名\_index\_search\_slowlog.log）：记录搜索过慢的日志，默认时间为半秒</li><li><p>慢索引日志（集群名\_index\_indexing\_slowlog.log）：记录索引过慢的日志，默认时间为半秒</p><p>在大部分情况下，这种日志配置已经足够使用了。</p></li></ul><h4 id="elasticsearch-in-sh"><a href="#elasticsearch-in-sh" class="headerlink" title="elasticsearch.in.sh"></a>elasticsearch.in.sh</h4><p> 作为一个 Java 应用，Elasticsearch 运行于 Java 虚拟机之上，所以许多配置与 JVM 配置息息相关。</p><p> 最常用的配置就是修改内存，Elasticsearch 主要消耗堆内存，默认配置为初始化分配 256mb，最大分配 1gb。如果超过了 1gb 操作就会失败，并且日志中会记录内存溢出（OutOfMemory）异常。</p><p> 通过修改环境变量<code>ES_HEAP_SIZE</code>可以设置堆内存大小，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export ES_HEAP_SIZE=500m</span><br></pre></td></tr></table></figure><p> 另一种方式是修改 elasticsearch.in.sh，在文件的最前面添加<code>ES_HEAD_SIZE = 500m</code>。</p><p> 在生产环境中，如果一台机器只用于运行 Elasticsearch，建议分配该机器物理内存的一半给 Elasticsearch，剩下一半用于操作系统的缓存，它可以使 Elasticsearch 更快的访问本地文件。</p><h3 id="集群状态"><a href="#集群状态" class="headerlink" title="集群状态"></a>集群状态</h3><p> 通过访问<code>_cat/health?v</code>可以查看集群健康，一般会返回如下数据（cat 下的命令多为运维使用，所以不会返回 JSON 格式，默认添加参数<code>v</code>可以显示每一列的名称）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks</span><br><span class="line">1462513392 13:43:12 elasticsearch red 1 1 142 142 0 0 154 0</span><br></pre></td></tr></table></figure><p> 集群的健康度分为三种状态：</p><ul><li>red：危险，集群中有主分片未分配，搜索时会有数据丢失</li><li>yellow：警告，集群中所有主分片都已经分配了，但是有复制分片没有分配</li><li><p>green：安全，所有主分片和复制分片都已经分配了</p><p>通过<code>_cat/shards?v</code>可以查看集群分片的状态，包括具体是哪些分片没有分配出去。由于之前提到一个节点存在多个相同的分片是没有任何意义的，所以改变这些分片状态的唯一方法就是通过添加节点。</p><p>通过启动新的 Elasticsearch 实例创建一个新节点，如果该节点能发现集群的组播地址，并且集群的名称与它配置文件所定义的集群名称相同，它就会加入该集群。</p><p>集群中的第一个节点是集群的主节点，它负责维护集群的状态，包括集群中都有哪些节点，每个节点都有哪些分片。集群状态会复制给每个节点，这样当主节点故障后，另一个节点能提升为主节点并继续工作。</p></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>Elasticsearch 是基于文档的，可伸缩的、模式自由的</li><li>尽管通过默认配置就可以建立一个集群，但是也应该修改一些配置，例如集群名和 JVM 堆大小。</li><li>索引请求会将文档通过 Hash 算法分配到某个主分片，接着同步到该分片的所有复制分片。</li><li>搜索请求会通过轮训调度算法分配到数据分片上（无论是主分片还是复制分片），接着聚合多个分片的结果最终返回给应用程序</li><li>应用程序通过 REST API 索引、搜索文档和修改配置，它不需要知道集群、节点和分片的含义</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;逻辑结构&quot;&gt;&lt;a href=&quot;#逻辑结构&quot; class=&quot;headerlink&quot; title=&quot;逻辑结构&quot;&gt;&lt;/a&gt;逻辑结构&lt;/h3&gt;&lt;p&gt;Elasticsearch 的逻辑结构分为索引、类型和文档。&lt;/p&gt;
&lt;h4 id=&quot;文档（Document）&quot;&gt;&lt;a hr
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>[Elasticsearch in Action读书笔记]第一章 Elasticsearch介绍</title>
    <link href="http://www.scienjus.com/elasticsearch-in-action-1/"/>
    <id>http://www.scienjus.com/elasticsearch-in-action-1/</id>
    <published>2016-05-03T04:04:56.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么需要搜索引擎"><a href="#为什么需要搜索引擎" class="headerlink" title="为什么需要搜索引擎"></a>为什么需要搜索引擎</h3><ol><li>搜索的目的是快速寻找需要的内容而不用浏览整个站点</li><li>搜索结果应该是有顺序的，相关度越高的结果越应该排在前面</li><li>需要提供筛选，以优化搜索结果整体的相关性</li><li><p>搜索的速度不能太慢</p><p>由于传统的关系型数据库无法很好地解决这类问题，所以需要引入专门的搜索引擎。</p></li></ol><h3 id="Elasticsearch-的用途"><a href="#Elasticsearch-的用途" class="headerlink" title="Elasticsearch 的用途"></a>Elasticsearch 的用途</h3><ol><li>部署在关系型数据库之上，加快搜索相关的 SQL 查询。或是为 NoSQL 及其他数据源添加搜索功能</li><li>像 MongoDB 一样作为文档型 NoSQL 数据库使用</li></ol><h3 id="Elasticsearch-的特点"><a href="#Elasticsearch-的特点" class="headerlink" title="Elasticsearch 的特点"></a>Elasticsearch 的特点</h3><h4 id="更快速的搜索"><a href="#更快速的搜索" class="headerlink" title="更快速的搜索"></a>更快速的搜索</h4><p>Elasticsearch 是开源软件，构建于 Lucene，Elasticsearch 使用 Lucene 的方式查询和索引文档，通过扩展使其更快且更方便。并且可以使用 HTTP JSON API 的方式交互，使得应用程序不需要限制于 Java 语言。</p><p>Lucene 使用倒排索引的方式管理文档，它使每个词元都维护一个与其有关的文档列表。就像是通过目录指向页码，然后通过页码翻到具体的内容页一样。</p><p><img src="/uploads/2016/05/inverted-index.png" alt="倒排索引"></p><p> 上图的博客和标签是一个很好的例子：左边为原始数据，一个博客可以拥有多个标签。右边通过倒排索引使得每个标签都指向那些拥有它的博客。这样当搜索标签时，左边只能依次遍历查找，而右边则可以直接找到对应的所有博客。</p><h4 id="保证结果的相关度"><a href="#保证结果的相关度" class="headerlink" title="保证结果的相关度"></a>保证结果的相关度</h4><p> 相关度是一个很重要的概念，它用于证明搜索到的文档到底是真的关于这个关键词，还是仅仅包含了这个关键词。一个最简单的例子：也许一个文档里出现该关键词的次数越多，它就与这个关键词越有关。</p><p>Elasticsearch 默认使用 TF-IDF（term frequency–inverse document frequency）进行相关度计算<br>，它的意思是：</p><ul><li>term frequency：词频，指单词在文档中出现的频率，词频越高相关度也就越高</li><li><p>inverse document frequency：逆向文档频率，指其他出现该单词的文档的个数，逆向文档频率越低相关度越高</p><p>也就是说，如果一个单词在某个文档中出现的次数很多，并且很少出现在其他文档中，那么这个单词就可以为该文档带来非常高的相关度。</p></li></ul><p>Elasticsearch 还提供了一些其他的方式计算相关度，例如增加某个字段的影响力，甚至可以通过脚本自己实现计算相关度分数的方法。这几乎可以满足各种需求，无论是你希望关键词出现在标题上的博客更靠前，还是希望点赞数越多的博客更靠前，或是较新的博客更靠前。</p><h4 id="不仅仅是精确匹配"><a href="#不仅仅是精确匹配" class="headerlink" title="不仅仅是精确匹配"></a>不仅仅是精确匹配</h4><p>Elasticsearch 还提供一些配置用于支持错词、衍生词（例如单复数、各种时态等），以提高匹配的精度。同时还可以支持关键词联想等功能。</p><h3 id="Elasticsearch-的使用场景"><a href="#Elasticsearch-的使用场景" class="headerlink" title="Elasticsearch 的使用场景"></a>Elasticsearch 的使用场景</h3><h4 id="作为主数据源"><a href="#作为主数据源" class="headerlink" title="作为主数据源"></a>作为主数据源</h4><p> 通常来说，搜索引擎一般是构建在其他数据源之上，用于提供更加良好的搜索体验。这是因为之前的大多搜索引擎都无法提供可靠地存储和一些常用的功能，像是统计。</p><p> 但是如今 Elasticsearch 提供了这些功能，所以可以直接当做数据库使用，当然只适用于某些场景。</p><p> 例如一个博客应用，这类应用并没有太复杂的关联关系，且对事务不敏感，所以很适合 Elasticsearch（除了太太太太耗内存）。</p><p><img src="/uploads/2016/05/with-data-store.jpg" alt="主数据源"></p><p> 就像上图一样，在创建新文章时将它索引到 Elasticsearch 中，之后通过查询获取文章内容。无论是简单的主键查询，还是复杂些的基于标签、类别的查询，包括搜索功能，都可以非常轻松的实现。甚至还可以通过聚合和修改相关度做一些标签统计、热门文章等复杂功能。</p><h4 id="作为辅助数据源"><a href="#作为辅助数据源" class="headerlink" title="作为辅助数据源"></a>作为辅助数据源</h4><p>Elasticsearch 并不适合所有场景，例如它没有事务这个概念，也无法很好地完成关联查询。所以更多的场景是辅助一个已有的主数据源，并提供它在搜索及实时分析领域上的支持。</p><p> 在使用多个数据源时，必须要保证数据源之间的数据是同步的，通常可以使用一些已有的插件或是自己写一个系统实现。</p><p><img src="/uploads/2016/05/with-data-store.jpg" alt="辅助数据源"></p><h4 id="现成的解决方案"><a href="#现成的解决方案" class="headerlink" title="现成的解决方案"></a>现成的解决方案</h4><p>Elasticsearch 的出名有很大一部分原因是由于它拥有 ELK（Logstash Elasticsearch Kibana）这一套通用的日志分析解决方案。其中 Logstash 用于收集日志，Elasticsearch 用于存储和索引日志，Kibana 提供了一个人性化的 Web 界面用于展示搜索结果。这样不需要写任何代码就可以拥有一个功能强大的日志分析系统。</p><h3 id="Elasticsearch-的优势"><a href="#Elasticsearch-的优势" class="headerlink" title="Elasticsearch 的优势"></a>Elasticsearch 的优势</h3><p>Elasticsearch 提供了 REST API，使得无论是开发者可以轻易的通过 JSON 构造查询语句搜索文档，或是修改配置信息。</p><p> 在 Lucene 之上，Elasticsearch 还提供了一些更加高级的功能，例如缓存、实时分析、聚合和统计等。并且文档的管理更加灵活，单次查询可以同时查询多个索引。</p><p> 最后，Elasticsearch 拥有良好的伸缩性，默认支持集群（即使只运行了一个节点），并且可以轻松地通过增加节点达到扩容和容灾的目的，可以在必要时刻移除节点以节约花费。</p><h3 id="安装-Elasticsearch"><a href="#安装-Elasticsearch" class="headerlink" title="安装 Elasticsearch"></a>安装 Elasticsearch</h3><h4 id="安装-Java"><a href="#安装-Java" class="headerlink" title="安装 Java"></a>安装 Java</h4><p>Elasticsearch 使用 Java 开发，所以首先需要安装 JRE，在这里就不详述了。</p><p> 它会通过两种方式寻找系统中的 Java：<code>JAVA_HOME</code>和系统路径。通过<code>env</code>（类 Unix 系统）和<code>set</code>可以查看环境变量，直接在命令行输入<code>java -version</code>可以查看是否存在与系统路径中。</p><h4 id="安装-Elasticsearch-1"><a href="#安装-Elasticsearch-1" class="headerlink" title="安装 Elasticsearch"></a>安装 Elasticsearch</h4><p>Elasticsearch 的安装十分简单，只需要在官网下载对应的<code>tar.gz</code>包，解压后运行启动脚本即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar zxf elasticsearch-*.tar.gz</span><br><span class="line">cd elasticsearch-*</span><br><span class="line">bin/elasticsearch</span><br></pre></td></tr></table></figure><h4 id="查看启动日志"><a href="#查看启动日志" class="headerlink" title="查看启动日志"></a>查看启动日志</h4><p> 启动时会在命令行输出一些日志：</p><p> 启动节点的版本，pid，名称等信息，Elasticsearch 默认会给节点随机起一个名字（这里是 Answer）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2016-05-03 17:24:15,032][INFO][node] [Answer] version [1.7.1], pid [21122], build [b88f43f/2015-07-29T09:54:16Z]</span><br></pre></td></tr></table></figure><p> 加载插件信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2016-05-03 17:24:15,233][INFO][plugins] [Answer] loaded [analysis-ik, marvel], sites [marvel]</span><br></pre></td></tr></table></figure><p> 内部节点通讯的端口为 9300：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2016-05-03 17:24:26,456][INFO][transport] [Answer] bound_address &#123;inet [/0:0:0:0:0:0:0:0:9300]&#125;, publish_address &#123;inet [/192.168.1.222:9300]&#125;</span><br></pre></td></tr></table></figure><p> 该节点被选为主节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2016-05-03 17:24:30,247][INFO][cluster.service] [Answer] new_master [Answer][BztA5MLnQW6-obfcjN4T7w][localhost.localdomain][inet [/192.168.1.222:9300]], reason: zen-disco-join (elected_as_master)</span><br></pre></td></tr></table></figure><p>http 通讯端口为 9200：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2016-05-03 17:24:30,371][INFO][http] [Answer] bound_address &#123;inet [/0:0:0:0:0:0:0:0:9200]&#125;, publish_address &#123;inet [/192.168.1.222:9200]&#125;</span><br></pre></td></tr></table></figure><p> 节点已启动完毕：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2016-05-03 17:24:30,372][INFO][node] [Answer] started</span><br></pre></td></tr></table></figure><p> 从网关恢复数据，第一次启动必然是 0：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2016-05-03 17:24:30,702][INFO][gateway] [Answer] recovered [0] indices into cluster_state</span><br></pre></td></tr></table></figure><h4 id="尝试交互"><a href="#尝试交互" class="headerlink" title="尝试交互"></a>尝试交互</h4><p> 节点启动成功后就可以通过 REST API 进行交互了，请求 9200 端口，会以 JSON 格式返回节点信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:9200</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;status&quot; : 200,</span><br><span class="line">  &quot;name&quot; : &quot;St. John Allerdyce&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;1.7.1&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;b88f43fc40b0bcd7f173a1f9ee2e97816de80b19&quot;,</span><br><span class="line">    &quot;build_timestamp&quot; : &quot;2015-07-29T09:54:16Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;4.10.4&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><p>Elasticsearch 是一个开源的搜索引擎，基于 Apache Lucene</p></li><li><p>典型应用场景是索引大量数据，并高效的进行全文搜索或是实时统计</p></li><li><p>搜索功能不仅限于全文搜索，可以修改相关度的计算方式或是给出搜索建议</p></li><li><p>运行十分简单，只需要下载文件，解压缩，运行脚本即可</p></li><li><p>可以使用 HTTP REST API 通过 JSON 进行索引、查询数据和修改集群设置</p></li><li><p>也可以将其作为一个用于实时搜索和分析的文档型 NoSQL 数据库</p></li><li><p>会自动将数据平均分布到各个分片中，可以很轻松的通过添加节点横向扩展集群，分片会被复制从而提高容错性</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;为什么需要搜索引擎&quot;&gt;&lt;a href=&quot;#为什么需要搜索引擎&quot; class=&quot;headerlink&quot; title=&quot;为什么需要搜索引擎&quot;&gt;&lt;/a&gt;为什么需要搜索引擎&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;搜索的目的是快速寻找需要的内容而不用浏览整个站点&lt;/li&gt;
&lt;li&gt;搜索
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>通过Function Score Query优化Elasticsearch搜索结果</title>
    <link href="http://www.scienjus.com/elasticsearch-function-score-query/"/>
    <id>http://www.scienjus.com/elasticsearch-function-score-query/</id>
    <published>2016-04-06T00:33:23.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>在使用 Elasticsearch 进行全文搜索时，搜索结果默认会以文档的相关度进行排序，如果想要改变默认的排序规则，也可以通过<code>sort</code>指定一个或多个排序字段。</p><p> 但是使用<code>sort</code>排序过于绝对，它会直接忽略掉文档本身的相关度（根本不会去计算）。在很多时候这样做的效果并不好，这时候就需要对多个字段进行综合评估，得出一个最终的排序。</p><h3 id="function-score"><a href="#function-score" class="headerlink" title="function\_score"></a>function\_score</h3><p> 在 Elasticsearch 中<code>function_score</code>是用于处理文档分值的 DSL，它会在查询结束后对每一个匹配的文档进行一系列的重打分操作，最后以生成的最终分数进行排序。它提供了几种默认的计算分值的函数：</p><ul><li><code>weight</code>：设置权重</li><li><code>field_value_factor</code>：将某个字段的值进行计算得出分数。</li><li><code>random_score</code>：随机得到 0 到 1 分数</li><li>衰减函数：同样以某个字段的值为标准，距离某个值越近得分越高</li><li><p><code>script_score</code>：通过自定义脚本计算分值</p><p>它还有一个属性<code>boost_mode</code>可以指定计算后的分数与原始的<code>_score</code>如何合并，有以下选项：</p></li><li><p><code>multiply</code>：将结果乘以<code>_score</code></p></li><li><code>sum</code>：将结果加上<code>_score</code></li><li><code>min</code>：取结果与<code>_score</code>的较小值</li><li><code>max</code>：取结果与<code>_score</code>的较大值</li><li><p><code>replace</code>：使结果替换掉<code>_score</code></p><p>接下来本文将详细介绍这些函数的用法，以及它们的使用场景。</p></li></ul><h3 id="weight"><a href="#weight" class="headerlink" title="weight"></a>weight</h3><p>weight 的用法最为简单，只需要设置一个数字作为权重，文档的分数就会乘以该权重。</p><p> 他最大的用途应该就是和过滤器一起使用了，因为过滤器只会筛选出符合标准的文档，而不会去详细的计算每个文档的具体得分，所以只要满足条件的文档的分数都是 1，而 weight 可以将其更换为你想要的数值。</p><h3 id="field-value-factor"><a href="#field-value-factor" class="headerlink" title="field\_value\_factor"></a>field\_value\_factor</h3><p>field\_value\_factor 的目的是通过文档中某个字段的值计算出一个分数，它有以下属性：</p><ul><li><p><code>field</code>：指定字段名</p></li><li></li></ul><p><code>factor</code>：对字段值进行预处理，乘以指定的数值（默认为 1）</p><ul><li><p><code>modifier</code>将字段值进行加工，有以下的几个选项：</p><ul><li><code>none</code>：不处理</li><li><code>log</code>：计算对数</li><li><code>log1p</code>：先将字段值 +1，再计算对数</li><li><code>log2p</code>：先将字段值 +2，再计算对数</li><li><code>ln</code>：计算自然对数</li><li><code>ln1p</code>：先将字段值 +1，再计算自然对数</li><li><code>ln2p</code>：先将字段值 +2，再计算自然对数</li><li><code>square</code>：计算平方</li><li><code>sqrt</code>：计算平方根</li><li><code>reciprocal</code>：计算倒数</li></ul><p>举一个简单的例子，假设有一个商品索引，搜索时希望在相关度排序的基础上，销量（<code>sales</code>）更高的商品能排在靠前的位置，那么这条查询 DSL 可以是这样的：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;function_score&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">          &quot;title&quot;: &quot;雨伞&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;field_value_factor&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;sales&quot;,</span><br><span class="line">        &quot;modifier&quot;: &quot;log1p&quot;,</span><br><span class="line">        &quot;factor&quot;: 0.1</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;boost_mode&quot;: &quot;sum&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这条查询会将标题中带有雨伞的商品检索出来，然后对这些文档计算一个与库存相关的分数，并与之前相关度的分数相加，对应的公式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_score = _score + log (1 + 0.1 * sales)</span><br></pre></td></tr></table></figure><h3 id="random-score"><a href="#random-score" class="headerlink" title="random\_score"></a>random\_score</h3><p> 这个函数的使用相当简单，只需要调用一下就可以返回一个 0 到 1 的分数。</p><p> 它有一个非常有用的特性是可以通过<code>seed</code>属性设置一个随机种子，该函数保证在随机种子相同时返回值也相同，这点使得它可以轻松地实现对于用户的个性化推荐。</p><h3 id="衰减函数"><a href="#衰减函数" class="headerlink" title="衰减函数"></a>衰减函数</h3><p> 衰减函数（Decay Function）提供了一个更为复杂的公式，它描述了这样一种情况：对于一个字段，它有一个理想的值，而字段实际的值越偏离这个理想值（无论是增大还是减小），就越不符合期望。这个函数可以很好的应用于数值、日期和地理位置类型，由以下属性组成：</p><ul><li>原点（<code>origin</code>）：该字段最理想的值，这个值可以得到满分（1.0）</li><li>偏移量（<code>offset</code>）：与原点相差在偏移量之内的值也可以得到满分</li><li>衰减规模（<code>scale</code>）：当值超出了原点到偏移量这段范围，它所得的分数就开始进行衰减了，衰减规模决定了这个分数衰减速度的快慢</li><li><p>衰减值（<code>decay</code>）：该字段可以被接受的值（默认为 0.5），相当于一个分界点，具体的效果与衰减的模式有关</p><p>例如我们想要买一样东西：</p></li><li><p>它的理想价格是 50 元，这个值为原点</p></li><li>但是我们不可能非 50 元就不买，而是会划定一个可接受的价格范围，例如 45-55 元，±5 就为偏移量</li><li><p>当价格超出了可接受的范围，就会让人觉得越来越不值。如果价格是 70 元，评价可能是<q>不太想买</q>，而如果价格是 200 元，评价则会是<q>不可能会买</q>，这就是由衰减规模和衰减值所组成的一条衰减曲线</p><p>或者如果我们想租一套房：</p></li><li><p>它的理想位置是公司附近</p></li><li>如果离公司在 5km 以内，是我们可以接受的范围，在这个范围内我们不去考虑距离，而是更偏向于其他信息</li><li><p>当距离超过 5km 时，我们对这套房的评价就越来越低了，直到超出了某个范围就再也不会考虑了</p><p>衰减函数还可以指定三种不同的模式：线性函数（linear）、以 e 为底的指数函数（Exp）和高斯函数（gauss），它们拥有不同的衰减曲线：</p></li></ul><p><img src="/uploads/2016/04/decay-function.png" alt="衰减曲线"></p><p> 将上面提到的租房用 DSL 表示就是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;function_score&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">          &quot;title&quot;: &quot;公寓&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;gauss&quot;: &#123;</span><br><span class="line">        &quot;location&quot;: &#123;</span><br><span class="line">          &quot;origin&quot;: &#123; &quot;lat&quot;: 40, &quot;lon&quot;: 116 &#125;,</span><br><span class="line">          &quot;offset&quot;: &quot;5km&quot;,</span><br><span class="line">          &quot;scale&quot;: &quot;10km&quot;</span><br><span class="line">           &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;boost_mode&quot;: &quot;sum&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 我们希望租房的位置在<code>40, 116</code>坐标附近，<code>5km</code>以内是满意的距离，<code>15km</code>以内是可以接受的距离。</p><h3 id="script-score"><a href="#script-score" class="headerlink" title="script\_score"></a>script\_score</h3><p> 虽然强大的 field\_value\_factor 和衰减函数已经可以解决大部分问题了，但是也可以看出它们还有一定的局限性：</p><ol><li>这两种方式都只能针对一个字段计算分值</li><li><p>这两种方式应用的字段类型有限，field\_value\_factor 一般只用于数字类型，而衰减函数一般只用于数字、位置和时间类型</p><p>这时候就需要 script\_score 了，它支持我们自己编写一个脚本运行，在该脚本中我们可以拿到当前文档的所有字段信息，并且只需要将计算的分数作为返回值传回 Elasticsearch 即可。</p><p>注：使用脚本需要首先在配置文件中打开相关功能：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">script.groovy.sandbox.enabled: true</span><br><span class="line">script.inline: on</span><br><span class="line">script.indexed: on</span><br><span class="line">script.search: on</span><br><span class="line">script.engine.groovy.inline.aggs: on</span><br></pre></td></tr></table></figure><p> 举一个之前做不到的例子，假如我们有一个位置索引，它有一个分类（<code>category</code>）属性，该属性是字符串枚举类型，例如商场、电影院或者餐厅等。现在由于我们有一个电影相关的活动，所以需要将电影院在搜索列表中的排位相对靠前。</p><p> 之前的两种方式都无法给字符串打分，但是如果我们自己写脚本的话却很简单，使用 Groovy（Elasticsearch 的默认脚本语言）也就是一行的事：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return doc [&apos;category&apos;].value == &apos;电影院&apos; ? 1.1 : 1.0</span><br></pre></td></tr></table></figure><p> 接下来只要将这个脚本配置到查询语句中就可以了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;function_score&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;天安门&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;script_score&quot;: &#123;</span><br><span class="line">        &quot;script&quot;: &quot;return doc [&apos;category&apos;].value == &apos;电影院&apos; ? 1.1 : 1.0&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 或是将脚本放在<code>elasticsearch/config/scripts</code>下，然后在查询语句中引用它：</p><p>category-score.groovy：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return doc [&apos;category&apos;].value == &apos;电影院&apos; ? 1.1 : 1.0</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;function_score&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;天安门&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;script_score&quot;: &#123;</span><br><span class="line">        &quot;script&quot;: &#123;</span><br><span class="line">         &quot;file&quot;: &quot;category-score&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 在<code>script</code>中还可以通过<code>params</code>属性向脚本传值，所以为了解除耦合，上面的 DSL 还能接着改写为：</p><p>category-score.groovy：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return doc [&apos;category&apos;].value == recommend_category ? 1.1 : 1.0</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;function_score&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;天安门&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;script_score&quot;: &#123;</span><br><span class="line">        &quot;script&quot;: &#123;</span><br><span class="line">         &quot;file&quot;: &quot;category-score&quot;,</span><br><span class="line">         &quot;params&quot;: &#123;</span><br><span class="line">            &quot;recommend_category&quot;: &quot;电影院&quot;</span><br><span class="line">         &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这样就可以在不更改大部分查询语句和脚本的基础上动态修改推荐的位置类别了。</p><h3 id="同时使用多个函数"><a href="#同时使用多个函数" class="headerlink" title="同时使用多个函数"></a>同时使用多个函数</h3><p> 上面的例子都只是调用某一个函数并与查询得到的<code>_score</code>进行合并处理，而在实际应用中肯定会出现在多个点上计算分值并合并，虽然脚本也许可以解决这个问题，但是应该没人愿意维护一个复杂的脚本吧。这时候通过多个函数将每个分值都计算出在合并才是更好的选择。</p><p> 在 function\_score 中可以使用<code>functions</code>属性指定多个函数。它是一个数组，所以原有函数不需要发生改动。同时还可以通过<code>score_mode</code>指定各个函数分值之间的合并处理，值跟最开始提到的<code>boost_mode</code>相同。下面举两个例子介绍一些多个函数混用的场景。</p><p> 第一个例子是类似于大众点评的餐厅应用。该应用希望向用户推荐一些不错的餐馆，特征是：范围要在当前位置的 5km 以内，有停车位是最重要的，有 Wi-Fi 更好，餐厅的评分（1 分到 5 分）越高越好，并且对不同用户最好展示不同的结果以增加随机性。</p><p> 那么它的查询语句应该是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;function_score&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;geo_distance&quot;: &#123;</span><br><span class="line">          &quot;distance&quot;: &quot;5km&quot;,</span><br><span class="line">          &quot;location&quot;: &#123;</span><br><span class="line">            &quot;lat&quot;: $lat,</span><br><span class="line">            &quot;lon&quot;: $lng</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;functions&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;filter&quot;: &#123;</span><br><span class="line">            &quot;term&quot;: &#123;</span><br><span class="line">              &quot;features&quot;: &quot;wifi&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;weight&quot;: 1</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;filter&quot;: &#123;</span><br><span class="line">            &quot;term&quot;: &#123;</span><br><span class="line">              &quot;features&quot;: &quot;停车位&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;weight&quot;: 2</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;field_value_factor&quot;: &#123;</span><br><span class="line">               &quot;field&quot;: &quot;score&quot;,</span><br><span class="line">               &quot;factor&quot;: 1.2</span><br><span class="line">             &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;random_score&quot;: &#123;</span><br><span class="line">            &quot;seed&quot;: &quot;$id&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;score_mode&quot;: &quot;sum&quot;,</span><br><span class="line">      &quot;boost_mode&quot;: &quot;multiply&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 注：其中所有以<code>$</code>开头的都是变量。</p><p> 这样一个饭馆的最高得分应该是 2 分（有停车位）+ 1 分（有 wifi）+ 6 分（评分 5 分 \* 1.2）+ 1 分（随机评分）。</p><p> 另一个例子是类似于新浪微博的社交网站。现在要优化搜索功能，使其以文本相关度排序为主，但是越新的微博会排在相对靠前的位置，点赞（忽略相同计算方式的转发和评论）数较高的微博也会排在较前面。如果这篇微博购买了推广并且是创建不到 24 小时（同时满足），它的位置会非常靠前。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;function_score&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">          &quot;content&quot;: &quot;$text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;functions&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;gauss&quot;: &#123;</span><br><span class="line">            &quot;createDate&quot;: &#123;</span><br><span class="line">              &quot;origin&quot;: &quot;$now&quot;,</span><br><span class="line">              &quot;scale&quot;: &quot;6d&quot;,</span><br><span class="line">              &quot;offset&quot;: &quot;1d&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;field_value_factor&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;like_count&quot;,</span><br><span class="line">            &quot;modifier&quot;: &quot;log1p&quot;,</span><br><span class="line">            &quot;factor&quot;: 0.1</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;script_score&quot;: &#123;</span><br><span class="line">            &quot;script&quot;: &quot;return doc [&apos;is_recommend&apos;].value &amp;&amp; doc [&apos;create_date&apos;] &gt; time ? 1.5 : 1.0&quot;,</span><br><span class="line">            params: &#123;</span><br><span class="line">                &quot;time&quot;: $time</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;boost_mode&quot;: &quot;multiply&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 它的公式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_score * gauss (create_date, $now, &quot;1d&quot;, &quot;6d&quot;) * log (1 + 0.1 * like_count) * is_recommend ? 1.5 : 1.0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在使用 Elasticsearch 进行全文搜索时，搜索结果默认会以文档的相关度进行排序，如果想要改变默认的排序规则，也可以通过&lt;code&gt;sort&lt;/code&gt;指定一个或多个排序字段。&lt;/p&gt;
&lt;p&gt; 但是使用&lt;code&gt;sort&lt;/code&gt;排序过于绝对，它会直接忽略掉
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>使用FastRoute重写Spring的路由</title>
    <link href="http://www.scienjus.com/fastroute-spring/"/>
    <id>http://www.scienjus.com/fastroute-spring/</id>
    <published>2016-04-05T01:41:14.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Spring-的路由实现"><a href="#Spring-的路由实现" class="headerlink" title="Spring 的路由实现"></a>Spring 的路由实现</h3><p> 在 Spring 中路由被抽象为<code>MappingHandler</code>接口，而最常用的实现类是处理<code>@RequestMapping</code>的<code>RequestMappingHandlerMapping</code>。</p><p><code>MappingHandler</code>接口只有一个方法<code>getHandler</code>，该方法接受标准的<code>HttpServletRequest</code>并返回<code>HandlerExecutionChain</code>，这个对象包含一组拦截器和具体需要执行的处理器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HandlerExecutionChain getHandler (HttpServletRequest request) throws Exception;</span><br></pre></td></tr></table></figure><p><code>AbstractHandlerMapping</code>实现了这个方法，并将其定义为<code>final</code>方法，但是事实上只是添加了一些处理逻辑，并提供了一个抽象方法<code>getHandlerInternal</code>由子类实现。</p><p> 接下来，在<code>AbstractHandlerMethodMapping</code>中，这个方法被完整的实现了，最核心的业务在<code>lookupHandlerMethod</code>方法中，让我们来看一下这个方法具体是如何实现路由的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">protected HandlerMethod lookupHandlerMethod (String lookupPath, HttpServletRequest request) throws Exception &#123;</span><br><span class="line">    List matches = new ArrayList ();</span><br><span class="line">    List directPathMatches = this.mappingRegistry.getMappingsByUrl (lookupPath);</span><br><span class="line">    if (directPathMatches != null) &#123;</span><br><span class="line">        addMatchingMappings (directPathMatches, matches, request);</span><br><span class="line">    &#125;</span><br><span class="line">    if (matches.isEmpty ()) &#123;</span><br><span class="line">        // No choice but to go through all mappings...</span><br><span class="line">        addMatchingMappings (this.mappingRegistry.getMappings ().keySet (), matches, request);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (!matches.isEmpty ()) &#123;</span><br><span class="line">        Comparator comparator = new MatchComparator (getMappingComparator (request));</span><br><span class="line">        Collections.sort (matches, comparator);</span><br><span class="line">        if (logger.isTraceEnabled ()) &#123;</span><br><span class="line">            logger.trace (&quot;Found &quot; + matches.size () + &quot; matching mapping (s) for [&quot; +</span><br><span class="line">                    lookupPath + &quot;] : &quot; + matches);</span><br><span class="line">        &#125;</span><br><span class="line">        Match bestMatch = matches.get (0);</span><br><span class="line">        if (matches.size () &gt; 1) &#123;</span><br><span class="line">            if (CorsUtils.isPreFlightRequest (request)) &#123;</span><br><span class="line">                return PREFLIGHT_AMBIGUOUS_MATCH;</span><br><span class="line">            &#125;</span><br><span class="line">            Match secondBestMatch = matches.get (1);</span><br><span class="line">            if (comparator.compare (bestMatch, secondBestMatch) == 0) &#123;</span><br><span class="line">                Method m1 = bestMatch.handlerMethod.getMethod ();</span><br><span class="line">                Method m2 = secondBestMatch.handlerMethod.getMethod ();</span><br><span class="line">                throw new IllegalStateException (&quot;Ambiguous handler methods mapped for HTTP path &apos;&quot; +</span><br><span class="line">                        request.getRequestURL () + &quot;&apos;: &#123;&quot; + m1 + &quot;, &quot; + m2 + &quot;&#125;&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        handleMatch (bestMatch.mapping, lookupPath, request);</span><br><span class="line">        return bestMatch.handlerMethod;</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">        return handleNoMatch (this.mappingRegistry.getMappings ().keySet (), lookupPath, request);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 首先它会调用<code>getMappingsByUrl</code>去寻找静态路由，这个方法实际就是一个 Map，以路由地址和路由对象组成的键值对。如果<code>@RequestMapping</code>中注册的路径没有包含参数或正则（例如<code>{id}</code>或<code>/**</code>），这个方法会很快的查询到匹配的路由。</p><p> 但是如果注册的路径包含了参数或正则，这个方法就会返回一个空列表，之后 Spring 会对所有的路由进行遍历，寻找匹配的路由。</p><p> 匹配大致分两步：首先将路由中除了路径以外的信息进行对比，包括请求方式（HTTP Method）、参数（Param）、请求头（Header）、内容类型（Content-Type）。如果所有信息都符合才会进行比较耗时的路径匹配，Spring 默认使用的是<code>AntPathMatcher</code>而不是正则表达式匹配路径，性能上应该会比单纯使用正则表达式要更高。</p><p> 最后，Spring 会将所有匹配的路由进行排序，得到匹配度最高的路由（如果有多个匹配度相同且最高的路由，会抛出异常）。接着对该路由进行解析，获得路径中的动态参数。</p><p> 从这个流程中可以看出，遍历整个列表绝对是一个低效的实现方式，即使<code>AntPathMatcher</code>的性能要高于正则表达式，每次都要从头扫描 URL 却是没有必要的。</p><p> 接下来介绍一种更加快速的路由匹配方式：FastRoute。</p><h3 id="FastRoute-的路由实现"><a href="#FastRoute-的路由实现" class="headerlink" title="FastRoute 的路由实现"></a>FastRoute 的路由实现</h3><p> <a href="https://github.com/nikic/FastRoute" target="_blank" rel="external">FastRoute</a> 是 GitHub 上的一个 PHP 开源项目，并且应用于 <a href="https://github.com/laravel/lumen" target="_blank" rel="external">Lumen</a> 框架中。它提供了一种更加快速但是并不麻烦的路由匹配方式。</p><p> 之前我们提到，Spring 这种循环整个列表进行匹配的做法并不高效，而在 FastRoute 中，它将所有的路由拼成了一个完整的正则表达式，所以只要一次正则匹配就可以完成所有路由的查询。</p><p> 例如有以下三个路由：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/users/&#123;id&#125;</span><br><span class="line"></span><br><span class="line">/users/&#123;id&#125;/&#123;name&#125;</span><br><span class="line"></span><br><span class="line">/users/&#123;uid&#125;/posts/&#123;pid&#125;</span><br></pre></td></tr></table></figure><p> 替换成正则表达式分别是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">^/users/([^/]+)$</span><br><span class="line"></span><br><span class="line">^/users/([^/]+)/([^/]+)$</span><br><span class="line"></span><br><span class="line">^/users/([^/]+)/posts/([^/]+)$</span><br></pre></td></tr></table></figure><p> 按照以往的方法，当收到一个请求，就需要按顺序对每个正则表达式进行匹配，如果有三个路由就需要匹配三次，有一千个路由就需要匹配一千次。但是如果将所有的路由拼成一个完整的正则表达式，就会变成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">^(?:</span><br><span class="line"> (/users/([^/]+))</span><br><span class="line">|</span><br><span class="line"> (/users/([^/]+)/([^/]+))</span><br><span class="line">|</span><br><span class="line"> (/users/([^/]+)/posts/([^/]+))</span><br><span class="line">)$</span><br></pre></td></tr></table></figure><p> 这样只需要一次就可以对所有的路由进行匹配了。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Pattern pattern = Pattern.compile (&quot;^(?:(/users/([^/]+))|(/users/([^/]+)/([^/]+))|(users/([^/]+)/posts/([^/]+)))$&quot;);</span><br><span class="line"></span><br><span class="line">Matcher matcher = pattern.matcher (&quot;/users/123/abc&quot;);</span><br><span class="line"></span><br><span class="line">if (matcher.matches ()) &#123;</span><br><span class="line">  for (int i = 1; i</span><br></pre></td></tr></table></figure><p> 将会输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">null</span><br><span class="line">null</span><br><span class="line">/users/123/abc</span><br><span class="line">123</span><br><span class="line">abc</span><br><span class="line">null</span><br><span class="line">null</span><br><span class="line">null</span><br></pre></td></tr></table></figure><p> 而路由与匹配组的映射关系应该是这样一个数组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> [</span><br><span class="line">    Route (&quot;/users/&#123;id&#125;&quot;), Param (&quot;id&quot;),</span><br><span class="line">    Route (&quot;/users/&#123;id&#125;/&#123;name&#125;&quot;), Param (&quot;id&quot;), Param (&quot;name&quot;),</span><br><span class="line">    Route (&quot;/users/&#123;uid&#125;/posts/&#123;pid&#125;&quot;), Param (&quot;uid&quot;), Param (&quot;pid&quot;)</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p> 这样也就可以很轻易的通过组的序号得到对应的路由和参数信息。</p><p> 如果你想了解更多的信息，也可以看 <a href="http://nikic.github.io/2014/02/18/Fast-request-routing-using-regular-expressions.html" target="_blank" rel="external">这篇作者写的分析文章</a>，介绍的非常全面。</p><h3 id="在-Spring-中实现-FastRoute"><a href="#在-Spring-中实现-FastRoute" class="headerlink" title="在 Spring 中实现 FastRoute"></a>在 Spring 中实现 FastRoute</h3><p> 我尝试通过继承<code>RequestMappingHandlerMapping</code>并重写<code>lookupHandlerMethod</code>方法添加自己的路由逻辑，但是这过程并不顺利，一方面是<code>AbstractHandlerMapping</code>定义了很多私有类和<code>final</code>方法，在实现类中都无法使用。另一方面是 FastRoute 需要在所有路由都注册后将它们编译成完整的正则表达式，而 Spring 中却没有这个事件，所以我只能在第一次请求的时候进行这个编译操作。</p><p> <a href="https://github.com/ScienJus/fastroute-spring" target="_blank" rel="external">这是我目前完成的一个实现</a>，它的实现方式很糟糕，并且阉割了很多功能，不过已经可以进行最基本的性能测试了。我创建了大概 1000 个左右的路由（其中五分之二是静态路由，五分之三是正则路由）分别进行了两种测试：</p><p> 方式 1：使用 Jmeter 进行压力测试，线程数 200，业务逻辑仅仅是返回一个字符串。</p><p><code>RequestMappingHandlerMapping</code>的结果：</p><p><img src="/uploads/2016/04/route2.jpg" alt="RequestMappingHandlerMapping"></p><p><code>FastRouteHandlerMapping</code>的结果</p><p><img src="/uploads/2016/04/route1.jpg" alt="RequestMappingHandlerMapping"></p><p> 方式 2：直接在程序内部记录<code>lookupHandlerMethod</code>方法所消耗的时间，因为<code>FastRouteHandlerMapping</code>实际上只重写了这个方法。</p><p><code>RequestMappingHandlerMapping</code>的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">50000 次调用时间：84370ms</span><br></pre></td></tr></table></figure><p><code>FastRouteHandlerMapping</code>的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">50000 次调用时间：2932ms</span><br></pre></td></tr></table></figure><p> 可以看到性能提升还是非常明显的！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Spring-的路由实现&quot;&gt;&lt;a href=&quot;#Spring-的路由实现&quot; class=&quot;headerlink&quot; title=&quot;Spring 的路由实现&quot;&gt;&lt;/a&gt;Spring 的路由实现&lt;/h3&gt;&lt;p&gt; 在 Spring 中路由被抽象为&lt;code&gt;Mapping
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>我所认为的RESTful API最佳实践</title>
    <link href="http://www.scienjus.com/my-restful-api-best-practices/"/>
    <id>http://www.scienjus.com/my-restful-api-best-practices/</id>
    <published>2016-04-03T01:45:03.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="不要纠结于无意义的规范"><a href="#不要纠结于无意义的规范" class="headerlink" title="不要纠结于无意义的规范"></a>不要纠结于无意义的规范</h3><p> 在开始本文之前，我想先说这么一句：RESTful 真的很好，但它只是一种软件架构风格，过度纠结如何遵守规范只是徒增烦恼，也违背了使用它的初衷。</p><p> 就像 Elasticsearch 的 API 会在 GET 请求中直接传 JSON，但这是它的业务需要，因为普通的 Query Param 根本无法构造如此复杂的查询 DSL。Github 的 V3 API 中也有很多不符合标准的地方，这也并不会妨碍它成为业界 RESTful API 的参考标准。</p><p> 我接下来要介绍的一些东西也会跟标准不符，但这是我在实际开发中遇到过、困扰过、思考过所得出的结论，所以才是<q>我所认为的</q>RESTful API 最佳实践。</p><h3 id="为什么要用-RESTful"><a href="#为什么要用-RESTful" class="headerlink" title="为什么要用 RESTful"></a>为什么要用 RESTful</h3><p>RESTful 给我的最大感觉就是规范、易懂和优雅，一个结构清晰、易于理解的 API 完全可以省去许多无意义的沟通和文档。并且 RESTful 现在越来越流行，也有越来越多优秀的周边工具（例如文档工具 Swagger）。</p><h3 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h3><p> 如果能全站 HTTPS 当然是最好的，不能的话也请尽量将登录、注册等涉及密码的接口使用 HTTPS。</p><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>API 的版本号和客户端 APP 的版本号是毫无关系的，不要让 APP 将它们用于提交应用市场的版本号传递到服务器，而是提供类似于<code>v1</code>、<code>v2</code>之类的 API 版本号。版本号只允许枚举，不允许判断区间。</p><p> 版本号拼接在 URL 中或是放在 Header 中都可以。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">api.xxx.com/v1/users</span><br></pre></td></tr></table></figure><p> 或：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">api.xxx.com/users</span><br><span class="line"></span><br><span class="line">version=v1</span><br></pre></td></tr></table></figure><h3 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h3><p> 一般来说 API 的外在形式无非就是增删改查（当然具体的业务逻辑肯定要复杂得多），而查询又分为详情和列表两种，在 RESTful 中这就相当于通用的模板。例如针对文章（Article）设计 API，那么最基础的 URL 就是这几种：</p><ul><li><code>GET /articles</code>： 文章列表</li><li><code>GET /articles/id</code>：文章详情</li><li><code>POST /articles/</code>： 创建文章</li><li><code>PUT /articles/id</code>：修改文章</li><li><code>DELETE /articles/id</code>：删除文章</li></ul><p>RESTful 中使用 GET、POST、PUT 和 DELETE 来表示资源的查询、创建、更改、删除，并且除了 POST 其他三种请求都具备幂等性（多次请求的效果相同）。需要注意的是 POST 和 PUT 最大的区别就是幂等性，所以 PUT 也可以用于创建操作，只要在创建前就可以确定资源的 id。</p><p> 将 id 放在 URL 中而不是 Query Param 的其中一个好处是可以表示资源之间的层级关系，例如文章下面会有评论（Comment）和点赞（Like），这两项资源必然会属于一篇文章，所以它们的 URL 应该是这样的：</p><p> 评论：</p><ul><li><code>GET /articles/aid/comments</code>： 某篇文章的评论列表</li><li><code>GET /comments/cid</code>： 获取</li><li><code>POST /articles/aid/comments</code>： 在某篇文章中创建评论</li><li><code>PUT /comments/cid</code>： 修改评论</li><li><p><code>DELETE /comments/cid</code>： 删除评论</p><p>这里有一点比较特殊，永远去使用可以指向资源的的最短 URL 路径，也就是说既然<code>/comments/cid</code>已经可以指向一条评论了，就不需要再用<code>/articles/aid/comments/cid</code>特意的指出所属文章了。</p><p>点赞：</p></li><li><p><code>GET /articles/id/like</code>：查看文章是否被点赞</p></li><li><code>PUT /articles/id/like</code>：点赞文章</li><li><code>DELETE /articles/id/like</code>：取消点赞</li></ul><p>RESTful 中不建议出现动词，所以可以将这种关系作为资源来映射。并且由于大部分的关系查询都与当前的登录用户有关，所以也可以直接在关系所属的资源中返回关系状态。例如点赞状态就可以直接在获取文章详情时返回。注意这里我选择了 PUT 而不是 POST，因为我觉得点赞这种行为应该是幂等的，多次操作的结果应该相同。</p><h3 id="Token-和-Sign"><a href="#Token-和-Sign" class="headerlink" title="Token 和 Sign"></a>Token 和 Sign</h3><p>API 需要设计成无状态，所以客户端在每次请求时都需要提供有效的 Token 和 Sign，在我看来它们的用途分别是：</p><ul><li>Token 用于证明请求所属的用户，一般都是服务端在登录后随机生成一段字符串（UUID）和登录用户进行绑定，再将其返回给客户端。Token 的状态保持一般有两种方式实现：一种是在用户每次操作都会延长或重置 TOKEN 的生存时间（类似于缓存的机制），另一种是 Token 的生存时间固定不变，但是同时返回一个刷新用的 Token，当 Token 过期时可以将其刷新而不是重新登录。</li><li>Sign 用于证明该次请求合理，所以一般客户端会把请求参数拼接后并加密作为 Sign 传给服务端，这样即使被抓包了，对方只修改参数而无法生成对应的 Sign 也会被服务端识破。当然也可以将时间戳、请求地址和 Token 也混入 Sign，这样 Sign 也拥有了所属人、时效性和目的地。</li></ul><h3 id="统计性参数"><a href="#统计性参数" class="headerlink" title="统计性参数"></a>统计性参数</h3><p> 我不太清楚这类参数具体该被称为什么，总之就是用户的各种隐私【误。类似于经纬度、手机系统、型号、IMEI、网络状态、客户端版本、渠道等，这些参数会经常收集然后用作运营、统计等平台，但是在大部分情况下他们是与业务无关的。这类参数变化不频繁的可以在登录时提交，变化比较频繁的可以用轮训或是在其他请求中附加提交。</p><h3 id="业务参数"><a href="#业务参数" class="headerlink" title="业务参数"></a>业务参数</h3><p> 在 RESTful 的标准中，PUT 和 PATCH 都可以用于修改操作，它们的区别是 PUT 需要提交整个对象，而 PATCH 只需要提交修改的信息。但是在我看来实际应用中不需要这么麻烦，所以我一律使用 PUT，并且只提交修改的信息。</p><p> 另一个问题是在 POST 创建对象时，究竟该用表单提交更好些还是用 JSON 提交更好些。其实两者都可以，在我看来它们唯一的区别是 JSON 可以比较方便的表示更为复杂的结构（有嵌套对象）。另外无论使用哪种，请保持统一，不要两者混用。</p><p> 还有一个建议是最好将过滤、分页和排序的相关信息全权交给客户端，包括过滤条件、页数或是游标、每页的数量、排序方式、升降序等，这样可以使 API 更加灵活。但是对于过滤条件、排序方式等，不需要支持所有方式，只需要支持目前用得上的和以后可能会用上的方式即可，并通过字符串枚举解析，这样可见性要更好些。例如：</p><p> 搜索，客户端只提供关键词，具体搜索的字段，和搜索方式（前缀、全文、精确）由服务端决定：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/users/?query=ScienJus</span><br></pre></td></tr></table></figure><p> 过滤，只需要对已有的情况进行支持：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/users/?gender=1</span><br></pre></td></tr></table></figure><p> 对于某些特定且复杂的业务逻辑，不要试图让客户端用复杂的查询参数表示，而是在 URL 使用别名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/users/recommend</span><br></pre></td></tr></table></figure><p> 分页：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/users/?offset=10&amp;limit=10</span><br><span class="line"></span><br><span class="line">/articles/?cursor=2015-01-01 15:20:30&amp;limit=10</span><br><span class="line"></span><br><span class="line">/users/?page=2&amp;pre_page=20</span><br></pre></td></tr></table></figure><p> 排序，只需要对已有的情况进行支持：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/articles/sort=-create_date</span><br></pre></td></tr></table></figure><p>PS：我很喜欢这种在字段名前面加<code>-</code>表示降序排列的方式。</p><h3 id="响应"><a href="#响应" class="headerlink" title="响应"></a>响应</h3><p> 尽量使用 HTTP 状态码，常用的有：</p><ul><li>200：请求成功</li><li>201：创建、修改成功</li><li>204：删除成功</li><li>400：参数错误</li><li>401：未登录</li><li>403：禁止访问</li><li>404：未找到</li><li><p>500：系统错误</p><p>但是有些时候仅仅使用 HTTP 状态码没有办法明确的表达错误信息，所以我倾向于在里面再包一层自定义的返回码，例如：</p><p>成功时：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;code&quot;: 100,</span><br><span class="line">    &quot;msg&quot;: &quot;成功&quot;,</span><br><span class="line">    &quot;data&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 失败时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;code&quot;: -1000,</span><br><span class="line">    &quot;msg&quot;: &quot;用户名或密码错误&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>data</code>是真正需要返回的数据，并且只会在请求成功时才存在，<code>msg</code>只用在开发环境，并且只为了开发人员识别。客户端逻辑只允许识别<code>code</code>，并且不允许直接将<code>msg</code>的内容展示给用户。如果这个错误很复杂，无法使用一段话描述清楚，也可以在添加一个<code>doc</code>字段，包含指向该错误的文档的链接。</p><h3 id="返回数据"><a href="#返回数据" class="headerlink" title="返回数据"></a>返回数据</h3><p>JSON 比 XML 可视化更好，也更加节约流量，所以尽量不要使用 XML。</p><p> 创建和修改操作成功后，需要返回该资源的全部信息。</p><p> 返回数据不要和客户端界面强耦合，不要在设计 API 时就考虑少查询一张关联表或是少查询 / 返回几个字段能带来多大的性能提升。并且一定要以资源为单位，即使客户端一个页面需要展示多个资源，也不要在一个接口中全部返回，而是让客户端分别请求多个接口。</p><p> 最好将返回数据进行加密和压缩，尤其是压缩在移动应用中还是比较重要的。</p><h3 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h3><p> 在 <a href="http://www.scienjus.com/app-server-paging/">APP 后端分页设计</a> 中提到过，分页布局一般分为两种，一种是在 Web 端比较常见的有底部分页栏的电梯式分页，另一种是在 APP 中比较常见的上拉加载更多的流式分页。这两种分页的 API 到底该如何设计呢？</p><p> 电梯式分页需要提供<code>page</code>（页数）和<code>pre_page</code>（每页的数量）。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/users/?page=2&amp;pre_page=20</span><br></pre></td></tr></table></figure><p> 而服务端则需要额外返回<code>total_count</code>（总记录数），以及可选的当前页数、每页的数量（这两个与客户端提交的相同）、总页数、是否有下一页、是否有上一页（这三个都可以通过总记录数计算出）。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;pagination&quot;: &#123;</span><br><span class="line">       &quot;previous&quot;: 1,</span><br><span class="line">       &quot;next&quot;: 3,</span><br><span class="line">       &quot;current&quot;: 2,</span><br><span class="line">       &quot;per_page&quot;: 20,</span><br><span class="line">       &quot;total&quot;: 200,</span><br><span class="line">       &quot;pages&quot;: 10</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;data&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 流式布局也完全可以使用这种方式，并且不需要查询总记录数（好处是减少一次数据库操作，坏处时客户端需要多请求一次才能判断是否到最后一页）。但是会出现数据重复和缺失的情况，所以更推荐使用游标分页。</p><p> 游标分页需要提供<code>cursor</code>(下一页的起点游标) 和<code>limit</code>(数量) 参数。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/articles/?cursor=2015-01-01 15:20:30&amp;limit=10</span><br></pre></td></tr></table></figure><p> 如果文章列表默认是以创建时间为倒序排列的，那么<code>cursor</code>就是当前列表最后一条的创建时间（第一页为当前时间）。</p><p> 服务端需要返回的数据也很简单，只需要以此游标为起点的总记录数和下一个起点游标就可以了。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;pagination&quot;: &#123;</span><br><span class="line">       &quot;next&quot;: &quot;2015-01-01 12:20:30&quot;,</span><br><span class="line">       &quot;limit&quot;: 10,</span><br><span class="line">       &quot;total&quot;: 100,</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;data&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 如果<code>total</code>小于<code>limit</code>，就说明已经没有数据了。</p><p> 流式布局的分页 API 还有一种情况很常见，就是下拉刷新的增量更新。它的业务逻辑正好和游标分页相反，但是参数基本一样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/articles/?cursor=2015-01-01 15:20:30&amp;limit=20</span><br></pre></td></tr></table></figure><p> 返回数据有两种可能，一种是增量更新的数据小于指定的数量，就直接将全部数据返回（这个数量可以设置的相对大一些），客户端会将这些增量更新的数据添加在已有列表的顶部。但是如果增量更新的数据要大于指定的数量，就会只返回最新的 n 条数据作为第一页，这时候客户端需要清空之前的列表。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;pagination&quot;: &#123;</span><br><span class="line">       &quot;limit&quot;: 20,</span><br><span class="line">       &quot;total&quot;: 100,</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;data&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 如果<code>total</code>大于<code>limit</code>，说明增量的数据太多所以只返回了第一页，需要清空旧的列表。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;不要纠结于无意义的规范&quot;&gt;&lt;a href=&quot;#不要纠结于无意义的规范&quot; class=&quot;headerlink&quot; title=&quot;不要纠结于无意义的规范&quot;&gt;&lt;/a&gt;不要纠结于无意义的规范&lt;/h3&gt;&lt;p&gt; 在开始本文之前，我想先说这么一句：RESTful 真的很好，但它只
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>使用Chrome Developer Tools调试线上网站</title>
    <link href="http://www.scienjus.com/chrome-developer-tools/"/>
    <id>http://www.scienjus.com/chrome-developer-tools/</id>
    <published>2016-04-02T00:44:56.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>起因是刷微博闲聊的时候发现评论的图片无法查看大图：</p><p><img src="/uploads/2016/04/weibo1.jpg" alt="微博"></p><p> 本来以为是网的问题，但是当时闲得无聊，就随手打开了 Chrome Developer Tools (F12)，结果发现 Network 请求的图片地址很奇怪：</p><p><img src="/uploads/2016/04/weibo2.jpg" alt="Network"></p><p> 本应该传一个图片 id 的地方却传了<code>null</code>和<code>undefined</code>，这说明肯定是请求之前取图片 id 失败了，查看一下 Elements 中的节点（直接在页面的对应位置右键，选择检查元素）：</p><p><img src="/uploads/2016/04/weibo3.jpg" alt="Dom 树"></p><p> 可以看到<code>action-data</code>中的<code>pid</code>确实为<code>null</code>，这就是导致请求失败的直接原因，但是这里又是怎么出错的呢？</p><p> 一边观察 Elements 一边点击图片，可以发现这个元素并不是直接由服务端渲染而成的，而是通过 JS 动态加载的。那么就好说了，只需要查看一下加载的 JS 代码就可以了。</p><p> 在 Elements 中右键点击这个元素，然后选择 Break on -\&gt; Subtree Modifications，这样当这个元素发生改变时，便会自动断点到正在执行的 JS 代码。</p><p><img src="/uploads/2016/04/weibo4.jpg" alt="断点"></p><p> 然后再次点击这个图片，触发 Dom 操作，发现断点停留在一坨被混淆和压缩的代码中。不过不要害怕，只需要点击下图左下角的<code>{}</code>按钮，JS 代码就会自动格式化了：</p><p> 格式化前：</p><p><img src="/uploads/2016/04/weibo5.jpg" alt="格式化前"></p><p> 格式化后：</p><p><img src="/uploads/2016/04/weibo6.jpg" alt="格式化后"></p><p> 接下来就是很普通的断点调试了，F8 是跳到下一个断点，F10 是下一步，F11 是进入方法，F12 是跳出方法。右侧列表还有调用栈，变量值等信息：</p><p><img src="/uploads/2016/04/weibo7.jpg" alt="调试"></p><p> 虽然代码还是被混淆过，但已经足够排查出问题了：在下面这行代码中会通过一个正则表达式截取出图片的 id 赋值给<code>n</code>（也就是之后的<code>pid</code>）。但是由于某些原因图片链接与正则表达式并不匹配，导致没有截取到，所以最后<code>n</code>的值为<code>null</code>。</p><p><img src="/uploads/2016/04/weibo8.jpg" alt="Bug"></p><p> 虽然这只是一个低级的 Bug，但是也可以轻描淡写的展示出 Chrome Developer Tools 的强大功能：监测网络请求、查看和动态修改 Dom 元素、格式化 JS 代码、断点调试运行中的 JS 代码。使你能够轻松的在开小差的时候一言不合就开始 Debug【误</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;起因是刷微博闲聊的时候发现评论的图片无法查看大图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/uploads/2016/04/weibo1.jpg&quot; alt=&quot;微博&quot;&gt;&lt;/p&gt;
&lt;p&gt; 本来以为是网的问题，但是当时闲得无聊，就随手打开了 Chrome Developer Tool
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>MyBatis无法扫描Spring Boot别名的Bug</title>
    <link href="http://www.scienjus.com/mybatis-vfs-bug/"/>
    <id>http://www.scienjus.com/mybatis-vfs-bug/</id>
    <published>2016-03-25T02:25:41.000Z</published>
    <updated>2018-01-15T05:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>这个问题发生的原因比较复杂，主要条件有 4 个：</p><ol><li>使用 Spring Boot，并使用 Spring Boot 的 Maven 插件打包</li><li>使用 MyBatis（目前最新的<code>3.3.1</code>版本仍有这个问题）</li><li>将 Domain 配置在单独的 Jar 包中（例如 Maven 多模块）</li><li><p>使用<code>SqlSessionFactoryBean.setTypeAliasesPackage</code>指定包扫描 Domain</p><p>然后你会发现：在开发时直接使用 IDEA 执行<code>main</code>方法运行时一切正常，但是打成 Jar 包后使用<code>java -jar</code>启动时配置的 Domain 别名均会失效。</p><p>例如我有一个 Spring Boot 项目，其中分为三个 Maven 模块：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scienjus</span><br><span class="line">----scienjus-domain</span><br><span class="line">--------com.scienjus.domain.User</span><br><span class="line">----scienjus-mapper</span><br><span class="line">--------com.scienjus.mapper.UserMapper</span><br><span class="line">--------UserMapper.xml</span><br><span class="line">----scienjus-web</span><br><span class="line">--------SqlSessionFactoryConfig</span><br></pre></td></tr></table></figure><p> 在 SqlSessionFactoryConfig 中配置 SqlSesstionFactory：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public SqlSessionFactory sqlSessionFactory () throws Exception &#123;</span><br><span class="line">    final SqlSessionFactoryBean sqlSessionFactory = new SqlSessionFactoryBean ();</span><br><span class="line">    sqlSessionFactory.setDataSource (dataSource ());</span><br><span class="line">    // 配置别名</span><br><span class="line">    sqlSessionFactory.setTypeAliasesPackage (&quot;com.scienjus.domain&quot;);</span><br><span class="line">    return sqlSessionFactory.getObject ();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 在 UserMapper.xml 使用别名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id=&quot;get&quot; resultType=&quot;User&quot;&gt;</span><br><span class="line">    select * from user u where id = \#&#123;id&#125;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure><p> 开发时使用 IDEA 启动一切都会正常运行，但是如果等到运行时通过命令行启动，将会出现以下错误信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.apache.ibatis.builder.BuilderException: Error resolving class. Cause:</span><br><span class="line">org.apache.ibatis.type.TypeException: Could not resolve type alias &apos;User&apos;. Cause:</span><br><span class="line">java.lang.ClassNotFoundException: Cannot find class: User</span><br></pre></td></tr></table></figure><p> 这个错误的大概意思是生成 Mapper 时出错了，原因是无法识别<code>User</code>这个别名，也找不到<code>User</code>这个 class。可以看出之前配的包扫描根本没有扫描到<code>com.scienjus.domain.User</code>这个类。</p><p> 为了证明这点，我翻了一下 MyBatis 的源码，然后在<code>org.apache.ibatis.type.TypeAliasRegistry</code>的<code>registerAliases (String packageName, Class&gt; superType)</code>方法中发现了 MyBatis 是如何通过包名扫描别名类的。直接将这部分逻辑搬到<code>main</code>方法中执行试试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public static void main (String [] args) &#123;</span><br><span class="line">    ResolverUtil resolverUtil = new ResolverUtil ();</span><br><span class="line">    resolverUtil.find (new IsA (Object.class), &quot;com.scienjus.domain&quot;);</span><br><span class="line">    Set typeSet = resolverUtil.getClasses ();</span><br><span class="line">    Iterator i$ = typeSet.iterator ();</span><br><span class="line"></span><br><span class="line">    while (i$.hasNext ()) &#123;</span><br><span class="line">        Class type = (Class) i$.next ();</span><br><span class="line">        if (!type.isAnonymousClass () &amp;&amp; !type.isInterface () &amp;&amp; !type.isMemberClass ()) &#123;</span><br><span class="line">            System.out.println (type.getName ());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 分别在 IDEA 和 Jar 中执行，会发现前者将会打印出<code>com.scienjus.domain.User</code>，后者却无任何输出结果，说明问题出在这里。</p><p> 既然锁定了问题出现的地方，就可以仔细看看这是如何发生的了。查看<code>ResolverUtil.find</code>方法，其通过<code>VFS.getInstance ().list (path)</code>方法获得 Class 文件，而<code>VFS.getInstance ()</code>默认情况下返回的是<code>DefaultVFS</code>，也就是说原因是这个类的<code>list</code>方法无法扫描到 Spring Boot 依赖 Jar 包中的类。</p><p> 再细化一下调用逻辑，就可以准备断点调试了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public static void main (String [] args) throws IOException &#123;</span><br><span class="line">    DefaultVFS defaultVFS = new DefaultVFS ();</span><br><span class="line">    List children = defaultVFS.list (&quot;com/scienjus/domain&quot;);</span><br><span class="line">    for (String child : children) &#123;</span><br><span class="line">        System.out.println (child);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 断点调试使用<code>java -jar</code>启动的程序并没有想象中困难，IDEA 和 Eclipse 都内置了非常优秀的调试工具，略微介绍一下 IDEA 中的使用方法：</p><p> 开启 Debug 模式运行 Jar 包，并且监听一个特定的端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -Xdebug -Xrunjdwp:transport=dt_socket,address=5005,server=y,suspend=y -jar scienjus-web.jar</span><br></pre></td></tr></table></figure><p>IDEA 端在 Run -\&gt; Edit Configurations 中创建一个 Remote 应用，填写 IP 和监听的端口号，然后启动就可以了。</p><p> 通过断点调试我在<code>findJarForResource</code>发现了一块比较有意思的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// If the file part of the URL is itself a URL, then that URL probably points to the JAR</span><br><span class="line">try &#123;</span><br><span class="line">  for (;;) &#123;</span><br><span class="line">    url = new URL (url.getFile ());</span><br><span class="line">    if (log.isDebugEnabled ()) &#123;</span><br><span class="line">      log.debug (&quot;Inner URL: &quot; + url);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125; catch (MalformedURLException e) &#123;</span><br><span class="line">  // This will happen at some point and serves as a break in the loop</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这是一个死循环，唯有抛出<code>MalformedURLException</code>异常时才会跳出循环，根据上面的注释我们可以得知，这件事是必然发生的，且会将<code>url</code>指向一个想要的结果。对比一下两种方式运行时<code>url</code>最后的结果：</p><p>IDEA 中直接运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scienjus-domain/target/classes/com/scienjus/domain</span><br></pre></td></tr></table></figure><p> 命令行运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scienjus-web/target/scienjus-web.jar!/lib/scienjus-domain.jar!/com/scienjus/domain</span><br></pre></td></tr></table></figure><p> 之后将变量<code>jarUrl</code>的值赋为<code>scienjus-web/target/scienjus-web.jar!/lib/scienjus-domain.jar</code>，但是最后<code>listResources</code>方法会返回<code>null</code>。</p><p> 而调用这个方法时的注释则是这样说的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// First, try to find the URL of a JAR file containing the requested resource. If a JAR</span><br><span class="line">// file is found, then we&apos;ll list child resources by reading the JAR.</span><br></pre></td></tr></table></figure><p> 也就是说，如果扫描的文件确实在一个 Jar 包中，这个方法应该返回这个 Jar 包的 URL，于是尝试一个比较粗暴的改进：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public static void main (String [] args) throws IOException &#123;</span><br><span class="line">    DefaultVFS defaultVFS = new DefaultVFS () &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected URL findJarForResource (URL url) throws MalformedURLException &#123;</span><br><span class="line">            String urlStr = url.toString ();</span><br><span class="line">            if (urlStr.contains (&quot;jar!&quot;)) &#123;</span><br><span class="line">                return new URL (urlStr.substring (0, urlStr.lastIndexOf (&quot;jar&quot;) + &quot;jar&quot;.length ()));</span><br><span class="line">            &#125;</span><br><span class="line">            return super.findJarForResource (url);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    List children = defaultVFS.list (&quot;com/scienjus/domain&quot;);</span><br><span class="line">    for (String child : children) &#123;</span><br><span class="line">        System.out.println (child);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 如果这个 URL 中含有<code>jar!</code>的标识，就直接返回这个 Jar 包的地址。我不太确定这样做是否有隐患，不过我只有在扫描 Domain 别名时会用到这个类，并且这时候是正常工作的。</p><p> 既然这个类可以正常工作了，只需要将它设为默认的 VFS。在 MyBatis 的 <a href="http://www.mybatis.org/mybatis-3/zh/configuration.html#properties" target="_blank" rel="external">文档</a> 中写着可以通过配置文件更改<code>vfsImpl</code>属性更换 VFS 实现类，我这里用这个配置没有效果，原因是 Spring 的配置会在 MyBatis 配置文件之前执行，所以在读取这个配置之前<code>VFS.getInstall ()</code>已经实例化了。然后我给 MyBatis 提了个 Issue，顺道还发现这个扫描不到类的 Bug 早在去年10月 就有人提出了，也早就有解决办法了，只是需要到<code>3.4.1</code>版本才会发布。</p><p>MyBatis 官方的解决办法首先是推荐使用 <a href="https://github.com/mybatis/mybatis-spring-boot" target="_blank" rel="external">mybatis-spring-boot</a> 的<code>1.0.1</code>版本，默认已经配置了一个兼容 Spring Boot 的 VFS 实现类。或是将 <a href="https://github.com/mybatis/mybatis-spring-boot/commit/35be747a4c4e53121e4c4c32d08418864095adf7" target="_blank" rel="external">这个实现类</a> 添加到你的项目中，并手动配置。</p><p> 为了不让这些瞎折腾白费，我决定将这整个过程发布出来，教各位在使用开源项目遇到 bug 时如何定（zuo）位（si），这可能也是本文的仅剩的一点价值了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这个问题发生的原因比较复杂，主要条件有 4 个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用 Spring Boot，并使用 Spring Boot 的 Maven 插件打包&lt;/li&gt;
&lt;li&gt;使用 MyBatis（目前最新的&lt;code&gt;3.3.1&lt;/code&gt;版本仍有这个问题）&lt;/l
      
    
    </summary>
    
    
  </entry>
  
</feed>
